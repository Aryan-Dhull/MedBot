{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"62f68fdb808b4f61b3ca1413149be8cd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6fff938c635447389f1da62a05335b73","IPY_MODEL_393029e4fb3647c08979241ec8e7d5d2","IPY_MODEL_697b2620933d4761b2fb152025f54422"],"layout":"IPY_MODEL_b2cba9d8253d4cb3bbed8e15f6012f16"}},"6fff938c635447389f1da62a05335b73":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1273d9a3ee0b4271813644f40622a61c","placeholder":"​","style":"IPY_MODEL_7ac400995146492aa08d221afd2f6fd9","value":"Loading checkpoint shards: 100%"}},"393029e4fb3647c08979241ec8e7d5d2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_25f68dab2a2c4b74a41a264439575e8d","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_16459c8ae7664b31858b3dba201f3801","value":2}},"697b2620933d4761b2fb152025f54422":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c95900b4a1934a909a491a06fc897cc5","placeholder":"​","style":"IPY_MODEL_f4bf55404ca048978eccf62a7861c1cc","value":" 2/2 [00:13&lt;00:00,  5.74s/it]"}},"b2cba9d8253d4cb3bbed8e15f6012f16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1273d9a3ee0b4271813644f40622a61c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ac400995146492aa08d221afd2f6fd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25f68dab2a2c4b74a41a264439575e8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16459c8ae7664b31858b3dba201f3801":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c95900b4a1934a909a491a06fc897cc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4bf55404ca048978eccf62a7861c1cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"224660411b33488b8070f702ee6f259e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_533e70493bde46319b2a701710bb7234","IPY_MODEL_af00cda72d8e4f7b80773a24fe9ff99e","IPY_MODEL_b3bb1699ac0a462bb20da1e759366a81"],"layout":"IPY_MODEL_f5236eb4124b44f282588e2051b4839e"}},"533e70493bde46319b2a701710bb7234":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1f6d333fa1d4c608107da2a49912dc0","placeholder":"​","style":"IPY_MODEL_f736aa29d82d49b391a2e9f240c59792","value":"Map: 100%"}},"af00cda72d8e4f7b80773a24fe9ff99e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ecc3ac785eea4ad693986b75fefe65cb","max":13125,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c431103e4134c4f8d81fa2229dba4a3","value":13125}},"b3bb1699ac0a462bb20da1e759366a81":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5266779c2967413d9fb32d3eb4373f65","placeholder":"​","style":"IPY_MODEL_b282da4544b849c1b1284ddb60126764","value":" 13125/13125 [00:17&lt;00:00, 1117.86 examples/s]"}},"f5236eb4124b44f282588e2051b4839e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1f6d333fa1d4c608107da2a49912dc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f736aa29d82d49b391a2e9f240c59792":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ecc3ac785eea4ad693986b75fefe65cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c431103e4134c4f8d81fa2229dba4a3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5266779c2967413d9fb32d3eb4373f65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b282da4544b849c1b1284ddb60126764":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e8f818c31eb4030808d35f91e93dbc4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99f13844164d42bca880ab298ae84869","IPY_MODEL_b504d9c7b0444967a18538634d1dfed5","IPY_MODEL_f78f68f0571b4c079cca8c4bf7c427fb"],"layout":"IPY_MODEL_3ebba0a98f1f470fb49606d6e422929b"}},"99f13844164d42bca880ab298ae84869":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f73f1b83156d4e6496f6fd481ef10931","placeholder":"​","style":"IPY_MODEL_9a6e8d194a4e464a81c958e940c51e05","value":"Map: 100%"}},"b504d9c7b0444967a18538634d1dfed5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a58c7c99d694c3197e1dec300f240eb","max":13125,"min":0,"orientation":"horizontal","style":"IPY_MODEL_27deb6ed10f64526a9a3d47b77612087","value":13125}},"f78f68f0571b4c079cca8c4bf7c427fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b296317f9d384eaab2652c115d90f57f","placeholder":"​","style":"IPY_MODEL_1f9c92ce500c4a9ba031421979c218de","value":" 13125/13125 [00:10&lt;00:00, 1467.15 examples/s]"}},"3ebba0a98f1f470fb49606d6e422929b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f73f1b83156d4e6496f6fd481ef10931":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a6e8d194a4e464a81c958e940c51e05":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a58c7c99d694c3197e1dec300f240eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27deb6ed10f64526a9a3d47b77612087":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b296317f9d384eaab2652c115d90f57f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f9c92ce500c4a9ba031421979c218de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b865ac44a9a8436a91c617d000d91848":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7df5a775d3cf468b90e069ca6a61be04","IPY_MODEL_65ea478d6eb64a9c8f5ab607b8c86d22","IPY_MODEL_6026ec7263dd40a1a8539eeef16725f0"],"layout":"IPY_MODEL_5ed79d8f9c2f490fadf7d3067f21f635"}},"7df5a775d3cf468b90e069ca6a61be04":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_31f46be033b44e60b00ec4dc3346cf21","placeholder":"​","style":"IPY_MODEL_667fb313df2b4a5b807c83453ef684f1","value":"Map: 100%"}},"65ea478d6eb64a9c8f5ab607b8c86d22":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f64805f9cb749de88315e3f76235ca2","max":13125,"min":0,"orientation":"horizontal","style":"IPY_MODEL_683bf4ba85e74a7da4f11f0fbbfce881","value":13125}},"6026ec7263dd40a1a8539eeef16725f0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9786d63b370248b1b0fad0b8b20d80d9","placeholder":"​","style":"IPY_MODEL_9a3f49090d464f6e9950f0fd3aabab67","value":" 13125/13125 [00:13&lt;00:00, 956.11 examples/s]"}},"5ed79d8f9c2f490fadf7d3067f21f635":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31f46be033b44e60b00ec4dc3346cf21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"667fb313df2b4a5b807c83453ef684f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f64805f9cb749de88315e3f76235ca2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"683bf4ba85e74a7da4f11f0fbbfce881":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9786d63b370248b1b0fad0b8b20d80d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a3f49090d464f6e9950f0fd3aabab67":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install and import the necessary libraries\n!pip install -q torch\n!pip install -q -U accelerate peft bitsandbytes transformers trl einops","metadata":{"id":"yQAVFua5xIP0","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:34:05.519678Z","iopub.execute_input":"2024-11-17T12:34:05.519967Z","iopub.status.idle":"2024-11-17T12:34:29.350959Z","shell.execute_reply.started":"2024-11-17T12:34:05.519928Z","shell.execute_reply":"2024-11-17T12:34:29.349826Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:34:29.352369Z","iopub.execute_input":"2024-11-17T12:34:29.352734Z","iopub.status.idle":"2024-11-17T12:34:29.357466Z","shell.execute_reply.started":"2024-11-17T12:34:29.352699Z","shell.execute_reply":"2024-11-17T12:34:29.356461Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(token=\"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:34:29.358925Z","iopub.execute_input":"2024-11-17T12:34:29.359547Z","iopub.status.idle":"2024-11-17T12:34:29.878067Z","shell.execute_reply.started":"2024-11-17T12:34:29.359512Z","shell.execute_reply":"2024-11-17T12:34:29.877130Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nimport torch\nfrom datasets import load_dataset\nfrom datasets import load_from_disk\nfrom peft import LoraConfig, prepare_model_for_kbit_training, PeftModel\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    AutoTokenizer,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\n\nfrom trl import SFTTrainer","metadata":{"id":"qktqRakcz7KR","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:34:29.881359Z","iopub.execute_input":"2024-11-17T12:34:29.881710Z","iopub.status.idle":"2024-11-17T12:34:41.080601Z","shell.execute_reply.started":"2024-11-17T12:34:29.881677Z","shell.execute_reply":"2024-11-17T12:34:41.079812Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Model\nbase_model = \"meta-llama/Meta-Llama-3-8B-Instruct\"\nnew_model = \"llama-medbot\"\n\n# Tokenizer\ntokenizer = AutoTokenizer.from_pretrained(base_model, use_fast=True)\ntokenizer.pad_token=tokenizer.eos_token\ntokenizer.padding_side=\"right\"","metadata":{"id":"XainoHg40CN8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1bd62b41-faf0-4443-e17c-c7c1aa461388","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:34:41.081685Z","iopub.execute_input":"2024-11-17T12:34:41.081984Z","iopub.status.idle":"2024-11-17T12:34:41.735582Z","shell.execute_reply.started":"2024-11-17T12:34:41.081951Z","shell.execute_reply":"2024-11-17T12:34:41.734569Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from datasets import load_dataset, DatasetDict, Dataset\ndataset = load_dataset(\"keivalya/MedQuad-MedicalQnADataset\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Define a function to transform the dataset\ndef format_example(example):\n    # Use the specified format for text\n    example[\"text\"] = f\"### Instruction: {example['Question']} ### Assistant: {example['Answer']}\"\n    return example\n\ntrain_test_split = dataset['train'].train_test_split(test_size=0.2)\ntrain_dataset=train_test_split[\"train\"]\ntrain_dataset = train_dataset\ntest_dataset=train_test_split[\"test\"]\ntest_dataset = test_dataset\n\n# Apply the transformation to both the train and test datasets\ntrain_dataset = train_dataset.map(format_example)\n\n# Remove unnecessary columns and keep only the \"text\" column\ntrain_dataset = train_dataset.remove_columns([\"qtype\", \"Question\", \"Answer\"])\n# print(formatted_dataset)\n\ntrain_dataset=train_dataset.select(range(6000))\n\n# Preview the dataset\nprint(train_dataset)\nprint(test_dataset)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j4ljJCJBBYq5","outputId":"98f308f9-6047-4ccd-a5d2-0d2782ecbbb6","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:34:41.736870Z","iopub.execute_input":"2024-11-17T12:34:41.737210Z","iopub.status.idle":"2024-11-17T12:34:45.292023Z","shell.execute_reply.started":"2024-11-17T12:34:41.737175Z","shell.execute_reply":"2024-11-17T12:34:45.291083Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/13125 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92efe4cb06e746a48e35607beb23cbd3"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['text'],\n    num_rows: 6000\n})\nDataset({\n    features: ['qtype', 'Question', 'Answer'],\n    num_rows: 3282\n})\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:34:45.293588Z","iopub.execute_input":"2024-11-17T12:34:45.293985Z","iopub.status.idle":"2024-11-17T12:34:45.298991Z","shell.execute_reply.started":"2024-11-17T12:34:45.293938Z","shell.execute_reply":"2024-11-17T12:34:45.298024Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Quantization configuration\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=False,\n)\n\n# Load base moodel\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    trust_remote_code=True,\n    low_cpu_mem_usage=True,\n    device_map={\"\": torch.cuda.current_device()}\n)\n\nmodel = model.to(device)","metadata":{"id":"ZBtEMcxWyhjM","colab":{"base_uri":"https://localhost:8080/","height":138,"referenced_widgets":["62f68fdb808b4f61b3ca1413149be8cd","6fff938c635447389f1da62a05335b73","393029e4fb3647c08979241ec8e7d5d2","697b2620933d4761b2fb152025f54422","b2cba9d8253d4cb3bbed8e15f6012f16","1273d9a3ee0b4271813644f40622a61c","7ac400995146492aa08d221afd2f6fd9","25f68dab2a2c4b74a41a264439575e8d","16459c8ae7664b31858b3dba201f3801","c95900b4a1934a909a491a06fc897cc5","f4bf55404ca048978eccf62a7861c1cc"]},"outputId":"c1ca4f4e-9ef2-4e30-f314-6145f58ddf14","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:34:45.300286Z","iopub.execute_input":"2024-11-17T12:34:45.300922Z","iopub.status.idle":"2024-11-17T12:35:52.473506Z","shell.execute_reply.started":"2024-11-17T12:34:45.300877Z","shell.execute_reply":"2024-11-17T12:35:52.471781Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34a4e2cc00e5414ea72ea9b5e6d76fc3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1f6f7750ac346e0b504e04350797289"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"model.config.use_cache = False\nmodel.config.pretraining_tp = 1\nmodel = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":243,"referenced_widgets":["224660411b33488b8070f702ee6f259e","533e70493bde46319b2a701710bb7234","af00cda72d8e4f7b80773a24fe9ff99e","b3bb1699ac0a462bb20da1e759366a81","f5236eb4124b44f282588e2051b4839e","b1f6d333fa1d4c608107da2a49912dc0","f736aa29d82d49b391a2e9f240c59792","ecc3ac785eea4ad693986b75fefe65cb","9c431103e4134c4f8d81fa2229dba4a3","5266779c2967413d9fb32d3eb4373f65","b282da4544b849c1b1284ddb60126764"]},"id":"2qGb6_AiF6ss","outputId":"eacee662-f469-4e70-d88b-14b33048eab1","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:52.475991Z","iopub.execute_input":"2024-11-17T12:35:52.476405Z","iopub.status.idle":"2024-11-17T12:35:52.504973Z","shell.execute_reply.started":"2024-11-17T12:35:52.476360Z","shell.execute_reply":"2024-11-17T12:35:52.504104Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Set training arguments\ntraining_arguments = TrainingArguments(\n    output_dir = \"./results\",\n    num_train_epochs = 1,\n    fp16 = False,\n    bf16 = False,\n    per_device_train_batch_size = 2,\n    per_device_eval_batch_size = 2,\n    gradient_accumulation_steps = 1,\n    gradient_checkpointing = True,\n    max_grad_norm = 0.3,\n    learning_rate = 2e-4,\n    weight_decay = 0.001,\n    optim = \"paged_adamw_32bit\",\n    lr_scheduler_type = \"cosine\",\n    max_steps = -1,\n    warmup_ratio = 0.03,\n    group_by_length = True,\n    save_steps = 0,\n    logging_steps = 100,\n)\n\n# LoRA configuration\npeft_config = LoraConfig(\n    r=64,                   #default=8\n    lora_alpha= 16,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules = [\"q_proj\", \"v_proj\"]\n)\n","metadata":{"id":"2c8cNUYkGb3V","outputId":"2cb24bf2-f44f-4325-c5db-2f8ff663dc0d","colab":{"base_uri":"https://localhost:8080/","height":225,"referenced_widgets":["6e8f818c31eb4030808d35f91e93dbc4","99f13844164d42bca880ab298ae84869","b504d9c7b0444967a18538634d1dfed5","f78f68f0571b4c079cca8c4bf7c427fb","3ebba0a98f1f470fb49606d6e422929b","f73f1b83156d4e6496f6fd481ef10931","9a6e8d194a4e464a81c958e940c51e05","4a58c7c99d694c3197e1dec300f240eb","27deb6ed10f64526a9a3d47b77612087","b296317f9d384eaab2652c115d90f57f","1f9c92ce500c4a9ba031421979c218de"]},"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:52.506225Z","iopub.execute_input":"2024-11-17T12:35:52.506613Z","iopub.status.idle":"2024-11-17T12:35:52.569384Z","shell.execute_reply.started":"2024-11-17T12:35:52.506553Z","shell.execute_reply":"2024-11-17T12:35:52.568602Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"#print_trainable_parameters(model)\n\n# Set supervised fine-tuning parameters\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=train_dataset,\n    peft_config=peft_config,\n    dataset_text_field=\"text\",\n    max_seq_length= 200,\n    tokenizer=tokenizer,\n    args=training_arguments,\n)","metadata":{"id":"d8ga7V-aGvBn","outputId":"b8af5204-d4c3-4b9e-b92f-9ab77067aed6","colab":{"base_uri":"https://localhost:8080/","height":225,"referenced_widgets":["b865ac44a9a8436a91c617d000d91848","7df5a775d3cf468b90e069ca6a61be04","65ea478d6eb64a9c8f5ab607b8c86d22","6026ec7263dd40a1a8539eeef16725f0","5ed79d8f9c2f490fadf7d3067f21f635","31f46be033b44e60b00ec4dc3346cf21","667fb313df2b4a5b807c83453ef684f1","3f64805f9cb749de88315e3f76235ca2","683bf4ba85e74a7da4f11f0fbbfce881","9786d63b370248b1b0fad0b8b20d80d9","9a3f49090d464f6e9950f0fd3aabab67"]},"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:52.570541Z","iopub.execute_input":"2024-11-17T12:35:52.570881Z","iopub.status.idle":"2024-11-17T12:35:56.695627Z","shell.execute_reply.started":"2024-11-17T12:35:52.570847Z","shell.execute_reply":"2024-11-17T12:35:56.694829Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fb88933cad2421ea8a95e53f00b091f"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# Train model\ntrainer.train()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":362},"id":"45UAm35t0TKZ","outputId":"bf886eb6-00dd-4791-b40e-e0c50645afad","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:56.696795Z","iopub.execute_input":"2024-11-17T12:35:56.697108Z","iopub.status.idle":"2024-11-17T17:16:46.244020Z","shell.execute_reply.started":"2024-11-17T12:35:56.697075Z","shell.execute_reply":"2024-11-17T17:16:46.243068Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113127755553858, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6e5d05d26d642908290787283a811ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241117_123630-1h5fbfy2</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/pranav21551-indraprastha-institute-of-information-techno/huggingface/runs/1h5fbfy2' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/pranav21551-indraprastha-institute-of-information-techno/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/pranav21551-indraprastha-institute-of-information-techno/huggingface' target=\"_blank\">https://wandb.ai/pranav21551-indraprastha-institute-of-information-techno/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/pranav21551-indraprastha-institute-of-information-techno/huggingface/runs/1h5fbfy2' target=\"_blank\">https://wandb.ai/pranav21551-indraprastha-institute-of-information-techno/huggingface/runs/1h5fbfy2</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3000/3000 4:40:04, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>1.651400</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.233500</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.138000</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.093700</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.063100</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.041300</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>1.096700</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>1.047800</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>1.049300</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.024600</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>1.068500</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>1.036900</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>1.003600</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>1.026900</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>1.030200</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>1.059900</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>1.090000</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.987900</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>1.020300</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.992100</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>0.993000</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.987600</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>1.042000</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>1.011300</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>1.054200</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>0.988200</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>0.973800</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>1.023300</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>1.033100</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>1.022700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3000, training_loss=1.0628282267252604, metrics={'train_runtime': 16847.7978, 'train_samples_per_second': 0.356, 'train_steps_per_second': 0.178, 'total_flos': 4.357909859003597e+16, 'train_loss': 1.0628282267252604, 'epoch': 1.0})"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"trainer.model.save_pretrained(\"./phi2_finetuned_subjective/final_model\")","metadata":{"id":"MLMlfccP0Ur-","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T17:16:46.248969Z","iopub.execute_input":"2024-11-17T17:16:46.249302Z","iopub.status.idle":"2024-11-17T17:16:46.755777Z","shell.execute_reply.started":"2024-11-17T17:16:46.249267Z","shell.execute_reply":"2024-11-17T17:16:46.754807Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from peft import PeftModel\nf_model = PeftModel.from_pretrained(model,'/kaggle/working/phi2_finetuned_subjective/final_model')\nf_model = f_model.merge_and_unload()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T17:16:46.757108Z","iopub.execute_input":"2024-11-17T17:16:46.757441Z","iopub.status.idle":"2024-11-17T17:16:50.188682Z","shell.execute_reply.started":"2024-11-17T17:16:46.757406Z","shell.execute_reply":"2024-11-17T17:16:50.187644Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:336: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"print(test_dataset[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T17:16:50.190015Z","iopub.execute_input":"2024-11-17T17:16:50.190330Z","iopub.status.idle":"2024-11-17T17:16:50.199861Z","shell.execute_reply.started":"2024-11-17T17:16:50.190296Z","shell.execute_reply":"2024-11-17T17:16:50.197631Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"{'qtype': 'symptoms', 'Question': 'What are the symptoms of Carbamoyl phosphate synthetase 1 deficiency ?', 'Answer': 'What are the signs and symptoms of Carbamoyl phosphate synthetase 1 deficiency? The Human Phenotype Ontology provides the following list of signs and symptoms for Carbamoyl phosphate synthetase 1 deficiency. If the information is available, the table below includes how often the symptom is seen in people with this condition. You can use the MedlinePlus Medical Dictionary to look up the definitions for these medical terms. Signs and Symptoms Approximate number of patients (when available) Aminoaciduria 90% Hyperammonemia 90% Muscular hypotonia 90% Respiratory insufficiency 90% Seizures 90% Stroke 5% Ataxia - Autosomal recessive inheritance - Cerebral edema - Coma - Episodic ammonia intoxication - Failure to thrive - Hypoargininemia - Intellectual disability - Irritability - Lethargy - Low plasma citrulline - Protein avoidance - Respiratory alkalosis - Vomiting - The Human Phenotype Ontology (HPO) has collected information on how often a sign or symptom occurs in a condition. Much of this information comes from Orphanet, a European rare disease database. The frequency of a sign or symptom is usually listed as a rough estimate of the percentage of patients who have that feature. The frequency may also be listed as a fraction. The first number of the fraction is how many people had the symptom, and the second number is the total number of people who were examined in one study. For example, a frequency of 25/25 means that in a study of 25 people all patients were found to have that symptom. Because these frequencies are based on a specific study, the fractions may be different if another group of patients are examined. Sometimes, no information on frequency is available. In these cases, the sign or symptom may be rare or common.'}\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from tqdm import tqdm\n\nf_model.eval()  # Set the model to evaluation mode\npredictions = []\nall_preds = []  # Ensure this is defined for appending predictions\ndevice = next(f_model.parameters()).device  # Ensure device compatibility\nbatch_size = 1  # Set a batch size if needed\n\nfor i, question in enumerate(tqdm(test_dataset, desc=\"Generating predictions\", unit=\"question\")):\n    prompt = question['Question']\n\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n    outputs = model.generate(inputs['input_ids'], max_length=70)\n    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    predictions.append(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T17:20:23.117048Z","iopub.execute_input":"2024-11-17T17:20:23.118039Z","iopub.status.idle":"2024-11-17T22:28:52.779054Z","shell.execute_reply.started":"2024-11-17T17:20:23.117993Z","shell.execute_reply":"2024-11-17T22:28:52.777844Z"},"_kg_hide-output":true,"_kg_hide-input":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"Generating predictions:   0%|          | 0/3282 [00:00<?, ?question/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 1/3282 [00:05<4:55:23,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 2/3282 [00:10<4:51:36,  5.33s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 3/3282 [00:16<5:07:08,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 4/3282 [00:22<5:14:37,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 5/3282 [00:28<5:15:08,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 6/3282 [00:34<5:15:30,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 7/3282 [00:39<5:12:07,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 8/3282 [00:45<5:16:32,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 9/3282 [00:51<5:12:35,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 10/3282 [00:57<5:15:31,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 11/3282 [01:02<5:10:16,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 12/3282 [01:08<5:13:47,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 13/3282 [01:14<5:09:03,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 14/3282 [01:20<5:14:54,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 15/3282 [01:26<5:16:50,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 16/3282 [01:32<5:18:52,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 17/3282 [01:37<5:08:15,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 18/3282 [01:42<5:09:44,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 19/3282 [01:48<5:04:56,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 20/3282 [01:54<5:09:51,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 21/3282 [01:59<5:00:24,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 22/3282 [02:04<4:53:52,  5.41s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 23/3282 [02:10<5:03:00,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 24/3282 [02:16<5:08:24,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 25/3282 [02:21<5:05:02,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 26/3282 [02:27<5:12:00,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 27/3282 [02:33<5:10:36,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 28/3282 [02:39<5:14:27,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 29/3282 [02:44<5:03:19,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 30/3282 [02:49<4:49:42,  5.35s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 31/3282 [02:54<4:51:56,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 32/3282 [03:00<5:01:10,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 33/3282 [03:06<4:56:56,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 34/3282 [03:12<5:01:28,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 35/3282 [03:17<4:54:08,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 36/3282 [03:22<4:56:25,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 37/3282 [03:27<4:50:38,  5.37s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 38/3282 [03:33<4:56:52,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 39/3282 [03:39<4:59:43,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 40/3282 [03:44<4:51:24,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 41/3282 [03:49<4:45:21,  5.28s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|▏         | 42/3282 [03:54<4:44:04,  5.26s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|▏         | 43/3282 [03:59<4:44:37,  5.27s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|▏         | 44/3282 [04:05<4:46:27,  5.31s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|▏         | 45/3282 [04:11<5:02:22,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|▏         | 46/3282 [04:17<5:08:01,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|▏         | 47/3282 [04:23<5:08:37,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|▏         | 48/3282 [04:28<5:04:27,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|▏         | 49/3282 [04:34<5:13:37,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 50/3282 [04:40<5:12:33,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 51/3282 [04:46<5:19:10,  5.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 52/3282 [04:52<5:16:20,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 53/3282 [04:58<5:14:14,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 54/3282 [05:04<5:15:52,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 55/3282 [05:10<5:17:04,  5.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 56/3282 [05:15<5:11:39,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 57/3282 [05:21<5:05:01,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 58/3282 [05:26<5:00:21,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 59/3282 [05:32<5:05:24,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 60/3282 [05:38<5:10:55,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 61/3282 [05:44<5:13:19,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 62/3282 [05:50<5:14:23,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 63/3282 [05:56<5:15:46,  5.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 64/3282 [06:02<5:10:29,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 65/3282 [06:06<4:56:41,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 66/3282 [06:12<5:00:09,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 67/3282 [06:18<5:05:41,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 68/3282 [06:24<5:08:55,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 69/3282 [06:30<5:05:45,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 70/3282 [06:36<5:08:55,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 71/3282 [06:41<5:08:37,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 72/3282 [06:47<5:05:24,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 73/3282 [06:53<5:06:15,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 74/3282 [06:58<5:05:01,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 75/3282 [07:04<5:08:58,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 76/3282 [07:10<5:13:05,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 77/3282 [07:16<5:13:51,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 78/3282 [07:22<5:14:13,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 79/3282 [07:28<5:17:15,  5.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 80/3282 [07:34<5:14:16,  5.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 81/3282 [07:39<5:07:42,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 82/3282 [07:45<5:06:03,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 83/3282 [07:51<5:01:51,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 84/3282 [07:56<5:03:24,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 85/3282 [08:02<5:07:24,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 86/3282 [08:08<4:59:44,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 87/3282 [08:13<4:53:05,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 88/3282 [08:19<5:02:58,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 89/3282 [08:24<4:59:41,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 90/3282 [08:30<4:55:57,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 91/3282 [08:36<5:06:18,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 92/3282 [08:42<5:06:10,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 93/3282 [08:47<5:03:14,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 94/3282 [08:53<5:06:25,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 95/3282 [08:59<5:08:38,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 96/3282 [09:05<5:03:23,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 97/3282 [09:11<5:07:04,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 98/3282 [09:16<4:54:55,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 99/3282 [09:21<4:43:33,  5.35s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 100/3282 [09:26<4:47:03,  5.41s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 101/3282 [09:31<4:45:06,  5.38s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 102/3282 [09:37<4:48:14,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 103/3282 [09:43<4:53:06,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 104/3282 [09:49<4:59:36,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 105/3282 [09:55<5:03:29,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 106/3282 [10:00<5:00:47,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 107/3282 [10:06<4:56:10,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 108/3282 [10:11<5:00:59,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 109/3282 [10:17<5:01:53,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 110/3282 [10:23<4:59:39,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 111/3282 [10:29<5:00:55,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 112/3282 [10:34<4:54:35,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 113/3282 [10:39<4:50:16,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 114/3282 [10:45<4:54:22,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▎         | 115/3282 [10:50<4:51:17,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▎         | 116/3282 [10:56<4:55:08,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▎         | 117/3282 [11:02<5:00:05,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▎         | 118/3282 [11:08<5:07:04,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▎         | 119/3282 [11:14<5:03:09,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▎         | 120/3282 [11:19<5:03:11,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▎         | 121/3282 [11:25<4:58:49,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▎         | 122/3282 [11:31<4:57:11,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▎         | 123/3282 [11:36<4:50:22,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 124/3282 [11:42<4:57:17,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 125/3282 [11:47<4:51:37,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 126/3282 [11:52<4:49:11,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 127/3282 [11:58<4:56:26,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 128/3282 [12:04<4:55:18,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 129/3282 [12:09<4:40:23,  5.34s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 130/3282 [12:14<4:44:00,  5.41s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 131/3282 [12:20<4:43:35,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 132/3282 [12:26<4:53:43,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 133/3282 [12:31<4:54:48,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 134/3282 [12:37<4:55:27,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 135/3282 [12:42<4:52:59,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 136/3282 [12:48<4:58:44,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 137/3282 [12:54<4:59:31,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 138/3282 [13:00<5:04:36,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 139/3282 [13:06<5:02:12,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 140/3282 [13:12<5:01:52,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 141/3282 [13:17<5:00:05,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 142/3282 [13:22<4:48:48,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 143/3282 [13:27<4:41:01,  5.37s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 144/3282 [13:33<4:38:15,  5.32s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 145/3282 [13:38<4:47:21,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 146/3282 [13:44<4:54:31,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 147/3282 [13:50<4:58:35,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 148/3282 [13:56<4:59:03,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 149/3282 [14:02<4:57:53,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 150/3282 [14:07<4:57:04,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 151/3282 [14:12<4:40:52,  5.38s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 152/3282 [14:17<4:40:50,  5.38s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 153/3282 [14:23<4:51:09,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 154/3282 [14:29<4:45:05,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 155/3282 [14:34<4:48:06,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 156/3282 [14:40<4:44:12,  5.45s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 157/3282 [14:45<4:47:26,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 158/3282 [14:51<4:51:01,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 159/3282 [14:56<4:49:09,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 160/3282 [15:02<4:49:15,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 161/3282 [15:07<4:43:42,  5.45s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 162/3282 [15:13<4:45:20,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 163/3282 [15:19<4:52:29,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 164/3282 [15:24<4:52:56,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 165/3282 [15:30<4:59:07,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 166/3282 [15:36<5:02:06,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 167/3282 [15:40<4:34:01,  5.28s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 168/3282 [15:46<4:38:29,  5.37s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 169/3282 [15:52<4:40:18,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 170/3282 [15:57<4:42:54,  5.45s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 171/3282 [16:02<4:36:05,  5.32s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 172/3282 [16:07<4:31:23,  5.24s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 173/3282 [16:12<4:32:13,  5.25s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 174/3282 [16:18<4:32:54,  5.27s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 175/3282 [16:23<4:34:55,  5.31s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 176/3282 [16:28<4:33:18,  5.28s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 177/3282 [16:34<4:37:52,  5.37s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 178/3282 [16:39<4:32:27,  5.27s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 179/3282 [16:45<4:38:39,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 180/3282 [16:51<4:47:17,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 181/3282 [16:56<4:44:51,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 182/3282 [17:02<4:47:16,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 183/3282 [17:07<4:47:24,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 184/3282 [17:13<4:50:24,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 185/3282 [17:19<4:55:30,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 186/3282 [17:24<4:47:43,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 187/3282 [17:28<4:27:57,  5.19s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 188/3282 [17:34<4:33:55,  5.31s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 189/3282 [17:39<4:30:50,  5.25s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 190/3282 [17:45<4:35:51,  5.35s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 191/3282 [17:50<4:37:53,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 192/3282 [17:56<4:40:55,  5.45s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 193/3282 [18:01<4:42:46,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 194/3282 [18:07<4:43:59,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 195/3282 [18:13<4:47:45,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 196/3282 [18:18<4:41:45,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 197/3282 [18:24<4:48:31,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 198/3282 [18:30<4:53:04,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 199/3282 [18:36<4:52:21,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 200/3282 [18:41<4:55:43,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 201/3282 [18:46<4:38:49,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 202/3282 [18:52<4:43:53,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 203/3282 [18:58<4:45:58,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 204/3282 [19:03<4:45:57,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 205/3282 [19:09<4:53:10,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▋         | 206/3282 [19:15<4:49:31,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▋         | 207/3282 [19:20<4:51:10,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▋         | 208/3282 [19:26<4:45:08,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▋         | 209/3282 [19:32<4:50:20,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▋         | 210/3282 [19:38<4:53:54,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▋         | 211/3282 [19:43<4:49:51,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▋         | 212/3282 [19:48<4:38:32,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▋         | 213/3282 [19:54<4:48:39,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 214/3282 [20:00<4:54:45,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 215/3282 [20:05<4:44:45,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 216/3282 [20:11<4:49:48,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 217/3282 [20:17<4:53:12,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 218/3282 [20:23<4:57:40,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 219/3282 [20:29<4:55:02,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 220/3282 [20:34<4:41:57,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 221/3282 [20:40<4:49:45,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 222/3282 [20:45<4:48:03,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 223/3282 [20:51<4:49:38,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 224/3282 [20:56<4:42:14,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 225/3282 [21:02<4:42:45,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 226/3282 [21:07<4:38:57,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 227/3282 [21:13<4:40:24,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 228/3282 [21:19<4:47:08,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 229/3282 [21:25<4:51:48,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 230/3282 [21:30<4:46:26,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 231/3282 [21:35<4:40:11,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 232/3282 [21:41<4:41:09,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 233/3282 [21:46<4:29:26,  5.30s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 234/3282 [21:52<4:39:17,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 235/3282 [21:56<4:23:48,  5.19s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 236/3282 [22:02<4:30:51,  5.34s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 237/3282 [22:07<4:35:57,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 238/3282 [22:13<4:37:52,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 239/3282 [22:19<4:44:14,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 240/3282 [22:24<4:42:27,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 241/3282 [22:30<4:38:18,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 242/3282 [22:36<4:44:37,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 243/3282 [22:41<4:39:47,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 244/3282 [22:47<4:48:57,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 245/3282 [22:52<4:45:23,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 246/3282 [22:58<4:49:24,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 247/3282 [23:04<4:52:16,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 248/3282 [23:10<4:49:08,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 249/3282 [23:16<4:48:20,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 250/3282 [23:21<4:48:57,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 251/3282 [23:27<4:49:34,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 252/3282 [23:32<4:40:11,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 253/3282 [23:38<4:47:44,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 254/3282 [23:44<4:50:58,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 255/3282 [23:50<4:48:03,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 256/3282 [23:55<4:37:39,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 257/3282 [24:00<4:38:48,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 258/3282 [24:06<4:44:31,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 259/3282 [24:12<4:49:09,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 260/3282 [24:18<4:51:40,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 261/3282 [24:24<4:55:31,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 262/3282 [24:30<4:49:43,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 263/3282 [24:35<4:47:02,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 264/3282 [24:41<4:44:58,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 265/3282 [24:46<4:45:04,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 266/3282 [24:52<4:48:37,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 267/3282 [24:58<4:44:37,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 268/3282 [25:03<4:43:16,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 269/3282 [25:09<4:45:01,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 270/3282 [25:15<4:46:06,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 271/3282 [25:21<4:43:59,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 272/3282 [25:26<4:39:48,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 273/3282 [25:32<4:41:02,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 274/3282 [25:37<4:38:59,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 275/3282 [25:42<4:34:55,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 276/3282 [25:47<4:23:59,  5.27s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 277/3282 [25:53<4:29:49,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 278/3282 [25:59<4:35:13,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▊         | 279/3282 [26:04<4:38:54,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▊         | 280/3282 [26:10<4:41:34,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▊         | 281/3282 [26:16<4:41:59,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▊         | 282/3282 [26:21<4:35:19,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▊         | 283/3282 [26:27<4:37:38,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▊         | 284/3282 [26:33<4:44:47,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▊         | 285/3282 [26:39<4:48:22,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▊         | 286/3282 [26:44<4:50:51,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▊         | 287/3282 [26:50<4:49:37,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 288/3282 [26:56<4:51:48,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 289/3282 [27:02<4:48:53,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 290/3282 [27:07<4:44:09,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 291/3282 [27:13<4:43:28,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 292/3282 [27:19<4:41:36,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 293/3282 [27:24<4:45:24,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 294/3282 [27:30<4:36:13,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 295/3282 [27:35<4:38:00,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 296/3282 [27:40<4:29:35,  5.42s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 297/3282 [27:44<4:10:13,  5.03s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 298/3282 [27:50<4:24:00,  5.31s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 299/3282 [27:56<4:33:10,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 300/3282 [28:02<4:39:57,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 301/3282 [28:08<4:37:49,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 302/3282 [28:13<4:33:23,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 303/3282 [28:19<4:35:44,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 304/3282 [28:25<4:43:12,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 305/3282 [28:30<4:37:03,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 306/3282 [28:35<4:31:30,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 307/3282 [28:41<4:31:42,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 308/3282 [28:45<4:19:39,  5.24s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 309/3282 [28:52<4:31:31,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 310/3282 [28:57<4:28:55,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 311/3282 [29:03<4:36:51,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 312/3282 [29:09<4:42:14,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 313/3282 [29:15<4:43:00,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 314/3282 [29:20<4:43:24,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 315/3282 [29:26<4:39:38,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 316/3282 [29:31<4:37:07,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 317/3282 [29:37<4:41:28,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 318/3282 [29:43<4:45:08,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 319/3282 [29:48<4:36:44,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 320/3282 [29:54<4:34:55,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 321/3282 [29:59<4:36:14,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 322/3282 [30:06<4:45:14,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 323/3282 [30:11<4:43:13,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 324/3282 [30:17<4:48:35,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 325/3282 [30:23<4:51:19,  5.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 326/3282 [30:29<4:51:47,  5.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 327/3282 [30:34<4:38:37,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 328/3282 [30:40<4:42:50,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 329/3282 [30:46<4:37:23,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 330/3282 [30:52<4:43:11,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 331/3282 [30:58<4:45:51,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 332/3282 [31:03<4:39:30,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 333/3282 [31:09<4:44:41,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 334/3282 [31:15<4:42:41,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 335/3282 [31:21<4:41:10,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 336/3282 [31:26<4:44:22,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 337/3282 [31:32<4:38:16,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 338/3282 [31:37<4:32:42,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 339/3282 [31:43<4:39:39,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 340/3282 [31:48<4:30:49,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 341/3282 [31:54<4:36:09,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 342/3282 [32:00<4:41:49,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 343/3282 [32:06<4:44:41,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 344/3282 [32:11<4:36:53,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 345/3282 [32:17<4:31:27,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 346/3282 [32:23<4:36:35,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 347/3282 [32:28<4:35:06,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 348/3282 [32:34<4:39:47,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 349/3282 [32:40<4:46:56,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 350/3282 [32:46<4:37:08,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 351/3282 [32:51<4:28:53,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 352/3282 [32:57<4:35:26,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 353/3282 [33:02<4:28:54,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 354/3282 [33:07<4:27:02,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 355/3282 [33:13<4:24:23,  5.42s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 356/3282 [33:18<4:26:34,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 357/3282 [33:24<4:32:52,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 358/3282 [33:30<4:37:10,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 359/3282 [33:36<4:40:15,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 360/3282 [33:41<4:36:01,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 361/3282 [33:47<4:30:33,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 362/3282 [33:52<4:33:23,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 363/3282 [33:58<4:35:24,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 364/3282 [34:04<4:31:20,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 365/3282 [34:09<4:36:39,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 366/3282 [34:15<4:29:35,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 367/3282 [34:20<4:29:53,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 368/3282 [34:27<4:40:36,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 369/3282 [34:32<4:40:10,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█▏        | 370/3282 [34:38<4:42:41,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█▏        | 371/3282 [34:43<4:27:06,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█▏        | 372/3282 [34:48<4:18:43,  5.33s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█▏        | 373/3282 [34:53<4:18:13,  5.33s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█▏        | 374/3282 [34:59<4:21:46,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█▏        | 375/3282 [35:04<4:22:49,  5.42s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█▏        | 376/3282 [35:10<4:30:31,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█▏        | 377/3282 [35:16<4:30:25,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 378/3282 [35:21<4:30:07,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 379/3282 [35:28<4:39:13,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 380/3282 [35:33<4:34:59,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 381/3282 [35:39<4:30:37,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 382/3282 [35:44<4:30:16,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 383/3282 [35:50<4:31:20,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 384/3282 [35:56<4:33:14,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 385/3282 [36:01<4:37:25,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 386/3282 [36:07<4:36:12,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 387/3282 [36:13<4:35:14,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 388/3282 [36:19<4:40:04,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 389/3282 [36:24<4:36:39,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 390/3282 [36:30<4:31:33,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 391/3282 [36:35<4:24:04,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 392/3282 [36:41<4:30:10,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 393/3282 [36:47<4:30:51,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 394/3282 [36:52<4:27:29,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 395/3282 [36:58<4:29:09,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 396/3282 [37:03<4:28:46,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 397/3282 [37:08<4:16:42,  5.34s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 398/3282 [37:14<4:22:37,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 399/3282 [37:19<4:25:23,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 400/3282 [37:25<4:26:04,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 401/3282 [37:31<4:31:57,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 402/3282 [37:36<4:25:17,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 403/3282 [37:42<4:28:43,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 404/3282 [37:48<4:29:35,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 405/3282 [37:53<4:28:48,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 406/3282 [37:59<4:28:15,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 407/3282 [38:04<4:26:29,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 408/3282 [38:09<4:10:49,  5.24s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 409/3282 [38:14<4:15:36,  5.34s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 410/3282 [38:20<4:21:20,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 411/3282 [38:26<4:32:05,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 412/3282 [38:32<4:37:04,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 413/3282 [38:38<4:41:45,  5.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 414/3282 [38:44<4:33:08,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 415/3282 [38:49<4:30:56,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 416/3282 [38:55<4:34:14,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 417/3282 [39:01<4:33:02,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 418/3282 [39:07<4:36:17,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 419/3282 [39:13<4:37:45,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 420/3282 [39:18<4:32:41,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 421/3282 [39:24<4:31:45,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 422/3282 [39:30<4:36:40,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 423/3282 [39:35<4:25:26,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 424/3282 [39:41<4:33:12,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 425/3282 [39:46<4:29:21,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 426/3282 [39:52<4:29:20,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 427/3282 [39:58<4:30:35,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 428/3282 [40:04<4:34:22,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 429/3282 [40:10<4:36:13,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 430/3282 [40:15<4:35:20,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 431/3282 [40:21<4:36:50,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 432/3282 [40:27<4:34:27,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 433/3282 [40:33<4:36:56,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 434/3282 [40:39<4:33:09,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 435/3282 [40:44<4:29:11,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 436/3282 [40:50<4:27:38,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 437/3282 [40:55<4:25:23,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 438/3282 [41:01<4:23:43,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 439/3282 [41:07<4:32:53,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 440/3282 [41:13<4:32:46,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 441/3282 [41:17<4:11:57,  5.32s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 442/3282 [41:23<4:18:10,  5.45s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 443/3282 [41:28<4:22:19,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▎        | 444/3282 [41:34<4:27:32,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▎        | 445/3282 [41:40<4:28:53,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▎        | 446/3282 [41:45<4:24:39,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▎        | 447/3282 [41:51<4:29:40,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▎        | 448/3282 [41:57<4:29:00,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▎        | 449/3282 [42:03<4:29:44,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▎        | 450/3282 [42:09<4:37:57,  5.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▎        | 451/3282 [42:15<4:34:47,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 452/3282 [42:20<4:28:34,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 453/3282 [42:26<4:25:35,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 454/3282 [42:32<4:29:32,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 455/3282 [42:38<4:32:16,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 456/3282 [42:43<4:30:39,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 457/3282 [42:49<4:32:56,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 458/3282 [42:55<4:32:14,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 459/3282 [43:00<4:24:01,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 460/3282 [43:06<4:28:55,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 461/3282 [43:12<4:29:31,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 462/3282 [43:17<4:19:32,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 463/3282 [43:23<4:26:50,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 464/3282 [43:28<4:25:17,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 465/3282 [43:34<4:19:02,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 466/3282 [43:39<4:12:05,  5.37s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 467/3282 [43:45<4:21:28,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 468/3282 [43:51<4:24:14,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 469/3282 [43:56<4:23:18,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 470/3282 [44:02<4:29:12,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 471/3282 [44:08<4:25:25,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 472/3282 [44:13<4:17:44,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 473/3282 [44:18<4:18:36,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 474/3282 [44:24<4:24:31,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 475/3282 [44:30<4:32:12,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 476/3282 [44:36<4:31:12,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 477/3282 [44:42<4:30:17,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 478/3282 [44:47<4:24:35,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 479/3282 [44:53<4:23:10,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 480/3282 [44:59<4:24:43,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 481/3282 [45:04<4:23:09,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 482/3282 [45:10<4:27:25,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 483/3282 [45:16<4:30:31,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 484/3282 [45:22<4:28:26,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 485/3282 [45:28<4:30:17,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 486/3282 [45:33<4:23:02,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 487/3282 [45:38<4:19:21,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 488/3282 [45:44<4:24:34,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 489/3282 [45:50<4:22:56,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 490/3282 [45:55<4:16:38,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 491/3282 [46:01<4:17:26,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 492/3282 [46:06<4:07:41,  5.33s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 493/3282 [46:11<4:08:20,  5.34s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 494/3282 [46:17<4:19:16,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 495/3282 [46:22<4:15:19,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 496/3282 [46:28<4:18:51,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 497/3282 [46:34<4:23:23,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 498/3282 [46:39<4:20:36,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 499/3282 [46:46<4:28:53,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 500/3282 [46:52<4:30:23,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 501/3282 [46:57<4:29:15,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 502/3282 [47:03<4:27:10,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 503/3282 [47:09<4:24:25,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 504/3282 [47:14<4:25:05,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 505/3282 [47:20<4:23:00,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 506/3282 [47:26<4:28:00,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 507/3282 [47:32<4:30:11,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 508/3282 [47:38<4:35:21,  5.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 509/3282 [47:44<4:34:46,  5.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 510/3282 [47:50<4:30:50,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 511/3282 [47:55<4:24:15,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 512/3282 [48:01<4:22:07,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 513/3282 [48:07<4:25:18,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 514/3282 [48:13<4:27:23,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 515/3282 [48:18<4:28:49,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 516/3282 [48:24<4:30:38,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 517/3282 [48:30<4:23:53,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 518/3282 [48:36<4:24:18,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 519/3282 [48:41<4:23:17,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 520/3282 [48:47<4:26:32,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 521/3282 [48:53<4:22:13,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 522/3282 [48:59<4:25:46,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 523/3282 [49:05<4:28:06,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 524/3282 [49:10<4:25:48,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 525/3282 [49:16<4:24:13,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 526/3282 [49:22<4:24:16,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 527/3282 [49:27<4:21:47,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 528/3282 [49:33<4:18:43,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 529/3282 [49:38<4:15:19,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 530/3282 [49:44<4:20:04,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 531/3282 [49:49<4:16:08,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 532/3282 [49:55<4:21:13,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 533/3282 [50:01<4:17:02,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▋        | 534/3282 [50:07<4:17:42,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▋        | 535/3282 [50:12<4:22:01,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▋        | 536/3282 [50:18<4:19:56,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▋        | 537/3282 [50:24<4:26:02,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▋        | 538/3282 [50:30<4:27:19,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▋        | 539/3282 [50:36<4:23:34,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▋        | 540/3282 [50:41<4:19:35,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▋        | 541/3282 [50:47<4:20:38,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 542/3282 [50:53<4:26:16,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 543/3282 [50:59<4:27:18,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 544/3282 [51:05<4:24:42,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 545/3282 [51:11<4:28:02,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 546/3282 [51:17<4:29:04,  5.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 547/3282 [51:23<4:29:46,  5.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 548/3282 [51:29<4:29:38,  5.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 549/3282 [51:33<4:12:34,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 550/3282 [51:39<4:10:21,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 551/3282 [51:44<4:13:56,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 552/3282 [51:50<4:11:18,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 553/3282 [51:56<4:16:44,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 554/3282 [52:02<4:20:52,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 555/3282 [52:08<4:23:12,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 556/3282 [52:13<4:18:48,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 557/3282 [52:19<4:17:09,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 558/3282 [52:25<4:23:27,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 559/3282 [52:31<4:28:57,  5.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 560/3282 [52:37<4:28:49,  5.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 561/3282 [52:43<4:31:27,  5.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 562/3282 [52:48<4:23:18,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 563/3282 [52:53<4:12:37,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 564/3282 [52:59<4:10:02,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 565/3282 [53:05<4:15:52,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 566/3282 [53:11<4:17:09,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 567/3282 [53:15<4:06:53,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 568/3282 [53:21<4:10:42,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 569/3282 [53:27<4:12:12,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 570/3282 [53:33<4:14:22,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 571/3282 [53:38<4:13:31,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 572/3282 [53:44<4:11:40,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 573/3282 [53:49<4:07:47,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 574/3282 [53:55<4:13:23,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 575/3282 [54:00<4:10:11,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 576/3282 [54:06<4:06:42,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 577/3282 [54:11<4:08:07,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 578/3282 [54:17<4:11:20,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 579/3282 [54:22<4:01:23,  5.36s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 580/3282 [54:28<4:09:12,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 581/3282 [54:33<4:10:47,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 582/3282 [54:39<4:18:06,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 583/3282 [54:44<4:08:38,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 584/3282 [54:50<4:03:01,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 585/3282 [54:56<4:10:21,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 586/3282 [55:01<4:12:46,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 587/3282 [55:06<4:05:53,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 588/3282 [55:12<4:03:21,  5.42s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 589/3282 [55:18<4:09:57,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 590/3282 [55:24<4:15:02,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 591/3282 [55:29<4:07:18,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 592/3282 [55:34<4:08:07,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 593/3282 [55:40<4:13:41,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 594/3282 [55:46<4:17:01,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 595/3282 [55:52<4:14:46,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 596/3282 [55:57<4:09:27,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 597/3282 [56:03<4:11:14,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 598/3282 [56:09<4:15:43,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 599/3282 [56:14<4:11:23,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 600/3282 [56:20<4:17:10,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 601/3282 [56:26<4:19:14,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 602/3282 [56:32<4:16:10,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 603/3282 [56:37<4:11:33,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 604/3282 [56:43<4:09:31,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 605/3282 [56:48<4:13:57,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 606/3282 [56:54<4:07:29,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 607/3282 [57:00<4:13:38,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▊        | 608/3282 [57:06<4:19:29,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▊        | 609/3282 [57:12<4:21:19,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▊        | 610/3282 [57:18<4:24:45,  5.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▊        | 611/3282 [57:23<4:13:52,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▊        | 612/3282 [57:29<4:13:29,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▊        | 613/3282 [57:35<4:14:18,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▊        | 614/3282 [57:40<4:17:26,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▊        | 615/3282 [57:46<4:17:01,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 616/3282 [57:52<4:15:31,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 617/3282 [57:58<4:15:37,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 618/3282 [58:02<4:02:18,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 619/3282 [58:08<4:01:22,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 620/3282 [58:13<3:59:29,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 621/3282 [58:19<3:59:27,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 622/3282 [58:23<3:49:57,  5.19s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 623/3282 [58:29<3:56:18,  5.33s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 624/3282 [58:35<4:08:00,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 625/3282 [58:40<3:55:36,  5.32s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 626/3282 [58:45<3:58:56,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 627/3282 [58:51<3:56:21,  5.34s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 628/3282 [58:56<3:52:20,  5.25s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 629/3282 [59:02<4:01:35,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 630/3282 [59:07<4:00:34,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 631/3282 [59:13<4:07:23,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 632/3282 [59:19<4:07:01,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 633/3282 [59:24<4:04:25,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 634/3282 [59:29<4:03:48,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 635/3282 [59:35<4:06:52,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 636/3282 [59:41<4:09:00,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 637/3282 [59:47<4:14:17,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 638/3282 [59:52<4:05:38,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 639/3282 [59:58<4:05:42,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 640/3282 [1:00:03<3:57:12,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 641/3282 [1:00:09<4:05:51,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 642/3282 [1:00:14<4:02:01,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 643/3282 [1:00:20<4:05:24,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 644/3282 [1:00:26<4:11:26,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 645/3282 [1:00:30<3:57:34,  5.41s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 646/3282 [1:00:36<4:04:40,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 647/3282 [1:00:42<4:09:35,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 648/3282 [1:00:48<4:04:20,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 649/3282 [1:00:54<4:09:25,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 650/3282 [1:00:59<4:10:17,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 651/3282 [1:01:05<4:13:30,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 652/3282 [1:01:11<4:10:41,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 653/3282 [1:01:17<4:09:52,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 654/3282 [1:01:23<4:15:14,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 655/3282 [1:01:27<4:01:06,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 656/3282 [1:01:33<4:03:07,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 657/3282 [1:01:39<4:02:01,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 658/3282 [1:01:45<4:07:29,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 659/3282 [1:01:51<4:13:26,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 660/3282 [1:01:56<4:00:57,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 661/3282 [1:02:01<3:55:33,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 662/3282 [1:02:06<3:57:55,  5.45s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 663/3282 [1:02:12<4:01:50,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 664/3282 [1:02:17<4:00:54,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 665/3282 [1:02:23<4:06:04,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 666/3282 [1:02:29<4:07:30,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 667/3282 [1:02:35<4:04:57,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 668/3282 [1:02:41<4:09:20,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 669/3282 [1:02:46<4:07:19,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 670/3282 [1:02:51<3:59:57,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 671/3282 [1:02:57<3:55:59,  5.42s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 672/3282 [1:03:02<3:57:55,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 673/3282 [1:03:07<3:57:04,  5.45s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 674/3282 [1:03:13<3:58:45,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 675/3282 [1:03:19<4:04:42,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 676/3282 [1:03:25<4:08:13,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 677/3282 [1:03:31<4:10:43,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 678/3282 [1:03:37<4:13:02,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 679/3282 [1:03:42<4:03:45,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 680/3282 [1:03:48<4:05:36,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 681/3282 [1:03:53<4:04:24,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 682/3282 [1:03:58<3:56:24,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 683/3282 [1:04:05<4:07:20,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 684/3282 [1:04:10<4:04:24,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 685/3282 [1:04:16<4:04:42,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 686/3282 [1:04:21<4:01:11,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 687/3282 [1:04:27<4:05:32,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 688/3282 [1:04:33<4:10:20,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 689/3282 [1:04:39<4:13:38,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 690/3282 [1:04:45<4:09:51,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 691/3282 [1:04:51<4:12:07,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 692/3282 [1:04:57<4:10:57,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 693/3282 [1:05:02<4:12:08,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 694/3282 [1:05:08<4:02:45,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 695/3282 [1:05:13<3:58:32,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 696/3282 [1:05:19<4:04:03,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 697/3282 [1:05:24<3:56:57,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██▏       | 698/3282 [1:05:30<4:03:57,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██▏       | 699/3282 [1:05:36<4:07:08,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██▏       | 700/3282 [1:05:41<4:02:33,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██▏       | 701/3282 [1:05:47<4:06:46,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██▏       | 702/3282 [1:05:53<4:05:49,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██▏       | 703/3282 [1:05:59<4:08:13,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██▏       | 704/3282 [1:06:04<3:56:16,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██▏       | 705/3282 [1:06:09<3:59:33,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 706/3282 [1:06:15<3:59:32,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 707/3282 [1:06:21<3:59:30,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 708/3282 [1:06:26<3:57:02,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 709/3282 [1:06:32<4:03:39,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 710/3282 [1:06:37<3:59:58,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 711/3282 [1:06:43<3:58:33,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 712/3282 [1:06:49<3:59:51,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 713/3282 [1:06:55<4:05:28,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 714/3282 [1:07:00<4:03:21,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 715/3282 [1:07:06<4:00:44,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 716/3282 [1:07:12<4:04:22,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 717/3282 [1:07:18<4:07:25,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 718/3282 [1:07:23<4:02:19,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 719/3282 [1:07:29<4:02:21,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 720/3282 [1:07:35<4:05:23,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 721/3282 [1:07:40<4:04:16,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 722/3282 [1:07:46<4:04:40,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 723/3282 [1:07:51<3:58:05,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 724/3282 [1:07:56<3:52:10,  5.45s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 725/3282 [1:08:02<3:51:31,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 726/3282 [1:08:07<3:49:49,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 727/3282 [1:08:13<3:59:10,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 728/3282 [1:08:19<4:03:35,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 729/3282 [1:08:25<4:08:51,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 730/3282 [1:08:30<3:52:37,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 731/3282 [1:08:36<3:55:06,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 732/3282 [1:08:42<3:59:53,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 733/3282 [1:08:47<3:56:37,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 734/3282 [1:08:53<4:01:29,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 735/3282 [1:08:58<3:59:58,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 736/3282 [1:09:04<4:00:02,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 737/3282 [1:09:10<3:58:50,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 738/3282 [1:09:16<4:05:01,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 739/3282 [1:09:21<4:02:21,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 740/3282 [1:09:27<4:01:44,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 741/3282 [1:09:33<4:08:00,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 742/3282 [1:09:39<4:04:24,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 743/3282 [1:09:45<4:07:45,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 744/3282 [1:09:50<4:01:37,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 745/3282 [1:09:56<3:56:19,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 746/3282 [1:10:02<4:00:19,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 747/3282 [1:10:07<3:56:22,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 748/3282 [1:10:13<4:00:13,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 749/3282 [1:10:18<3:58:36,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 750/3282 [1:10:24<3:58:36,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 751/3282 [1:10:30<3:59:46,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 752/3282 [1:10:36<4:03:06,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 753/3282 [1:10:41<3:59:20,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 754/3282 [1:10:47<3:55:31,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 755/3282 [1:10:52<3:55:13,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 756/3282 [1:10:58<3:53:53,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 757/3282 [1:11:04<3:58:54,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 758/3282 [1:11:09<3:56:19,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 759/3282 [1:11:15<4:00:21,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 760/3282 [1:11:20<3:54:54,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 761/3282 [1:11:26<4:00:39,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 762/3282 [1:11:32<3:56:27,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 763/3282 [1:11:37<3:50:00,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 764/3282 [1:11:42<3:51:09,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 765/3282 [1:11:49<3:57:46,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 766/3282 [1:11:54<3:58:47,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 767/3282 [1:12:00<4:01:22,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 768/3282 [1:12:06<4:05:04,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 769/3282 [1:12:12<4:01:34,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 770/3282 [1:12:18<4:04:55,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 771/3282 [1:12:23<3:54:32,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▎       | 772/3282 [1:12:29<3:58:52,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▎       | 773/3282 [1:12:34<3:55:57,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▎       | 774/3282 [1:12:40<3:59:51,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▎       | 775/3282 [1:12:46<3:58:55,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▎       | 776/3282 [1:12:52<3:58:11,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▎       | 777/3282 [1:12:57<3:54:14,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▎       | 778/3282 [1:13:03<3:58:01,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▎       | 779/3282 [1:13:08<3:51:52,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 780/3282 [1:13:14<4:00:02,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 781/3282 [1:13:20<3:53:14,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 782/3282 [1:13:26<4:00:57,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 783/3282 [1:13:32<4:06:18,  5.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 784/3282 [1:13:38<4:01:06,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 785/3282 [1:13:43<3:53:45,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 786/3282 [1:13:48<3:50:58,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 787/3282 [1:13:54<3:50:01,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 788/3282 [1:13:59<3:50:29,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 789/3282 [1:14:04<3:46:12,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 790/3282 [1:14:10<3:48:59,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 791/3282 [1:14:16<3:50:50,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 792/3282 [1:14:22<3:56:45,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 793/3282 [1:14:27<3:50:31,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 794/3282 [1:14:33<3:53:02,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 795/3282 [1:14:39<3:56:30,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 796/3282 [1:14:45<3:59:28,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 797/3282 [1:14:50<3:53:18,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 798/3282 [1:14:56<3:56:39,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 799/3282 [1:15:01<3:52:21,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 800/3282 [1:15:07<3:53:58,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 801/3282 [1:15:13<3:58:46,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 802/3282 [1:15:19<3:58:22,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 803/3282 [1:15:24<3:51:21,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 804/3282 [1:15:29<3:48:37,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 805/3282 [1:15:35<3:51:25,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 806/3282 [1:15:41<3:51:57,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 807/3282 [1:15:47<3:57:11,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 808/3282 [1:15:53<4:01:41,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 809/3282 [1:15:58<3:56:56,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 810/3282 [1:16:05<4:00:28,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 811/3282 [1:16:11<4:02:51,  5.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 812/3282 [1:16:16<3:58:45,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 813/3282 [1:16:22<3:59:58,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 814/3282 [1:16:28<4:01:19,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 815/3282 [1:16:34<4:05:29,  5.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 816/3282 [1:16:40<3:58:10,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 817/3282 [1:16:45<3:56:28,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 818/3282 [1:16:51<3:58:44,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 819/3282 [1:16:57<3:55:34,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 820/3282 [1:17:02<3:52:12,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 821/3282 [1:17:07<3:45:24,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 822/3282 [1:17:13<3:47:20,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 823/3282 [1:17:19<3:48:36,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 824/3282 [1:17:24<3:49:31,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 825/3282 [1:17:30<3:53:09,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 826/3282 [1:17:36<3:53:46,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 827/3282 [1:17:41<3:48:31,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 828/3282 [1:17:47<3:52:27,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 829/3282 [1:17:53<3:55:13,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 830/3282 [1:17:59<3:50:41,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 831/3282 [1:18:04<3:49:49,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 832/3282 [1:18:10<3:49:02,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 833/3282 [1:18:14<3:37:26,  5.33s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 834/3282 [1:18:20<3:39:13,  5.37s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 835/3282 [1:18:26<3:47:30,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 836/3282 [1:18:32<3:49:36,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 837/3282 [1:18:38<3:53:30,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 838/3282 [1:18:44<3:55:42,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 839/3282 [1:18:48<3:41:52,  5.45s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 840/3282 [1:18:54<3:42:17,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 841/3282 [1:19:00<3:49:23,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 842/3282 [1:19:06<3:54:18,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 843/3282 [1:19:12<3:54:10,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 844/3282 [1:19:16<3:42:54,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 845/3282 [1:19:22<3:46:11,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 846/3282 [1:19:28<3:47:25,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 847/3282 [1:19:33<3:42:38,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 848/3282 [1:19:39<3:45:57,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 849/3282 [1:19:44<3:41:33,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 850/3282 [1:19:50<3:45:12,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 851/3282 [1:19:56<3:51:14,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 852/3282 [1:20:02<3:54:11,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 853/3282 [1:20:07<3:50:35,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 854/3282 [1:20:13<3:54:46,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 855/3282 [1:20:19<3:51:57,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 856/3282 [1:20:24<3:49:59,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 857/3282 [1:20:31<3:54:22,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 858/3282 [1:20:36<3:49:22,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 859/3282 [1:20:42<3:53:46,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 860/3282 [1:20:47<3:46:40,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 861/3282 [1:20:53<3:50:09,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▋       | 862/3282 [1:20:59<3:52:30,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▋       | 863/3282 [1:21:04<3:39:10,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▋       | 864/3282 [1:21:09<3:41:53,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▋       | 865/3282 [1:21:15<3:49:16,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▋       | 866/3282 [1:21:21<3:46:36,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▋       | 867/3282 [1:21:27<3:48:07,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▋       | 868/3282 [1:21:33<3:51:35,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▋       | 869/3282 [1:21:38<3:50:18,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 870/3282 [1:21:44<3:52:56,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 871/3282 [1:21:50<3:48:59,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 872/3282 [1:21:55<3:45:05,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 873/3282 [1:22:01<3:48:36,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 874/3282 [1:22:06<3:41:35,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 875/3282 [1:22:12<3:39:54,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 876/3282 [1:22:17<3:37:35,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 877/3282 [1:22:23<3:40:21,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 878/3282 [1:22:28<3:42:14,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 879/3282 [1:22:33<3:34:48,  5.36s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 880/3282 [1:22:39<3:41:09,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 881/3282 [1:22:44<3:32:50,  5.32s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 882/3282 [1:22:50<3:37:50,  5.45s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 883/3282 [1:22:56<3:43:16,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 884/3282 [1:23:00<3:35:19,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 885/3282 [1:23:06<3:37:28,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 886/3282 [1:23:12<3:40:00,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 887/3282 [1:23:17<3:39:31,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 888/3282 [1:23:23<3:39:11,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 889/3282 [1:23:28<3:41:06,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 890/3282 [1:23:34<3:40:10,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 891/3282 [1:23:40<3:44:40,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 892/3282 [1:23:46<3:47:41,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 893/3282 [1:23:51<3:47:57,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 894/3282 [1:23:57<3:49:59,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 895/3282 [1:24:03<3:46:15,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 896/3282 [1:24:08<3:45:54,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 897/3282 [1:24:14<3:45:36,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 898/3282 [1:24:20<3:46:23,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 899/3282 [1:24:25<3:43:46,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 900/3282 [1:24:31<3:43:59,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 901/3282 [1:24:37<3:50:41,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 902/3282 [1:24:42<3:44:35,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 903/3282 [1:24:48<3:42:26,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 904/3282 [1:24:54<3:48:26,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 905/3282 [1:24:59<3:39:35,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 906/3282 [1:25:05<3:38:46,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 907/3282 [1:25:10<3:38:15,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 908/3282 [1:25:16<3:47:36,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 909/3282 [1:25:22<3:49:56,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 910/3282 [1:25:27<3:41:38,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 911/3282 [1:25:33<3:45:39,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 912/3282 [1:25:39<3:44:58,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 913/3282 [1:25:44<3:34:00,  5.42s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 914/3282 [1:25:49<3:33:33,  5.41s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 915/3282 [1:25:55<3:35:28,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 916/3282 [1:26:01<3:40:40,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 917/3282 [1:26:07<3:45:55,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 918/3282 [1:26:12<3:38:37,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 919/3282 [1:26:18<3:41:12,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 920/3282 [1:26:23<3:36:22,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 921/3282 [1:26:29<3:42:48,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 922/3282 [1:26:35<3:47:20,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 923/3282 [1:26:40<3:42:44,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 924/3282 [1:26:46<3:47:20,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 925/3282 [1:26:52<3:45:51,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 926/3282 [1:26:57<3:40:30,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 927/3282 [1:27:03<3:44:38,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 928/3282 [1:27:09<3:40:43,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 929/3282 [1:27:15<3:46:44,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 930/3282 [1:27:21<3:46:30,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 931/3282 [1:27:26<3:41:56,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 932/3282 [1:27:32<3:46:19,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 933/3282 [1:27:38<3:41:42,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 934/3282 [1:27:43<3:41:39,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 935/3282 [1:27:48<3:36:14,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▊       | 936/3282 [1:27:54<3:35:46,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▊       | 937/3282 [1:28:00<3:38:29,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▊       | 938/3282 [1:28:06<3:42:37,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▊       | 939/3282 [1:28:12<3:47:34,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▊       | 940/3282 [1:28:17<3:46:35,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▊       | 941/3282 [1:28:23<3:40:40,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▊       | 942/3282 [1:28:29<3:43:35,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▊       | 943/3282 [1:28:35<3:46:10,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 944/3282 [1:28:40<3:45:27,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 945/3282 [1:28:46<3:47:18,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 946/3282 [1:28:52<3:48:37,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 947/3282 [1:28:58<3:46:03,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 948/3282 [1:29:04<3:47:05,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 949/3282 [1:29:09<3:39:35,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 950/3282 [1:29:15<3:44:10,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 951/3282 [1:29:21<3:43:56,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 952/3282 [1:29:26<3:34:27,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 953/3282 [1:29:32<3:37:02,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 954/3282 [1:29:38<3:41:12,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 955/3282 [1:29:44<3:44:06,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 956/3282 [1:29:49<3:45:31,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 957/3282 [1:29:55<3:44:49,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 958/3282 [1:30:01<3:42:08,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 959/3282 [1:30:07<3:44:05,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 960/3282 [1:30:13<3:47:54,  5.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 961/3282 [1:30:19<3:48:36,  5.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 962/3282 [1:30:25<3:50:09,  5.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 963/3282 [1:30:30<3:41:31,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 964/3282 [1:30:36<3:39:43,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 965/3282 [1:30:41<3:35:10,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 966/3282 [1:30:46<3:34:08,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 967/3282 [1:30:52<3:35:27,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 968/3282 [1:30:58<3:40:43,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 969/3282 [1:31:04<3:38:58,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 970/3282 [1:31:09<3:37:37,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 971/3282 [1:31:15<3:33:29,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 972/3282 [1:31:20<3:28:33,  5.42s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 973/3282 [1:31:25<3:27:09,  5.38s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 974/3282 [1:31:31<3:33:07,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 975/3282 [1:31:37<3:37:20,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 976/3282 [1:31:42<3:31:05,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 977/3282 [1:31:48<3:36:27,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 978/3282 [1:31:53<3:33:40,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 979/3282 [1:31:58<3:25:24,  5.35s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 980/3282 [1:32:04<3:28:56,  5.45s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 981/3282 [1:32:10<3:34:07,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 982/3282 [1:32:15<3:25:35,  5.36s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 983/3282 [1:32:20<3:24:40,  5.34s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 984/3282 [1:32:26<3:34:39,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 985/3282 [1:32:32<3:38:30,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 986/3282 [1:32:38<3:41:22,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 987/3282 [1:32:44<3:43:12,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 988/3282 [1:32:49<3:37:56,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 989/3282 [1:32:55<3:40:17,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 990/3282 [1:33:01<3:37:55,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 991/3282 [1:33:06<3:33:11,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 992/3282 [1:33:11<3:25:44,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 993/3282 [1:33:16<3:18:23,  5.20s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 994/3282 [1:33:22<3:24:37,  5.37s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 995/3282 [1:33:28<3:30:42,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 996/3282 [1:33:33<3:34:57,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 997/3282 [1:33:39<3:37:57,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 998/3282 [1:33:45<3:40:31,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 999/3282 [1:33:51<3:39:58,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 1000/3282 [1:33:57<3:37:22,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 1001/3282 [1:34:02<3:36:40,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1002/3282 [1:34:08<3:40:36,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1003/3282 [1:34:14<3:38:56,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1004/3282 [1:34:20<3:41:58,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1005/3282 [1:34:26<3:38:50,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1006/3282 [1:34:31<3:32:20,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1007/3282 [1:34:36<3:31:01,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1008/3282 [1:34:42<3:35:29,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1009/3282 [1:34:48<3:33:06,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1010/3282 [1:34:54<3:36:48,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1011/3282 [1:34:59<3:30:49,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1012/3282 [1:35:04<3:29:46,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1013/3282 [1:35:10<3:27:57,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1014/3282 [1:35:15<3:22:40,  5.36s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1015/3282 [1:35:20<3:19:52,  5.29s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1016/3282 [1:35:26<3:27:29,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1017/3282 [1:35:32<3:29:27,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1018/3282 [1:35:38<3:35:57,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1019/3282 [1:35:43<3:28:05,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1020/3282 [1:35:48<3:28:41,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1021/3282 [1:35:54<3:30:06,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1022/3282 [1:36:00<3:34:21,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1023/3282 [1:36:06<3:37:21,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1024/3282 [1:36:12<3:37:01,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1025/3282 [1:36:17<3:32:49,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███▏      | 1026/3282 [1:36:23<3:36:03,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███▏      | 1027/3282 [1:36:29<3:32:51,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███▏      | 1028/3282 [1:36:34<3:31:48,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███▏      | 1029/3282 [1:36:39<3:26:48,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███▏      | 1030/3282 [1:36:45<3:28:46,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███▏      | 1031/3282 [1:36:51<3:33:09,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███▏      | 1032/3282 [1:36:57<3:33:49,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███▏      | 1033/3282 [1:37:01<3:23:05,  5.42s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1034/3282 [1:37:07<3:24:42,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1035/3282 [1:37:13<3:24:48,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1036/3282 [1:37:18<3:30:12,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1037/3282 [1:37:24<3:29:39,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1038/3282 [1:37:30<3:31:11,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1039/3282 [1:37:36<3:34:31,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1040/3282 [1:37:41<3:32:36,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1041/3282 [1:37:47<3:37:24,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1042/3282 [1:37:53<3:38:20,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1043/3282 [1:37:59<3:38:52,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1044/3282 [1:38:05<3:32:27,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1045/3282 [1:38:10<3:30:58,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1046/3282 [1:38:16<3:30:55,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1047/3282 [1:38:21<3:29:54,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1048/3282 [1:38:27<3:32:47,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1049/3282 [1:38:33<3:29:00,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1050/3282 [1:38:38<3:21:22,  5.41s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1051/3282 [1:38:43<3:25:06,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1052/3282 [1:38:49<3:24:34,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1053/3282 [1:38:54<3:24:21,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1054/3282 [1:39:01<3:32:15,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1055/3282 [1:39:05<3:21:35,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1056/3282 [1:39:11<3:27:19,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1057/3282 [1:39:17<3:30:47,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1058/3282 [1:39:23<3:33:14,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1059/3282 [1:39:29<3:34:54,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1060/3282 [1:39:34<3:31:20,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1061/3282 [1:39:41<3:35:02,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1062/3282 [1:39:45<3:23:22,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1063/3282 [1:39:51<3:21:06,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1064/3282 [1:39:56<3:23:44,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1065/3282 [1:40:02<3:30:25,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1066/3282 [1:40:08<3:26:00,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1067/3282 [1:40:13<3:26:01,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1068/3282 [1:40:19<3:29:36,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1069/3282 [1:40:25<3:34:26,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1070/3282 [1:40:31<3:32:49,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1071/3282 [1:40:36<3:20:36,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1072/3282 [1:40:42<3:25:40,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1073/3282 [1:40:48<3:29:42,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1074/3282 [1:40:53<3:30:16,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1075/3282 [1:40:59<3:29:42,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1076/3282 [1:41:05<3:30:14,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1077/3282 [1:41:11<3:33:45,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1078/3282 [1:41:16<3:24:03,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1079/3282 [1:41:21<3:20:08,  5.45s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1080/3282 [1:41:26<3:20:28,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1081/3282 [1:41:32<3:25:20,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1082/3282 [1:41:38<3:29:12,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1083/3282 [1:41:44<3:23:37,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1084/3282 [1:41:49<3:23:41,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1085/3282 [1:41:55<3:24:45,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1086/3282 [1:42:01<3:28:44,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1087/3282 [1:42:06<3:24:10,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1088/3282 [1:42:12<3:25:02,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1089/3282 [1:42:17<3:25:30,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1090/3282 [1:42:23<3:30:51,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1091/3282 [1:42:29<3:32:49,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1092/3282 [1:42:36<3:36:01,  5.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1093/3282 [1:42:41<3:34:09,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1094/3282 [1:42:47<3:34:26,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1095/3282 [1:42:52<3:26:52,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1096/3282 [1:42:58<3:30:50,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1097/3282 [1:43:04<3:33:36,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1098/3282 [1:43:11<3:36:21,  5.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1099/3282 [1:43:16<3:33:09,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▎      | 1100/3282 [1:43:22<3:29:49,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▎      | 1101/3282 [1:43:28<3:33:34,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▎      | 1102/3282 [1:43:34<3:32:11,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▎      | 1103/3282 [1:43:38<3:19:21,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▎      | 1104/3282 [1:43:44<3:15:13,  5.38s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▎      | 1105/3282 [1:43:49<3:18:11,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▎      | 1106/3282 [1:43:55<3:23:25,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▎      | 1107/3282 [1:44:01<3:24:52,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1108/3282 [1:44:06<3:24:01,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1109/3282 [1:44:13<3:28:29,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1110/3282 [1:44:18<3:22:25,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1111/3282 [1:44:22<3:12:17,  5.31s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1112/3282 [1:44:28<3:14:58,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1113/3282 [1:44:32<3:03:53,  5.09s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1114/3282 [1:44:38<3:11:12,  5.29s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1115/3282 [1:44:44<3:16:06,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1116/3282 [1:44:50<3:21:37,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1117/3282 [1:44:55<3:17:30,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1118/3282 [1:45:00<3:16:25,  5.45s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1119/3282 [1:45:06<3:19:44,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1120/3282 [1:45:12<3:23:35,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1121/3282 [1:45:18<3:21:37,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1122/3282 [1:45:24<3:26:20,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1123/3282 [1:45:29<3:26:30,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1124/3282 [1:45:35<3:23:32,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1125/3282 [1:45:41<3:26:39,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1126/3282 [1:45:47<3:29:38,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1127/3282 [1:45:51<3:16:58,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1128/3282 [1:45:57<3:13:55,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1129/3282 [1:46:03<3:20:49,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1130/3282 [1:46:09<3:24:35,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1131/3282 [1:46:14<3:25:07,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1132/3282 [1:46:20<3:26:58,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1133/3282 [1:46:26<3:26:40,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1134/3282 [1:46:31<3:21:28,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1135/3282 [1:46:36<3:15:02,  5.45s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1136/3282 [1:46:42<3:18:17,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1137/3282 [1:46:48<3:23:36,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1138/3282 [1:46:54<3:25:49,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1139/3282 [1:47:00<3:28:41,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1140/3282 [1:47:06<3:23:45,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1141/3282 [1:47:11<3:24:11,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1142/3282 [1:47:17<3:26:04,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1143/3282 [1:47:23<3:27:22,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1144/3282 [1:47:29<3:28:15,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1145/3282 [1:47:35<3:25:12,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1146/3282 [1:47:41<3:28:09,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1147/3282 [1:47:47<3:29:12,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1148/3282 [1:47:52<3:25:49,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1149/3282 [1:47:57<3:12:48,  5.42s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1150/3282 [1:48:03<3:19:16,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1151/3282 [1:48:09<3:25:41,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1152/3282 [1:48:15<3:23:17,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1153/3282 [1:48:20<3:21:39,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1154/3282 [1:48:26<3:21:25,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1155/3282 [1:48:31<3:13:24,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1156/3282 [1:48:36<3:13:37,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1157/3282 [1:48:42<3:13:45,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1158/3282 [1:48:47<3:13:49,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1159/3282 [1:48:52<3:10:52,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1160/3282 [1:48:58<3:14:42,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1161/3282 [1:49:04<3:14:24,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1162/3282 [1:49:10<3:21:54,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1163/3282 [1:49:15<3:16:30,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1164/3282 [1:49:21<3:15:34,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1165/3282 [1:49:26<3:16:54,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1166/3282 [1:49:32<3:20:15,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1167/3282 [1:49:37<3:15:13,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1168/3282 [1:49:43<3:13:39,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1169/3282 [1:49:48<3:14:23,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1170/3282 [1:49:54<3:19:09,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1171/3282 [1:50:00<3:21:41,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1172/3282 [1:50:05<3:15:04,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1173/3282 [1:50:11<3:12:23,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1174/3282 [1:50:17<3:17:28,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1175/3282 [1:50:22<3:11:07,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1176/3282 [1:50:27<3:07:40,  5.35s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1177/3282 [1:50:32<3:08:08,  5.36s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1178/3282 [1:50:37<3:02:40,  5.21s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1179/3282 [1:50:42<3:03:25,  5.23s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1180/3282 [1:50:48<3:10:59,  5.45s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1181/3282 [1:50:53<3:07:28,  5.35s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1182/3282 [1:50:59<3:14:43,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1183/3282 [1:51:05<3:14:43,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1184/3282 [1:51:11<3:13:42,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1185/3282 [1:51:16<3:15:55,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1186/3282 [1:51:22<3:18:54,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1187/3282 [1:51:28<3:19:30,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1188/3282 [1:51:34<3:17:59,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1189/3282 [1:51:39<3:13:59,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▋      | 1190/3282 [1:51:45<3:17:59,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▋      | 1191/3282 [1:51:51<3:20:12,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▋      | 1192/3282 [1:51:56<3:15:24,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▋      | 1193/3282 [1:52:02<3:18:28,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▋      | 1194/3282 [1:52:07<3:13:14,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▋      | 1195/3282 [1:52:13<3:13:27,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▋      | 1196/3282 [1:52:18<3:10:35,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▋      | 1197/3282 [1:52:23<3:10:33,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1198/3282 [1:52:29<3:09:30,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1199/3282 [1:52:35<3:16:26,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1200/3282 [1:52:41<3:19:22,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1201/3282 [1:52:47<3:18:22,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1202/3282 [1:52:53<3:23:25,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1203/3282 [1:52:58<3:17:23,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1204/3282 [1:53:04<3:20:11,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1205/3282 [1:53:09<3:16:02,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1206/3282 [1:53:15<3:16:01,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1207/3282 [1:53:20<3:12:02,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1208/3282 [1:53:26<3:17:03,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1209/3282 [1:53:32<3:12:50,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1210/3282 [1:53:38<3:19:24,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1211/3282 [1:53:44<3:17:22,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1212/3282 [1:53:50<3:19:10,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1213/3282 [1:53:55<3:15:03,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1214/3282 [1:54:00<3:10:19,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1215/3282 [1:54:06<3:10:48,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1216/3282 [1:54:12<3:14:34,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1217/3282 [1:54:17<3:17:06,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1218/3282 [1:54:23<3:18:54,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1219/3282 [1:54:29<3:13:46,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1220/3282 [1:54:35<3:17:57,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1221/3282 [1:54:41<3:20:51,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1222/3282 [1:54:46<3:16:03,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1223/3282 [1:54:52<3:18:00,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1224/3282 [1:54:58<3:19:15,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1225/3282 [1:55:03<3:11:59,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1226/3282 [1:55:09<3:13:34,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1227/3282 [1:55:14<3:12:44,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1228/3282 [1:55:20<3:12:00,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1229/3282 [1:55:25<3:01:15,  5.30s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1230/3282 [1:55:30<3:07:24,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1231/3282 [1:55:36<3:11:38,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1232/3282 [1:55:43<3:18:34,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1233/3282 [1:55:49<3:21:43,  5.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1234/3282 [1:55:55<3:20:01,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1235/3282 [1:56:00<3:17:50,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1236/3282 [1:56:06<3:18:44,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1237/3282 [1:56:12<3:19:23,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1238/3282 [1:56:18<3:18:16,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1239/3282 [1:56:23<3:15:36,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1240/3282 [1:56:29<3:15:30,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1241/3282 [1:56:34<3:09:54,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1242/3282 [1:56:40<3:13:02,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1243/3282 [1:56:46<3:15:50,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1244/3282 [1:56:52<3:17:07,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1245/3282 [1:56:58<3:13:41,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1246/3282 [1:57:03<3:14:07,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1247/3282 [1:57:09<3:14:18,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1248/3282 [1:57:15<3:15:58,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1249/3282 [1:57:21<3:17:02,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1250/3282 [1:57:27<3:19:14,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1251/3282 [1:57:33<3:21:32,  5.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1252/3282 [1:57:39<3:18:26,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1253/3282 [1:57:44<3:17:07,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1254/3282 [1:57:50<3:12:27,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1255/3282 [1:57:56<3:14:28,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1256/3282 [1:58:02<3:15:51,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1257/3282 [1:58:08<3:17:12,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1258/3282 [1:58:13<3:16:09,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1259/3282 [1:58:19<3:16:57,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1260/3282 [1:58:25<3:13:08,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1261/3282 [1:58:30<3:08:41,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1262/3282 [1:58:36<3:12:11,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1263/3282 [1:58:42<3:11:34,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▊      | 1264/3282 [1:58:47<3:11:09,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▊      | 1265/3282 [1:58:52<3:06:16,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▊      | 1266/3282 [1:58:58<3:04:42,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▊      | 1267/3282 [1:59:03<3:05:26,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▊      | 1268/3282 [1:59:09<3:01:19,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▊      | 1269/3282 [1:59:14<3:03:02,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▊      | 1270/3282 [1:59:19<2:55:55,  5.25s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▊      | 1271/3282 [1:59:25<3:00:03,  5.37s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1272/3282 [1:59:30<3:03:50,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1273/3282 [1:59:36<3:04:39,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1274/3282 [1:59:42<3:08:59,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1275/3282 [1:59:48<3:11:59,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1276/3282 [1:59:54<3:12:08,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1277/3282 [2:00:00<3:14:07,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1278/3282 [2:00:05<3:15:01,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1279/3282 [2:00:11<3:16:58,  5.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1280/3282 [2:00:17<3:16:58,  5.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1281/3282 [2:00:23<3:16:59,  5.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1282/3282 [2:00:29<3:17:27,  5.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1283/3282 [2:00:35<3:18:37,  5.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1284/3282 [2:00:41<3:15:34,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1285/3282 [2:00:47<3:16:19,  5.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1286/3282 [2:00:53<3:16:19,  5.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1287/3282 [2:00:58<3:08:27,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1288/3282 [2:01:04<3:08:22,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1289/3282 [2:01:10<3:10:40,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1290/3282 [2:01:15<3:12:39,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1291/3282 [2:01:21<3:08:28,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1292/3282 [2:01:26<3:06:27,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1293/3282 [2:01:31<3:01:25,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1294/3282 [2:01:37<3:04:10,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1295/3282 [2:01:43<3:03:13,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1296/3282 [2:01:48<3:04:25,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1297/3282 [2:01:54<3:01:34,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1298/3282 [2:02:00<3:07:03,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1299/3282 [2:02:05<3:06:07,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1300/3282 [2:02:11<3:03:34,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1301/3282 [2:02:16<3:05:26,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1302/3282 [2:02:22<3:09:29,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1303/3282 [2:02:28<3:09:34,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1304/3282 [2:02:34<3:06:54,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1305/3282 [2:02:39<3:02:11,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1306/3282 [2:02:44<2:56:10,  5.35s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1307/3282 [2:02:50<2:59:59,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1308/3282 [2:02:55<3:02:37,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1309/3282 [2:03:01<3:04:29,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1310/3282 [2:03:07<3:03:58,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1311/3282 [2:03:12<3:02:37,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1312/3282 [2:03:17<2:59:50,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1313/3282 [2:03:24<3:06:10,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1314/3282 [2:03:30<3:09:42,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1315/3282 [2:03:35<3:10:54,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1316/3282 [2:03:42<3:12:53,  5.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1317/3282 [2:03:48<3:15:56,  5.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1318/3282 [2:03:53<3:12:40,  5.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1319/3282 [2:03:59<3:10:17,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1320/3282 [2:04:05<3:11:02,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1321/3282 [2:04:10<3:03:45,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1322/3282 [2:04:16<3:09:25,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1323/3282 [2:04:22<3:06:16,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1324/3282 [2:04:27<3:04:50,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1325/3282 [2:04:33<3:04:44,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1326/3282 [2:04:39<3:04:50,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1327/3282 [2:04:45<3:07:08,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1328/3282 [2:04:51<3:10:01,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1329/3282 [2:04:56<3:09:12,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1330/3282 [2:05:02<3:07:41,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1331/3282 [2:05:08<3:07:31,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1332/3282 [2:05:13<3:05:38,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1333/3282 [2:05:19<3:00:38,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1334/3282 [2:05:24<2:58:02,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1335/3282 [2:05:30<3:00:38,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1336/3282 [2:05:35<3:02:25,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1337/3282 [2:05:41<3:05:09,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1338/3282 [2:05:47<3:02:51,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1339/3282 [2:05:52<2:59:26,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1340/3282 [2:05:58<3:00:38,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1341/3282 [2:06:04<3:03:46,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1342/3282 [2:06:10<3:08:53,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1343/3282 [2:06:16<3:08:10,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1344/3282 [2:06:22<3:09:22,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1345/3282 [2:06:27<3:07:24,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1346/3282 [2:06:33<3:05:58,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1347/3282 [2:06:39<3:04:01,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1348/3282 [2:06:44<3:01:57,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1349/3282 [2:06:50<3:02:59,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1350/3282 [2:06:55<2:59:15,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1351/3282 [2:07:01<3:01:06,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1352/3282 [2:07:06<2:58:44,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1353/3282 [2:07:12<3:02:06,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████▏     | 1354/3282 [2:07:17<2:56:00,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████▏     | 1355/3282 [2:07:23<3:01:28,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████▏     | 1356/3282 [2:07:29<2:57:04,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████▏     | 1357/3282 [2:07:34<2:57:37,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████▏     | 1358/3282 [2:07:40<2:57:02,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████▏     | 1359/3282 [2:07:45<2:59:16,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████▏     | 1360/3282 [2:07:51<3:00:47,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████▏     | 1361/3282 [2:07:56<2:57:24,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████▏     | 1362/3282 [2:08:02<3:00:57,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1363/3282 [2:08:08<3:03:17,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1364/3282 [2:08:14<2:59:01,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1365/3282 [2:08:20<3:03:21,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1366/3282 [2:08:25<3:02:38,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1367/3282 [2:08:31<3:00:18,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1368/3282 [2:08:37<3:03:11,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1369/3282 [2:08:42<2:59:44,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1370/3282 [2:08:47<2:56:26,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1371/3282 [2:08:53<2:52:24,  5.41s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1372/3282 [2:08:58<2:53:00,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1373/3282 [2:09:04<2:54:17,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1374/3282 [2:09:10<2:58:16,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1375/3282 [2:09:15<2:53:30,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1376/3282 [2:09:20<2:53:34,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1377/3282 [2:09:26<2:57:46,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1378/3282 [2:09:32<3:01:50,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1379/3282 [2:09:38<3:04:43,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1380/3282 [2:09:44<3:05:51,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1381/3282 [2:09:50<3:02:01,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1382/3282 [2:09:56<3:04:49,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1383/3282 [2:10:01<3:02:13,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1384/3282 [2:10:07<3:02:05,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1385/3282 [2:10:12<2:57:35,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1386/3282 [2:10:18<2:56:10,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1387/3282 [2:10:24<3:01:24,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1388/3282 [2:10:30<3:05:42,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1389/3282 [2:10:36<3:04:24,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1390/3282 [2:10:42<3:03:21,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1391/3282 [2:10:47<2:59:58,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1392/3282 [2:10:52<2:55:04,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1393/3282 [2:10:57<2:52:33,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1394/3282 [2:11:04<2:57:53,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1395/3282 [2:11:09<2:57:48,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1396/3282 [2:11:15<2:58:35,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1397/3282 [2:11:21<3:04:10,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1398/3282 [2:11:27<3:04:35,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1399/3282 [2:11:33<3:02:24,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1400/3282 [2:11:37<2:51:29,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1401/3282 [2:11:43<2:54:07,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1402/3282 [2:11:49<2:57:43,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1403/3282 [2:11:54<2:53:11,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1404/3282 [2:12:00<2:52:43,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1405/3282 [2:12:06<2:54:06,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1406/3282 [2:12:10<2:45:37,  5.30s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1407/3282 [2:12:15<2:37:01,  5.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1408/3282 [2:12:20<2:43:00,  5.22s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1409/3282 [2:12:26<2:49:49,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1410/3282 [2:12:32<2:48:26,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1411/3282 [2:12:38<2:53:38,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1412/3282 [2:12:43<2:56:46,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1413/3282 [2:12:50<3:00:53,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1414/3282 [2:12:55<3:01:44,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1415/3282 [2:13:01<3:02:43,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1416/3282 [2:13:07<2:57:13,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1417/3282 [2:13:12<2:52:37,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1418/3282 [2:13:18<2:54:32,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1419/3282 [2:13:23<2:51:26,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1420/3282 [2:13:29<2:55:22,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1421/3282 [2:13:35<2:57:45,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1422/3282 [2:13:41<3:00:31,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1423/3282 [2:13:47<2:58:55,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1424/3282 [2:13:51<2:50:59,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1425/3282 [2:13:57<2:47:03,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1426/3282 [2:14:02<2:45:11,  5.34s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1427/3282 [2:14:07<2:46:32,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▎     | 1428/3282 [2:14:12<2:44:47,  5.33s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▎     | 1429/3282 [2:14:19<2:51:19,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▎     | 1430/3282 [2:14:25<2:55:46,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▎     | 1431/3282 [2:14:30<2:52:51,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▎     | 1432/3282 [2:14:36<2:54:22,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▎     | 1433/3282 [2:14:42<2:57:05,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▎     | 1434/3282 [2:14:48<2:58:58,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▎     | 1435/3282 [2:14:53<2:51:37,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1436/3282 [2:14:59<2:55:54,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1437/3282 [2:15:05<2:57:50,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1438/3282 [2:15:11<2:59:21,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1439/3282 [2:15:17<3:00:25,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1440/3282 [2:15:20<2:39:28,  5.19s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1441/3282 [2:15:26<2:44:35,  5.36s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1442/3282 [2:15:32<2:49:55,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1443/3282 [2:15:38<2:55:13,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1444/3282 [2:15:44<2:58:13,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1445/3282 [2:15:50<2:58:54,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1446/3282 [2:15:56<2:59:50,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1447/3282 [2:16:02<3:01:16,  5.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1448/3282 [2:16:08<2:59:40,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1449/3282 [2:16:13<2:53:31,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1450/3282 [2:16:19<2:55:29,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1451/3282 [2:16:25<2:58:06,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1452/3282 [2:16:30<2:54:36,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1453/3282 [2:16:36<2:54:43,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1454/3282 [2:16:41<2:49:41,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1455/3282 [2:16:47<2:52:43,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1456/3282 [2:16:53<2:52:29,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1457/3282 [2:16:57<2:42:18,  5.34s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1458/3282 [2:17:03<2:42:38,  5.35s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1459/3282 [2:17:09<2:48:04,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1460/3282 [2:17:14<2:49:10,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1461/3282 [2:17:20<2:47:20,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1462/3282 [2:17:25<2:43:42,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1463/3282 [2:17:31<2:45:12,  5.45s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1464/3282 [2:17:36<2:47:54,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1465/3282 [2:17:43<2:54:39,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1466/3282 [2:17:49<2:56:16,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1467/3282 [2:17:55<2:57:23,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1468/3282 [2:18:00<2:57:35,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1469/3282 [2:18:06<2:53:53,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1470/3282 [2:18:12<2:52:59,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1471/3282 [2:18:17<2:49:48,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1472/3282 [2:18:23<2:50:58,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1473/3282 [2:18:29<2:53:01,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1474/3282 [2:18:34<2:49:49,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1475/3282 [2:18:40<2:49:13,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1476/3282 [2:18:46<2:52:55,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1477/3282 [2:18:51<2:53:02,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1478/3282 [2:18:57<2:55:33,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1479/3282 [2:19:03<2:56:10,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1480/3282 [2:19:09<2:58:27,  5.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1481/3282 [2:19:15<2:55:05,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1482/3282 [2:19:21<2:52:40,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1483/3282 [2:19:26<2:51:02,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1484/3282 [2:19:32<2:53:08,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1485/3282 [2:19:38<2:51:16,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1486/3282 [2:19:43<2:49:55,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1487/3282 [2:19:49<2:53:52,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1488/3282 [2:19:55<2:54:45,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1489/3282 [2:20:01<2:53:01,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1490/3282 [2:20:07<2:54:28,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1491/3282 [2:20:12<2:49:27,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1492/3282 [2:20:18<2:45:11,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1493/3282 [2:20:23<2:44:40,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1494/3282 [2:20:28<2:40:58,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1495/3282 [2:20:34<2:44:04,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1496/3282 [2:20:40<2:47:56,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1497/3282 [2:20:45<2:46:26,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1498/3282 [2:20:51<2:49:33,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1499/3282 [2:20:56<2:42:46,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1500/3282 [2:21:02<2:44:24,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1501/3282 [2:21:07<2:38:14,  5.33s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1502/3282 [2:21:13<2:46:01,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1503/3282 [2:21:19<2:46:33,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1504/3282 [2:21:24<2:46:03,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1505/3282 [2:21:30<2:44:53,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1506/3282 [2:21:36<2:49:43,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1507/3282 [2:21:41<2:44:57,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1508/3282 [2:21:46<2:44:05,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1509/3282 [2:21:52<2:45:50,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1510/3282 [2:21:57<2:42:10,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1511/3282 [2:22:04<2:47:01,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1512/3282 [2:22:09<2:46:10,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1513/3282 [2:22:14<2:39:53,  5.42s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1514/3282 [2:22:20<2:45:13,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1515/3282 [2:22:26<2:48:58,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1516/3282 [2:22:32<2:47:24,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1517/3282 [2:22:37<2:47:02,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▋     | 1518/3282 [2:22:42<2:41:08,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▋     | 1519/3282 [2:22:48<2:43:27,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▋     | 1520/3282 [2:22:52<2:30:34,  5.13s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▋     | 1521/3282 [2:22:58<2:38:30,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▋     | 1522/3282 [2:23:04<2:39:57,  5.45s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▋     | 1523/3282 [2:23:10<2:42:28,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▋     | 1524/3282 [2:23:15<2:42:33,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▋     | 1525/3282 [2:23:21<2:47:27,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▋     | 1526/3282 [2:23:27<2:45:12,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1527/3282 [2:23:32<2:46:02,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1528/3282 [2:23:38<2:43:25,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1529/3282 [2:23:44<2:43:57,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1530/3282 [2:23:49<2:44:13,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1531/3282 [2:23:55<2:41:56,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1532/3282 [2:24:00<2:42:49,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1533/3282 [2:24:05<2:39:23,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1534/3282 [2:24:10<2:33:02,  5.25s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1535/3282 [2:24:16<2:37:22,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1536/3282 [2:24:22<2:43:24,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1537/3282 [2:24:28<2:45:50,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1538/3282 [2:24:34<2:46:11,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1539/3282 [2:24:40<2:47:39,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1540/3282 [2:24:46<2:50:37,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1541/3282 [2:24:52<2:50:44,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1542/3282 [2:24:57<2:46:22,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1543/3282 [2:25:02<2:40:48,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1544/3282 [2:25:08<2:41:01,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1545/3282 [2:25:14<2:43:55,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1546/3282 [2:25:19<2:44:34,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1547/3282 [2:25:25<2:43:28,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1548/3282 [2:25:30<2:41:06,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1549/3282 [2:25:36<2:39:26,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1550/3282 [2:25:42<2:44:41,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1551/3282 [2:25:47<2:43:25,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1552/3282 [2:25:53<2:43:18,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1553/3282 [2:25:59<2:46:31,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1554/3282 [2:26:05<2:48:01,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1555/3282 [2:26:11<2:45:46,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1556/3282 [2:26:16<2:38:32,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1557/3282 [2:26:21<2:37:25,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1558/3282 [2:26:26<2:32:48,  5.32s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1559/3282 [2:26:31<2:34:04,  5.37s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1560/3282 [2:26:37<2:34:15,  5.37s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1561/3282 [2:26:43<2:40:02,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1562/3282 [2:26:49<2:41:30,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1563/3282 [2:26:54<2:35:26,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1564/3282 [2:26:59<2:35:52,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1565/3282 [2:27:05<2:37:46,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1566/3282 [2:27:11<2:41:28,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1567/3282 [2:27:16<2:36:54,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1568/3282 [2:27:22<2:41:35,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1569/3282 [2:27:28<2:43:44,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1570/3282 [2:27:33<2:43:04,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1571/3282 [2:27:39<2:38:36,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1572/3282 [2:27:44<2:37:55,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1573/3282 [2:27:50<2:38:55,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1574/3282 [2:27:55<2:36:23,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1575/3282 [2:28:00<2:32:19,  5.35s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1576/3282 [2:28:06<2:33:17,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1577/3282 [2:28:12<2:37:56,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1578/3282 [2:28:17<2:35:38,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1579/3282 [2:28:23<2:37:08,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1580/3282 [2:28:28<2:35:49,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1581/3282 [2:28:33<2:30:59,  5.33s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1582/3282 [2:28:39<2:39:01,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1583/3282 [2:28:45<2:41:21,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1584/3282 [2:28:51<2:40:54,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1585/3282 [2:28:56<2:40:37,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1586/3282 [2:29:02<2:43:33,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1587/3282 [2:29:07<2:32:24,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1588/3282 [2:29:12<2:31:27,  5.36s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1589/3282 [2:29:18<2:36:20,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1590/3282 [2:29:24<2:34:59,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1591/3282 [2:29:29<2:38:19,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▊     | 1592/3282 [2:29:35<2:36:15,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▊     | 1593/3282 [2:29:40<2:36:21,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▊     | 1594/3282 [2:29:46<2:37:55,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▊     | 1595/3282 [2:29:52<2:36:41,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▊     | 1596/3282 [2:29:57<2:36:33,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▊     | 1597/3282 [2:30:03<2:41:01,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▊     | 1598/3282 [2:30:09<2:40:20,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▊     | 1599/3282 [2:30:15<2:38:58,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1600/3282 [2:30:20<2:40:47,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1601/3282 [2:30:26<2:37:41,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1602/3282 [2:30:32<2:38:40,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1603/3282 [2:30:37<2:38:32,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1604/3282 [2:30:43<2:36:01,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1605/3282 [2:30:49<2:39:50,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1606/3282 [2:30:54<2:39:14,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1607/3282 [2:31:00<2:40:48,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1608/3282 [2:31:06<2:43:43,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1609/3282 [2:31:12<2:40:18,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1610/3282 [2:31:18<2:40:10,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1611/3282 [2:31:23<2:37:01,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1612/3282 [2:31:28<2:35:39,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1613/3282 [2:31:34<2:36:54,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1614/3282 [2:31:40<2:39:18,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1615/3282 [2:31:46<2:43:53,  5.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1616/3282 [2:31:52<2:41:03,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1617/3282 [2:31:58<2:39:47,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1618/3282 [2:32:03<2:38:55,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1619/3282 [2:32:09<2:36:39,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1620/3282 [2:32:15<2:38:41,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1621/3282 [2:32:20<2:34:10,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1622/3282 [2:32:24<2:25:53,  5.27s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1623/3282 [2:32:30<2:29:53,  5.42s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1624/3282 [2:32:36<2:31:49,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1625/3282 [2:32:42<2:33:51,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1626/3282 [2:32:47<2:35:18,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1627/3282 [2:32:53<2:36:18,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1628/3282 [2:32:59<2:34:42,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1629/3282 [2:33:03<2:26:05,  5.30s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1630/3282 [2:33:09<2:31:21,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1631/3282 [2:33:15<2:31:55,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1632/3282 [2:33:21<2:35:03,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1633/3282 [2:33:27<2:37:36,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1634/3282 [2:33:30<2:22:10,  5.18s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1635/3282 [2:33:36<2:28:08,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1636/3282 [2:33:42<2:30:59,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1637/3282 [2:33:47<2:28:27,  5.41s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1638/3282 [2:33:53<2:29:45,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1639/3282 [2:33:58<2:26:48,  5.36s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1640/3282 [2:34:04<2:34:00,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1641/3282 [2:34:10<2:37:24,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1642/3282 [2:34:16<2:35:50,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1643/3282 [2:34:22<2:37:27,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1644/3282 [2:34:26<2:26:08,  5.35s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1645/3282 [2:34:32<2:29:24,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1646/3282 [2:34:38<2:31:40,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1647/3282 [2:34:44<2:34:24,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1648/3282 [2:34:49<2:32:48,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1649/3282 [2:34:55<2:33:59,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1650/3282 [2:35:01<2:33:57,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1651/3282 [2:35:06<2:31:48,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1652/3282 [2:35:11<2:28:39,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1653/3282 [2:35:17<2:33:54,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1654/3282 [2:35:23<2:33:02,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1655/3282 [2:35:29<2:35:09,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1656/3282 [2:35:35<2:35:23,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1657/3282 [2:35:40<2:31:46,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1658/3282 [2:35:46<2:35:58,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1659/3282 [2:35:52<2:34:20,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1660/3282 [2:35:58<2:36:13,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1661/3282 [2:36:03<2:33:00,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1662/3282 [2:36:09<2:32:56,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1663/3282 [2:36:14<2:29:54,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1664/3282 [2:36:20<2:33:43,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1665/3282 [2:36:26<2:35:40,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1666/3282 [2:36:32<2:35:22,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1667/3282 [2:36:37<2:31:27,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1668/3282 [2:36:43<2:31:44,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1669/3282 [2:36:49<2:34:53,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1670/3282 [2:36:54<2:34:43,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1671/3282 [2:37:00<2:33:47,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1672/3282 [2:37:06<2:32:30,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1673/3282 [2:37:11<2:32:15,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1674/3282 [2:37:16<2:28:22,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1675/3282 [2:37:23<2:33:45,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1676/3282 [2:37:29<2:35:02,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1677/3282 [2:37:35<2:35:47,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1678/3282 [2:37:40<2:31:22,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1679/3282 [2:37:45<2:31:22,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1680/3282 [2:37:52<2:35:36,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1681/3282 [2:37:57<2:32:43,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1682/3282 [2:38:03<2:32:07,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████▏    | 1683/3282 [2:38:08<2:31:40,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████▏    | 1684/3282 [2:38:14<2:33:16,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████▏    | 1685/3282 [2:38:20<2:31:45,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████▏    | 1686/3282 [2:38:26<2:33:41,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████▏    | 1687/3282 [2:38:32<2:36:20,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████▏    | 1688/3282 [2:38:38<2:36:47,  5.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████▏    | 1689/3282 [2:38:43<2:33:16,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████▏    | 1690/3282 [2:38:49<2:34:38,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1691/3282 [2:38:55<2:31:48,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1692/3282 [2:39:01<2:34:50,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1693/3282 [2:39:06<2:28:58,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1694/3282 [2:39:12<2:28:26,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1695/3282 [2:39:18<2:31:07,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1696/3282 [2:39:24<2:32:35,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1697/3282 [2:39:29<2:30:52,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1698/3282 [2:39:35<2:33:56,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1699/3282 [2:39:41<2:30:19,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1700/3282 [2:39:46<2:28:30,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1701/3282 [2:39:52<2:30:58,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1702/3282 [2:39:58<2:31:02,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1703/3282 [2:40:03<2:30:20,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1704/3282 [2:40:09<2:29:44,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1705/3282 [2:40:15<2:29:25,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1706/3282 [2:40:21<2:32:44,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1707/3282 [2:40:26<2:29:17,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1708/3282 [2:40:32<2:28:59,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1709/3282 [2:40:38<2:30:39,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1710/3282 [2:40:44<2:32:53,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1711/3282 [2:40:50<2:34:21,  5.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1712/3282 [2:40:56<2:36:16,  5.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1713/3282 [2:41:01<2:30:06,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1714/3282 [2:41:07<2:30:05,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1715/3282 [2:41:13<2:31:11,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1716/3282 [2:41:18<2:28:37,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1717/3282 [2:41:24<2:24:01,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1718/3282 [2:41:30<2:27:19,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1719/3282 [2:41:35<2:26:33,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1720/3282 [2:41:41<2:27:25,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1721/3282 [2:41:46<2:25:52,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1722/3282 [2:41:51<2:21:10,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1723/3282 [2:41:57<2:21:28,  5.45s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1724/3282 [2:42:03<2:23:48,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1725/3282 [2:42:09<2:28:58,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1726/3282 [2:42:15<2:30:10,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1727/3282 [2:42:20<2:29:43,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1728/3282 [2:42:26<2:28:00,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1729/3282 [2:42:32<2:30:32,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1730/3282 [2:42:37<2:25:43,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1731/3282 [2:42:42<2:18:07,  5.34s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1732/3282 [2:42:47<2:16:54,  5.30s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1733/3282 [2:42:53<2:18:15,  5.36s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1734/3282 [2:42:59<2:23:30,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1735/3282 [2:43:04<2:24:11,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1736/3282 [2:43:09<2:18:16,  5.37s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1737/3282 [2:43:15<2:19:06,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1738/3282 [2:43:20<2:21:45,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1739/3282 [2:43:26<2:25:49,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1740/3282 [2:43:31<2:20:08,  5.45s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1741/3282 [2:43:37<2:23:58,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1742/3282 [2:43:43<2:24:24,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1743/3282 [2:43:49<2:26:30,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1744/3282 [2:43:55<2:26:04,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1745/3282 [2:44:01<2:27:36,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1746/3282 [2:44:06<2:28:41,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1747/3282 [2:44:12<2:29:42,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1748/3282 [2:44:17<2:23:18,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1749/3282 [2:44:23<2:22:58,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1750/3282 [2:44:29<2:23:24,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1751/3282 [2:44:35<2:25:53,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1752/3282 [2:44:40<2:24:38,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1753/3282 [2:44:46<2:24:31,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1754/3282 [2:44:51<2:24:22,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1755/3282 [2:44:57<2:24:58,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▎    | 1756/3282 [2:45:03<2:26:29,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▎    | 1757/3282 [2:45:09<2:27:31,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▎    | 1758/3282 [2:45:15<2:26:21,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▎    | 1759/3282 [2:45:20<2:23:25,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▎    | 1760/3282 [2:45:26<2:23:30,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▎    | 1761/3282 [2:45:31<2:23:23,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▎    | 1762/3282 [2:45:37<2:25:36,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▎    | 1763/3282 [2:45:43<2:22:05,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▎    | 1764/3282 [2:45:48<2:23:05,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1765/3282 [2:45:54<2:21:40,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1766/3282 [2:45:59<2:19:14,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1767/3282 [2:46:05<2:22:13,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1768/3282 [2:46:11<2:23:04,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1769/3282 [2:46:17<2:22:54,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1770/3282 [2:46:22<2:22:44,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1771/3282 [2:46:28<2:21:59,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1772/3282 [2:46:33<2:22:05,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1773/3282 [2:46:39<2:20:39,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1774/3282 [2:46:44<2:18:25,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1775/3282 [2:46:50<2:17:26,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1776/3282 [2:46:55<2:15:21,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1777/3282 [2:47:01<2:18:00,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1778/3282 [2:47:06<2:15:39,  5.41s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1779/3282 [2:47:12<2:18:12,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1780/3282 [2:47:17<2:18:31,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1781/3282 [2:47:23<2:19:20,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1782/3282 [2:47:28<2:19:56,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1783/3282 [2:47:34<2:22:27,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1784/3282 [2:47:40<2:19:15,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1785/3282 [2:47:46<2:22:09,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1786/3282 [2:47:52<2:23:37,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1787/3282 [2:47:58<2:24:59,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1788/3282 [2:48:02<2:18:18,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1789/3282 [2:48:09<2:21:49,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1790/3282 [2:48:15<2:24:18,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1791/3282 [2:48:20<2:21:49,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1792/3282 [2:48:25<2:18:43,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1793/3282 [2:48:31<2:17:53,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1794/3282 [2:48:37<2:19:20,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1795/3282 [2:48:42<2:14:49,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1796/3282 [2:48:47<2:13:02,  5.37s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1797/3282 [2:48:52<2:13:06,  5.38s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1798/3282 [2:48:58<2:14:29,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1799/3282 [2:49:04<2:19:29,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1800/3282 [2:49:10<2:21:42,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1801/3282 [2:49:15<2:17:01,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1802/3282 [2:49:21<2:19:56,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1803/3282 [2:49:27<2:22:36,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1804/3282 [2:49:33<2:22:19,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1805/3282 [2:49:38<2:21:24,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1806/3282 [2:49:44<2:22:27,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1807/3282 [2:49:50<2:23:12,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1808/3282 [2:49:56<2:20:34,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1809/3282 [2:50:01<2:20:00,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1810/3282 [2:50:07<2:19:37,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1811/3282 [2:50:12<2:16:36,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1812/3282 [2:50:18<2:20:38,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1813/3282 [2:50:24<2:20:43,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1814/3282 [2:50:30<2:21:49,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1815/3282 [2:50:36<2:21:25,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1816/3282 [2:50:42<2:22:31,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1817/3282 [2:50:48<2:23:58,  5.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1818/3282 [2:50:54<2:22:54,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1819/3282 [2:50:59<2:21:25,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1820/3282 [2:51:05<2:22:06,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1821/3282 [2:51:11<2:18:46,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1822/3282 [2:51:17<2:21:48,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1823/3282 [2:51:22<2:18:31,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1824/3282 [2:51:28<2:18:57,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1825/3282 [2:51:33<2:17:48,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1826/3282 [2:51:39<2:19:41,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1827/3282 [2:51:45<2:17:36,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1828/3282 [2:51:51<2:20:11,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1829/3282 [2:51:56<2:15:20,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1830/3282 [2:52:02<2:15:08,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1831/3282 [2:52:07<2:09:42,  5.36s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1832/3282 [2:52:11<2:03:15,  5.10s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1833/3282 [2:52:17<2:06:38,  5.24s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1834/3282 [2:52:22<2:11:21,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1835/3282 [2:52:27<2:06:59,  5.27s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1836/3282 [2:52:33<2:11:30,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1837/3282 [2:52:39<2:13:32,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1838/3282 [2:52:45<2:16:26,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1839/3282 [2:52:51<2:18:06,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1840/3282 [2:52:56<2:12:08,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1841/3282 [2:53:01<2:08:44,  5.36s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1842/3282 [2:53:07<2:13:33,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1843/3282 [2:53:13<2:18:46,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1844/3282 [2:53:19<2:20:33,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1845/3282 [2:53:25<2:20:50,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1846/3282 [2:53:30<2:15:53,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▋    | 1847/3282 [2:53:36<2:15:45,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▋    | 1848/3282 [2:53:42<2:17:16,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▋    | 1849/3282 [2:53:48<2:21:08,  5.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▋    | 1850/3282 [2:53:54<2:19:58,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▋    | 1851/3282 [2:53:59<2:17:06,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▋    | 1852/3282 [2:54:05<2:13:15,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▋    | 1853/3282 [2:54:10<2:09:47,  5.45s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▋    | 1854/3282 [2:54:16<2:13:59,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1855/3282 [2:54:22<2:14:10,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1856/3282 [2:54:27<2:16:22,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1857/3282 [2:54:33<2:14:26,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1858/3282 [2:54:39<2:16:10,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1859/3282 [2:54:45<2:16:12,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1860/3282 [2:54:51<2:17:18,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1861/3282 [2:54:56<2:15:00,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1862/3282 [2:55:02<2:16:24,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1863/3282 [2:55:08<2:17:44,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1864/3282 [2:55:13<2:13:18,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1865/3282 [2:55:19<2:17:20,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1866/3282 [2:55:25<2:14:14,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1867/3282 [2:55:30<2:11:24,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1868/3282 [2:55:36<2:15:17,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1869/3282 [2:55:42<2:13:20,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1870/3282 [2:55:46<2:04:58,  5.31s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1871/3282 [2:55:52<2:06:43,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1872/3282 [2:55:57<2:08:36,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1873/3282 [2:56:03<2:10:30,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1874/3282 [2:56:09<2:11:12,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1875/3282 [2:56:14<2:11:02,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1876/3282 [2:56:20<2:08:53,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1877/3282 [2:56:25<2:10:00,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1878/3282 [2:56:31<2:13:21,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1879/3282 [2:56:37<2:11:07,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1880/3282 [2:56:43<2:13:13,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1881/3282 [2:56:48<2:11:34,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1882/3282 [2:56:54<2:11:03,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1883/3282 [2:57:00<2:12:57,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1884/3282 [2:57:05<2:12:34,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1885/3282 [2:57:11<2:13:59,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1886/3282 [2:57:16<2:10:04,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1887/3282 [2:57:22<2:11:12,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1888/3282 [2:57:28<2:09:59,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1889/3282 [2:57:33<2:06:35,  5.45s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1890/3282 [2:57:38<2:04:47,  5.38s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1891/3282 [2:57:44<2:08:46,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1892/3282 [2:57:49<2:07:32,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1893/3282 [2:57:55<2:05:24,  5.42s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1894/3282 [2:58:00<2:08:43,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1895/3282 [2:58:07<2:11:58,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1896/3282 [2:58:13<2:15:20,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1897/3282 [2:58:18<2:13:19,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1898/3282 [2:58:24<2:15:07,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1899/3282 [2:58:30<2:11:42,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1900/3282 [2:58:35<2:10:39,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1901/3282 [2:58:41<2:09:14,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1902/3282 [2:58:46<2:09:33,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1903/3282 [2:58:52<2:11:41,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1904/3282 [2:58:58<2:12:52,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1905/3282 [2:59:04<2:12:37,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1906/3282 [2:59:09<2:09:49,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1907/3282 [2:59:15<2:11:49,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1908/3282 [2:59:21<2:08:40,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1909/3282 [2:59:26<2:06:23,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1910/3282 [2:59:32<2:09:54,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1911/3282 [2:59:38<2:07:52,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1912/3282 [2:59:42<2:02:02,  5.35s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1913/3282 [2:59:48<2:03:30,  5.41s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1914/3282 [2:59:54<2:05:11,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1915/3282 [3:00:00<2:09:23,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1916/3282 [3:00:06<2:12:23,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1917/3282 [3:00:12<2:11:53,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1918/3282 [3:00:17<2:12:50,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1919/3282 [3:00:24<2:14:10,  5.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▊    | 1920/3282 [3:00:29<2:14:02,  5.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▊    | 1921/3282 [3:00:35<2:11:05,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▊    | 1922/3282 [3:00:41<2:13:22,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▊    | 1923/3282 [3:00:47<2:11:51,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▊    | 1924/3282 [3:00:52<2:09:26,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▊    | 1925/3282 [3:00:57<2:00:19,  5.32s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▊    | 1926/3282 [3:01:02<2:00:43,  5.34s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▊    | 1927/3282 [3:01:07<2:01:01,  5.36s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▊    | 1928/3282 [3:01:13<2:05:35,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1929/3282 [3:01:19<2:04:17,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1930/3282 [3:01:25<2:06:51,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1931/3282 [3:01:31<2:09:32,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1932/3282 [3:01:37<2:11:25,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1933/3282 [3:01:42<2:08:55,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1934/3282 [3:01:48<2:10:19,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1935/3282 [3:01:54<2:09:20,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1936/3282 [3:02:00<2:08:38,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1937/3282 [3:02:05<2:06:50,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1938/3282 [3:02:11<2:06:45,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1939/3282 [3:02:16<2:04:16,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1940/3282 [3:02:21<2:03:05,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1941/3282 [3:02:27<2:00:27,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1942/3282 [3:02:32<2:03:51,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1943/3282 [3:02:38<2:03:54,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1944/3282 [3:02:44<2:06:10,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1945/3282 [3:02:49<2:03:37,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1946/3282 [3:02:55<2:01:53,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1947/3282 [3:02:59<1:57:40,  5.29s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1948/3282 [3:03:05<2:00:40,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1949/3282 [3:03:11<2:04:41,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1950/3282 [3:03:17<2:03:41,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1951/3282 [3:03:22<2:03:35,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1952/3282 [3:03:28<2:05:45,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1953/3282 [3:03:34<2:04:23,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1954/3282 [3:03:39<2:05:13,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1955/3282 [3:03:45<2:03:56,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1956/3282 [3:03:50<2:02:23,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1957/3282 [3:03:56<2:03:46,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1958/3282 [3:04:01<2:01:00,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1959/3282 [3:04:07<2:04:39,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1960/3282 [3:04:13<2:04:38,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1961/3282 [3:04:19<2:08:09,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1962/3282 [3:04:24<2:02:15,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1963/3282 [3:04:30<2:04:42,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1964/3282 [3:04:35<2:01:02,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1965/3282 [3:04:41<2:02:33,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1966/3282 [3:04:46<2:01:10,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1967/3282 [3:04:52<2:03:35,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1968/3282 [3:04:58<2:07:18,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1969/3282 [3:05:04<2:08:42,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1970/3282 [3:05:10<2:06:34,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1971/3282 [3:05:16<2:05:03,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1972/3282 [3:05:21<2:03:22,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1973/3282 [3:05:27<2:02:46,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1974/3282 [3:05:32<2:01:41,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1975/3282 [3:05:38<2:03:45,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1976/3282 [3:05:44<2:05:26,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1977/3282 [3:05:50<2:04:39,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1978/3282 [3:05:55<2:03:30,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1979/3282 [3:06:01<2:03:49,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1980/3282 [3:06:06<1:57:00,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1981/3282 [3:06:11<1:59:17,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1982/3282 [3:06:16<1:56:05,  5.36s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1983/3282 [3:06:22<1:57:22,  5.42s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1984/3282 [3:06:28<1:58:52,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1985/3282 [3:06:33<2:00:26,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1986/3282 [3:06:39<1:59:42,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1987/3282 [3:06:45<2:02:17,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1988/3282 [3:06:51<2:04:02,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1989/3282 [3:06:56<2:02:44,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1990/3282 [3:07:02<2:01:48,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1991/3282 [3:07:07<1:58:46,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1992/3282 [3:07:13<1:58:31,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1993/3282 [3:07:19<2:01:50,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1994/3282 [3:07:24<2:01:08,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1995/3282 [3:07:30<2:01:11,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1996/3282 [3:07:35<1:58:15,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1997/3282 [3:07:40<1:56:09,  5.42s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1998/3282 [3:07:44<1:46:46,  4.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1999/3282 [3:07:50<1:50:25,  5.16s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 2000/3282 [3:07:55<1:50:37,  5.18s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 2001/3282 [3:08:01<1:54:14,  5.35s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 2002/3282 [3:08:07<1:59:03,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 2003/3282 [3:08:13<2:00:08,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 2004/3282 [3:08:18<2:00:48,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 2005/3282 [3:08:24<1:59:30,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 2006/3282 [3:08:29<1:55:40,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 2007/3282 [3:08:35<1:57:38,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 2008/3282 [3:08:40<1:57:46,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 2009/3282 [3:08:46<2:01:24,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 2010/3282 [3:08:52<2:01:32,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████▏   | 2011/3282 [3:08:57<1:58:04,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████▏   | 2012/3282 [3:09:03<2:00:58,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████▏   | 2013/3282 [3:09:09<1:59:20,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████▏   | 2014/3282 [3:09:15<1:59:22,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████▏   | 2015/3282 [3:09:20<1:58:47,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████▏   | 2016/3282 [3:09:26<1:59:32,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████▏   | 2017/3282 [3:09:31<1:57:04,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████▏   | 2018/3282 [3:09:37<2:00:37,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2019/3282 [3:09:42<1:54:55,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2020/3282 [3:09:48<1:57:56,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2021/3282 [3:09:54<1:57:36,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2022/3282 [3:10:00<1:59:43,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2023/3282 [3:10:06<2:01:44,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2024/3282 [3:10:11<1:59:04,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2025/3282 [3:10:16<1:57:08,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2026/3282 [3:10:22<1:55:50,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2027/3282 [3:10:28<1:57:09,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2028/3282 [3:10:33<1:56:16,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2029/3282 [3:10:39<1:57:23,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2030/3282 [3:10:45<1:58:05,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2031/3282 [3:10:50<1:59:30,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2032/3282 [3:10:56<1:56:06,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2033/3282 [3:11:01<1:56:34,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2034/3282 [3:11:07<1:56:17,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2035/3282 [3:11:12<1:55:32,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2036/3282 [3:11:18<1:56:07,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2037/3282 [3:11:23<1:53:40,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2038/3282 [3:11:28<1:47:59,  5.21s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2039/3282 [3:11:34<1:50:40,  5.34s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2040/3282 [3:11:39<1:52:29,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2041/3282 [3:11:45<1:55:18,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2042/3282 [3:11:51<1:58:34,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2043/3282 [3:11:57<2:00:56,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2044/3282 [3:12:03<1:57:54,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2045/3282 [3:12:09<1:58:59,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2046/3282 [3:12:14<1:55:54,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2047/3282 [3:12:20<1:58:53,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2048/3282 [3:12:26<1:58:40,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2049/3282 [3:12:31<1:56:46,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2050/3282 [3:12:36<1:51:33,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2051/3282 [3:12:42<1:54:38,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2052/3282 [3:12:48<1:57:47,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2053/3282 [3:12:54<1:57:45,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2054/3282 [3:13:00<1:58:40,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2055/3282 [3:13:05<1:55:27,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2056/3282 [3:13:11<1:55:26,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2057/3282 [3:13:17<1:58:12,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2058/3282 [3:13:22<1:56:45,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2059/3282 [3:13:28<1:58:33,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2060/3282 [3:13:34<1:57:31,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2061/3282 [3:13:40<1:58:29,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2062/3282 [3:13:46<1:57:57,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2063/3282 [3:13:52<1:56:55,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2064/3282 [3:13:58<1:59:33,  5.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2065/3282 [3:14:03<1:55:51,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2066/3282 [3:14:09<1:56:57,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2067/3282 [3:14:14<1:55:05,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2068/3282 [3:14:20<1:52:03,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2069/3282 [3:14:26<1:55:33,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2070/3282 [3:14:31<1:55:08,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2071/3282 [3:14:37<1:57:10,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2072/3282 [3:14:43<1:55:40,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2073/3282 [3:14:49<1:56:38,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2074/3282 [3:14:54<1:55:13,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2075/3282 [3:15:01<1:57:05,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2076/3282 [3:15:06<1:56:07,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2077/3282 [3:15:12<1:53:41,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2078/3282 [3:15:17<1:54:12,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2079/3282 [3:15:23<1:55:26,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2080/3282 [3:15:29<1:56:16,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2081/3282 [3:15:35<1:55:52,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2082/3282 [3:15:40<1:53:57,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2083/3282 [3:15:46<1:54:12,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2084/3282 [3:15:52<1:55:15,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▎   | 2085/3282 [3:15:57<1:52:19,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▎   | 2086/3282 [3:16:03<1:54:45,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▎   | 2087/3282 [3:16:08<1:49:48,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▎   | 2088/3282 [3:16:14<1:50:38,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▎   | 2089/3282 [3:16:20<1:52:35,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▎   | 2090/3282 [3:16:26<1:52:29,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▎   | 2091/3282 [3:16:32<1:54:38,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▎   | 2092/3282 [3:16:37<1:54:27,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2093/3282 [3:16:43<1:55:59,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2094/3282 [3:16:49<1:54:12,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2095/3282 [3:16:55<1:52:22,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2096/3282 [3:17:00<1:53:50,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2097/3282 [3:17:07<1:55:56,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2098/3282 [3:17:13<1:56:22,  5.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2099/3282 [3:17:18<1:56:33,  5.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2100/3282 [3:17:24<1:53:23,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2101/3282 [3:17:30<1:52:44,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2102/3282 [3:17:35<1:53:57,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2103/3282 [3:17:41<1:50:54,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2104/3282 [3:17:46<1:47:10,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2105/3282 [3:17:51<1:48:14,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2106/3282 [3:17:57<1:47:19,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2107/3282 [3:18:02<1:47:49,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2108/3282 [3:18:08<1:48:05,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2109/3282 [3:18:14<1:48:53,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2110/3282 [3:18:19<1:45:02,  5.38s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2111/3282 [3:18:24<1:43:25,  5.30s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2112/3282 [3:18:29<1:45:27,  5.41s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2113/3282 [3:18:35<1:47:20,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2114/3282 [3:18:41<1:48:06,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2115/3282 [3:18:46<1:48:06,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2116/3282 [3:18:52<1:50:51,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2117/3282 [3:18:58<1:52:13,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2118/3282 [3:19:04<1:49:15,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2119/3282 [3:19:10<1:50:46,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2120/3282 [3:19:15<1:48:44,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2121/3282 [3:19:20<1:45:44,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2122/3282 [3:19:26<1:47:24,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2123/3282 [3:19:32<1:49:36,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2124/3282 [3:19:38<1:49:58,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2125/3282 [3:19:44<1:51:51,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2126/3282 [3:19:49<1:48:18,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2127/3282 [3:19:55<1:50:11,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2128/3282 [3:20:00<1:49:15,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2129/3282 [3:20:06<1:51:14,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2130/3282 [3:20:12<1:48:19,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2131/3282 [3:20:17<1:48:55,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2132/3282 [3:20:23<1:45:38,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2133/3282 [3:20:28<1:44:18,  5.45s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2134/3282 [3:20:34<1:49:05,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2135/3282 [3:20:40<1:51:00,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2136/3282 [3:20:46<1:52:43,  5.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2137/3282 [3:20:51<1:47:08,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2138/3282 [3:20:57<1:45:12,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2139/3282 [3:21:02<1:47:37,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2140/3282 [3:21:08<1:49:16,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2141/3282 [3:21:14<1:49:16,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2142/3282 [3:21:20<1:50:05,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2143/3282 [3:21:26<1:50:42,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2144/3282 [3:21:31<1:48:33,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2145/3282 [3:21:37<1:47:35,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2146/3282 [3:21:43<1:46:22,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2147/3282 [3:21:49<1:48:11,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2148/3282 [3:21:54<1:47:48,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2149/3282 [3:21:59<1:41:18,  5.37s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2150/3282 [3:22:04<1:41:53,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2151/3282 [3:22:09<1:37:39,  5.18s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2152/3282 [3:22:15<1:42:27,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2153/3282 [3:22:20<1:40:03,  5.32s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2154/3282 [3:22:25<1:40:56,  5.37s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2155/3282 [3:22:31<1:40:27,  5.35s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2156/3282 [3:22:36<1:38:37,  5.26s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2157/3282 [3:22:41<1:40:51,  5.38s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2158/3282 [3:22:47<1:40:18,  5.35s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2159/3282 [3:22:53<1:42:28,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2160/3282 [3:22:58<1:40:53,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2161/3282 [3:23:03<1:42:23,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2162/3282 [3:23:08<1:38:12,  5.26s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2163/3282 [3:23:14<1:43:25,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2164/3282 [3:23:20<1:42:26,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2165/3282 [3:23:26<1:44:41,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2166/3282 [3:23:31<1:45:21,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2167/3282 [3:23:37<1:45:17,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2168/3282 [3:23:43<1:46:47,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2169/3282 [3:23:49<1:47:32,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2170/3282 [3:23:55<1:48:20,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2171/3282 [3:24:00<1:41:41,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2172/3282 [3:24:05<1:40:32,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2173/3282 [3:24:11<1:43:23,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2174/3282 [3:24:17<1:46:13,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▋   | 2175/3282 [3:24:23<1:47:17,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▋   | 2176/3282 [3:24:29<1:48:30,  5.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▋   | 2177/3282 [3:24:35<1:48:48,  5.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▋   | 2178/3282 [3:24:41<1:48:57,  5.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▋   | 2179/3282 [3:24:46<1:45:25,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▋   | 2180/3282 [3:24:51<1:40:28,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▋   | 2181/3282 [3:24:57<1:42:47,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▋   | 2182/3282 [3:25:03<1:45:06,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2183/3282 [3:25:09<1:44:07,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2184/3282 [3:25:14<1:43:55,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2185/3282 [3:25:20<1:43:42,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2186/3282 [3:25:26<1:45:39,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2187/3282 [3:25:31<1:43:52,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2188/3282 [3:25:37<1:43:43,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2189/3282 [3:25:43<1:45:02,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2190/3282 [3:25:49<1:43:51,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2191/3282 [3:25:55<1:45:59,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2192/3282 [3:26:01<1:47:02,  5.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2193/3282 [3:26:07<1:47:42,  5.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2194/3282 [3:26:12<1:46:05,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2195/3282 [3:26:19<1:48:20,  5.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2196/3282 [3:26:24<1:46:00,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2197/3282 [3:26:30<1:43:48,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2198/3282 [3:26:36<1:44:50,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2199/3282 [3:26:42<1:45:15,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2200/3282 [3:26:47<1:41:42,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2201/3282 [3:26:53<1:42:13,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2202/3282 [3:26:58<1:43:19,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2203/3282 [3:27:05<1:46:36,  5.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2204/3282 [3:27:10<1:45:04,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2205/3282 [3:27:15<1:39:32,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2206/3282 [3:27:21<1:38:31,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2207/3282 [3:27:26<1:38:21,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2208/3282 [3:27:32<1:39:41,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2209/3282 [3:27:37<1:38:07,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2210/3282 [3:27:43<1:39:30,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2211/3282 [3:27:49<1:39:23,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2212/3282 [3:27:53<1:32:29,  5.19s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2213/3282 [3:27:58<1:34:28,  5.30s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2214/3282 [3:28:04<1:37:38,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2215/3282 [3:28:10<1:38:56,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2216/3282 [3:28:16<1:40:54,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2217/3282 [3:28:22<1:42:15,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2218/3282 [3:28:28<1:42:54,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2219/3282 [3:28:34<1:44:03,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2220/3282 [3:28:40<1:42:50,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2221/3282 [3:28:46<1:43:16,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2222/3282 [3:28:52<1:44:15,  5.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2223/3282 [3:28:57<1:43:24,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2224/3282 [3:29:03<1:40:20,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2225/3282 [3:29:08<1:37:41,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2226/3282 [3:29:13<1:38:14,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2227/3282 [3:29:19<1:38:37,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2228/3282 [3:29:24<1:36:53,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2229/3282 [3:29:30<1:37:05,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2230/3282 [3:29:36<1:38:09,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2231/3282 [3:29:41<1:37:54,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2232/3282 [3:29:47<1:39:41,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2233/3282 [3:29:53<1:40:42,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2234/3282 [3:29:59<1:42:03,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2235/3282 [3:30:04<1:38:06,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2236/3282 [3:30:09<1:34:24,  5.41s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2237/3282 [3:30:15<1:37:31,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2238/3282 [3:30:20<1:35:19,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2239/3282 [3:30:26<1:32:52,  5.34s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2240/3282 [3:30:31<1:33:26,  5.38s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2241/3282 [3:30:37<1:36:03,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2242/3282 [3:30:42<1:34:10,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2243/3282 [3:30:48<1:35:15,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2244/3282 [3:30:52<1:31:15,  5.28s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2245/3282 [3:30:56<1:22:27,  4.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2246/3282 [3:31:01<1:24:35,  4.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2247/3282 [3:31:07<1:28:55,  5.16s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2248/3282 [3:31:13<1:31:25,  5.30s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▊   | 2249/3282 [3:31:19<1:35:30,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▊   | 2250/3282 [3:31:24<1:35:02,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▊   | 2251/3282 [3:31:30<1:34:10,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▊   | 2252/3282 [3:31:36<1:36:30,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▊   | 2253/3282 [3:31:41<1:36:35,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▊   | 2254/3282 [3:31:47<1:34:42,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▊   | 2255/3282 [3:31:52<1:35:44,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▊   | 2256/3282 [3:31:58<1:37:31,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2257/3282 [3:32:04<1:39:06,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2258/3282 [3:32:10<1:40:37,  5.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2259/3282 [3:32:16<1:36:58,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2260/3282 [3:32:22<1:37:59,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2261/3282 [3:32:27<1:34:38,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2262/3282 [3:32:33<1:37:50,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2263/3282 [3:32:39<1:38:28,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2264/3282 [3:32:44<1:35:19,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2265/3282 [3:32:49<1:34:30,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2266/3282 [3:32:55<1:35:20,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2267/3282 [3:33:01<1:37:20,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2268/3282 [3:33:07<1:35:23,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2269/3282 [3:33:13<1:36:51,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2270/3282 [3:33:19<1:38:42,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2271/3282 [3:33:25<1:38:54,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2272/3282 [3:33:30<1:38:14,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2273/3282 [3:33:36<1:34:58,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2274/3282 [3:33:42<1:37:16,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2275/3282 [3:33:48<1:37:44,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2276/3282 [3:33:54<1:39:05,  5.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2277/3282 [3:33:59<1:36:21,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2278/3282 [3:34:05<1:35:49,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2279/3282 [3:34:10<1:35:50,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2280/3282 [3:34:16<1:33:59,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2281/3282 [3:34:22<1:35:31,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2282/3282 [3:34:28<1:35:33,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2283/3282 [3:34:32<1:31:01,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2284/3282 [3:34:38<1:30:57,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2285/3282 [3:34:44<1:34:08,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2286/3282 [3:34:50<1:36:44,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2287/3282 [3:34:56<1:38:05,  5.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2288/3282 [3:35:02<1:34:55,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2289/3282 [3:35:08<1:35:44,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2290/3282 [3:35:14<1:37:46,  5.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2291/3282 [3:35:19<1:36:24,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2292/3282 [3:35:25<1:33:11,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2293/3282 [3:35:31<1:34:23,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2294/3282 [3:35:36<1:33:58,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2295/3282 [3:35:42<1:32:42,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2296/3282 [3:35:47<1:32:15,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2297/3282 [3:35:53<1:32:23,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2298/3282 [3:35:59<1:32:28,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2299/3282 [3:36:04<1:33:53,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2300/3282 [3:36:10<1:33:55,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2301/3282 [3:36:16<1:33:53,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2302/3282 [3:36:22<1:34:49,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2303/3282 [3:36:27<1:32:39,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2304/3282 [3:36:33<1:32:02,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2305/3282 [3:36:39<1:33:14,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2306/3282 [3:36:45<1:34:02,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2307/3282 [3:36:51<1:34:31,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2308/3282 [3:36:56<1:31:26,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2309/3282 [3:37:02<1:33:22,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2310/3282 [3:37:08<1:35:26,  5.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2311/3282 [3:37:13<1:32:28,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2312/3282 [3:37:19<1:33:19,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2313/3282 [3:37:25<1:33:08,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2314/3282 [3:37:30<1:31:15,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2315/3282 [3:37:36<1:31:41,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2316/3282 [3:37:42<1:34:07,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2317/3282 [3:37:48<1:31:50,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2318/3282 [3:37:53<1:29:44,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2319/3282 [3:37:59<1:31:25,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2320/3282 [3:38:04<1:28:06,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2321/3282 [3:38:09<1:26:35,  5.41s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2322/3282 [3:38:15<1:26:53,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2323/3282 [3:38:20<1:26:34,  5.42s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2324/3282 [3:38:25<1:22:28,  5.16s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2325/3282 [3:38:31<1:26:35,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2326/3282 [3:38:37<1:28:43,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2327/3282 [3:38:42<1:27:45,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2328/3282 [3:38:48<1:29:33,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2329/3282 [3:38:53<1:27:49,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2330/3282 [3:38:59<1:29:32,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2331/3282 [3:39:05<1:29:56,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2332/3282 [3:39:11<1:31:09,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2333/3282 [3:39:17<1:30:38,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2334/3282 [3:39:22<1:31:23,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2335/3282 [3:39:29<1:32:32,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2336/3282 [3:39:34<1:30:45,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2337/3282 [3:39:40<1:30:44,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2338/3282 [3:39:46<1:32:25,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████▏  | 2339/3282 [3:39:52<1:31:00,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████▏  | 2340/3282 [3:39:57<1:29:29,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████▏  | 2341/3282 [3:40:03<1:31:24,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████▏  | 2342/3282 [3:40:09<1:30:11,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████▏  | 2343/3282 [3:40:13<1:24:07,  5.38s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████▏  | 2344/3282 [3:40:19<1:24:05,  5.38s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████▏  | 2345/3282 [3:40:24<1:25:20,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████▏  | 2346/3282 [3:40:30<1:27:17,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2347/3282 [3:40:35<1:24:55,  5.45s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2348/3282 [3:40:41<1:24:30,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2349/3282 [3:40:45<1:20:52,  5.20s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2350/3282 [3:40:51<1:21:13,  5.23s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2351/3282 [3:40:57<1:24:15,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2352/3282 [3:41:02<1:25:39,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2353/3282 [3:41:08<1:26:10,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2354/3282 [3:41:13<1:25:13,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2355/3282 [3:41:19<1:26:14,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2356/3282 [3:41:25<1:25:41,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2357/3282 [3:41:31<1:28:57,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2358/3282 [3:41:37<1:28:47,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2359/3282 [3:41:42<1:28:09,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2360/3282 [3:41:48<1:28:07,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2361/3282 [3:41:54<1:28:53,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2362/3282 [3:41:59<1:26:04,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2363/3282 [3:42:05<1:28:20,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2364/3282 [3:42:11<1:26:53,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2365/3282 [3:42:16<1:26:43,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2366/3282 [3:42:22<1:27:39,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2367/3282 [3:42:28<1:29:16,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2368/3282 [3:42:34<1:27:54,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2369/3282 [3:42:40<1:26:52,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2370/3282 [3:42:45<1:24:27,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2371/3282 [3:42:50<1:24:00,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2372/3282 [3:42:55<1:21:11,  5.35s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2373/3282 [3:43:01<1:22:04,  5.42s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2374/3282 [3:43:07<1:24:47,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2375/3282 [3:43:13<1:26:42,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2376/3282 [3:43:19<1:27:35,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2377/3282 [3:43:24<1:26:02,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2378/3282 [3:43:30<1:27:51,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2379/3282 [3:43:36<1:28:42,  5.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2380/3282 [3:43:42<1:26:20,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2381/3282 [3:43:47<1:25:53,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2382/3282 [3:43:53<1:24:16,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2383/3282 [3:43:58<1:24:22,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2384/3282 [3:44:04<1:23:34,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2385/3282 [3:44:09<1:22:36,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2386/3282 [3:44:15<1:21:05,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2387/3282 [3:44:20<1:22:27,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2388/3282 [3:44:26<1:24:02,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2389/3282 [3:44:32<1:24:26,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2390/3282 [3:44:38<1:23:51,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2391/3282 [3:44:43<1:23:51,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2392/3282 [3:44:49<1:23:48,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2393/3282 [3:44:54<1:22:30,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2394/3282 [3:45:00<1:21:59,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2395/3282 [3:45:05<1:21:14,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2396/3282 [3:45:11<1:21:52,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2397/3282 [3:45:17<1:24:16,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2398/3282 [3:45:22<1:21:32,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2399/3282 [3:45:28<1:24:03,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2400/3282 [3:45:34<1:26:12,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2401/3282 [3:45:40<1:25:11,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2402/3282 [3:45:46<1:24:04,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2403/3282 [3:45:51<1:24:53,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2404/3282 [3:45:57<1:25:28,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2405/3282 [3:46:03<1:25:36,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2406/3282 [3:46:09<1:24:14,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2407/3282 [3:46:15<1:26:03,  5.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2408/3282 [3:46:20<1:23:17,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2409/3282 [3:46:26<1:24:37,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2410/3282 [3:46:32<1:23:50,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2411/3282 [3:46:38<1:24:34,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2412/3282 [3:46:44<1:25:46,  5.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▎  | 2413/3282 [3:46:50<1:25:49,  5.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▎  | 2414/3282 [3:46:55<1:22:36,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▎  | 2415/3282 [3:47:01<1:24:18,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▎  | 2416/3282 [3:47:07<1:25:05,  5.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▎  | 2417/3282 [3:47:13<1:24:25,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▎  | 2418/3282 [3:47:19<1:24:29,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▎  | 2419/3282 [3:47:25<1:23:53,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▎  | 2420/3282 [3:47:30<1:22:38,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2421/3282 [3:47:37<1:23:46,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2422/3282 [3:47:42<1:22:58,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2423/3282 [3:47:48<1:24:18,  5.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2424/3282 [3:47:54<1:24:52,  5.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2425/3282 [3:48:00<1:23:59,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2426/3282 [3:48:06<1:23:59,  5.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2427/3282 [3:48:12<1:23:57,  5.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2428/3282 [3:48:18<1:23:53,  5.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2429/3282 [3:48:24<1:24:02,  5.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2430/3282 [3:48:29<1:22:51,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2431/3282 [3:48:35<1:22:24,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2432/3282 [3:48:41<1:21:18,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2433/3282 [3:48:46<1:20:56,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2434/3282 [3:48:52<1:20:59,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2435/3282 [3:48:57<1:18:39,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2436/3282 [3:49:03<1:17:49,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2437/3282 [3:49:08<1:15:15,  5.34s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2438/3282 [3:49:13<1:16:54,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2439/3282 [3:49:19<1:17:37,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2440/3282 [3:49:25<1:19:42,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2441/3282 [3:49:31<1:18:44,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2442/3282 [3:49:36<1:18:27,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2443/3282 [3:49:41<1:17:02,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2444/3282 [3:49:47<1:17:58,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2445/3282 [3:49:53<1:19:26,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2446/3282 [3:49:59<1:18:25,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2447/3282 [3:50:04<1:18:04,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2448/3282 [3:50:09<1:15:32,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2449/3282 [3:50:15<1:16:00,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2450/3282 [3:50:20<1:16:03,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2451/3282 [3:50:26<1:16:21,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2452/3282 [3:50:32<1:18:13,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2453/3282 [3:50:38<1:18:34,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2454/3282 [3:50:43<1:18:24,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2455/3282 [3:50:49<1:18:16,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2456/3282 [3:50:54<1:14:02,  5.38s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2457/3282 [3:50:59<1:13:37,  5.35s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2458/3282 [3:51:05<1:15:16,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2459/3282 [3:51:11<1:17:55,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2460/3282 [3:51:17<1:18:14,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2461/3282 [3:51:22<1:16:52,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2462/3282 [3:51:28<1:17:59,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2463/3282 [3:51:34<1:17:43,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2464/3282 [3:51:39<1:17:29,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2465/3282 [3:51:45<1:16:11,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2466/3282 [3:51:51<1:17:58,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2467/3282 [3:51:56<1:17:36,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2468/3282 [3:52:02<1:17:17,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2469/3282 [3:52:08<1:17:27,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2470/3282 [3:52:14<1:18:10,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2471/3282 [3:52:19<1:16:54,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2472/3282 [3:52:25<1:17:08,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2473/3282 [3:52:31<1:16:05,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2474/3282 [3:52:36<1:15:24,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2475/3282 [3:52:42<1:18:09,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2476/3282 [3:52:48<1:19:03,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2477/3282 [3:52:54<1:19:06,  5.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2478/3282 [3:53:00<1:18:26,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2479/3282 [3:53:06<1:18:32,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2480/3282 [3:53:12<1:18:37,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2481/3282 [3:53:18<1:19:12,  5.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2482/3282 [3:53:23<1:15:52,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2483/3282 [3:53:29<1:16:42,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2484/3282 [3:53:35<1:17:47,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2485/3282 [3:53:41<1:17:56,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2486/3282 [3:53:47<1:18:34,  5.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2487/3282 [3:53:52<1:16:01,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2488/3282 [3:53:58<1:15:20,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2489/3282 [3:54:04<1:16:16,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2490/3282 [3:54:09<1:15:21,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2491/3282 [3:54:15<1:16:36,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2492/3282 [3:54:21<1:15:34,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2493/3282 [3:54:26<1:13:23,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2494/3282 [3:54:32<1:13:17,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2495/3282 [3:54:37<1:13:33,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2496/3282 [3:54:44<1:15:10,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2497/3282 [3:54:49<1:12:58,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2498/3282 [3:54:55<1:14:11,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2499/3282 [3:55:01<1:15:10,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2500/3282 [3:55:07<1:15:41,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2501/3282 [3:55:12<1:14:20,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2502/3282 [3:55:17<1:11:36,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▋  | 2503/3282 [3:55:23<1:13:05,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▋  | 2504/3282 [3:55:29<1:14:38,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▋  | 2505/3282 [3:55:35<1:15:11,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▋  | 2506/3282 [3:55:40<1:13:29,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▋  | 2507/3282 [3:55:46<1:13:41,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▋  | 2508/3282 [3:55:52<1:14:32,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▋  | 2509/3282 [3:55:58<1:15:46,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▋  | 2510/3282 [3:56:03<1:10:36,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2511/3282 [3:56:08<1:08:24,  5.32s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2512/3282 [3:56:13<1:09:15,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2513/3282 [3:56:19<1:10:31,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2514/3282 [3:56:25<1:11:24,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2515/3282 [3:56:31<1:13:22,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2516/3282 [3:56:36<1:11:36,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2517/3282 [3:56:42<1:13:10,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2518/3282 [3:56:48<1:12:47,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2519/3282 [3:56:54<1:14:33,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2520/3282 [3:57:00<1:13:42,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2521/3282 [3:57:05<1:13:25,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2522/3282 [3:57:11<1:13:13,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2523/3282 [3:57:17<1:12:19,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2524/3282 [3:57:22<1:11:39,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2525/3282 [3:57:28<1:11:10,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2526/3282 [3:57:33<1:10:07,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2527/3282 [3:57:39<1:09:22,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2528/3282 [3:57:45<1:10:48,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2529/3282 [3:57:50<1:10:29,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2530/3282 [3:57:56<1:10:13,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2531/3282 [3:58:01<1:08:38,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2532/3282 [3:58:06<1:08:12,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2533/3282 [3:58:12<1:06:51,  5.36s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2534/3282 [3:58:17<1:05:52,  5.28s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2535/3282 [3:58:22<1:06:32,  5.34s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2536/3282 [3:58:28<1:09:22,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2537/3282 [3:58:34<1:08:35,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2538/3282 [3:58:39<1:09:21,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2539/3282 [3:58:46<1:11:16,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2540/3282 [3:58:51<1:11:55,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2541/3282 [3:58:57<1:10:56,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2542/3282 [3:59:03<1:10:32,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2543/3282 [3:59:07<1:06:54,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2544/3282 [3:59:13<1:08:48,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2545/3282 [3:59:18<1:06:36,  5.42s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2546/3282 [3:59:24<1:05:43,  5.36s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2547/3282 [3:59:29<1:07:06,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2548/3282 [3:59:36<1:10:00,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2549/3282 [3:59:41<1:07:02,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2550/3282 [3:59:46<1:06:55,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2551/3282 [3:59:51<1:04:29,  5.29s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2552/3282 [3:59:57<1:05:45,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2553/3282 [4:00:03<1:07:36,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2554/3282 [4:00:08<1:07:52,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2555/3282 [4:00:14<1:07:00,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2556/3282 [4:00:18<1:03:47,  5.27s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2557/3282 [4:00:24<1:05:26,  5.42s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2558/3282 [4:00:30<1:06:31,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2559/3282 [4:00:36<1:07:48,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2560/3282 [4:00:41<1:06:29,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2561/3282 [4:00:47<1:06:33,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2562/3282 [4:00:52<1:07:12,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2563/3282 [4:00:58<1:08:20,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2564/3282 [4:01:04<1:07:44,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2565/3282 [4:01:10<1:08:29,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2566/3282 [4:01:15<1:08:28,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2567/3282 [4:01:21<1:07:44,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2568/3282 [4:01:27<1:07:51,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2569/3282 [4:01:32<1:06:17,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2570/3282 [4:01:38<1:05:47,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2571/3282 [4:01:43<1:04:07,  5.41s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2572/3282 [4:01:48<1:04:17,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2573/3282 [4:01:53<1:01:49,  5.23s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2574/3282 [4:01:59<1:04:04,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2575/3282 [4:02:04<1:02:30,  5.30s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2576/3282 [4:02:09<1:02:02,  5.27s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▊  | 2577/3282 [4:02:15<1:04:10,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▊  | 2578/3282 [4:02:21<1:04:47,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▊  | 2579/3282 [4:02:26<1:05:14,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▊  | 2580/3282 [4:02:32<1:06:48,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▊  | 2581/3282 [4:02:38<1:06:13,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▊  | 2582/3282 [4:02:43<1:04:10,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▊  | 2583/3282 [4:02:49<1:04:40,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▊  | 2584/3282 [4:02:54<1:04:58,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2585/3282 [4:03:00<1:05:29,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2586/3282 [4:03:06<1:05:48,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2587/3282 [4:03:12<1:05:59,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2588/3282 [4:03:17<1:04:52,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2589/3282 [4:03:22<1:01:12,  5.30s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2590/3282 [4:03:27<1:02:44,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2591/3282 [4:03:33<1:03:44,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2592/3282 [4:03:38<1:01:15,  5.33s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2593/3282 [4:03:43<1:00:08,  5.24s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2594/3282 [4:03:48<59:03,  5.15s/question]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2595/3282 [4:03:53<59:29,  5.20s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2596/3282 [4:03:59<1:00:07,  5.26s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2597/3282 [4:04:04<1:00:29,  5.30s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2598/3282 [4:04:10<1:03:48,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2599/3282 [4:04:16<1:04:47,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2600/3282 [4:04:21<1:02:44,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2601/3282 [4:04:27<1:02:53,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2602/3282 [4:04:33<1:04:02,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2603/3282 [4:04:39<1:04:49,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2604/3282 [4:04:44<1:03:34,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2605/3282 [4:04:50<1:04:26,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2606/3282 [4:04:55<1:01:41,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2607/3282 [4:05:00<1:01:37,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2608/3282 [4:05:06<1:03:27,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2609/3282 [4:05:12<1:03:02,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2610/3282 [4:05:18<1:04:22,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2611/3282 [4:05:24<1:04:46,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2612/3282 [4:05:30<1:04:32,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2613/3282 [4:05:35<1:03:06,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2614/3282 [4:05:41<1:03:01,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2615/3282 [4:05:46<1:02:55,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2616/3282 [4:05:52<1:03:06,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2617/3282 [4:05:58<1:03:53,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2618/3282 [4:06:04<1:03:28,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2619/3282 [4:06:09<1:01:36,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2620/3282 [4:06:14<1:00:37,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2621/3282 [4:06:20<1:00:29,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2622/3282 [4:06:25<1:01:17,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2623/3282 [4:06:31<59:23,  5.41s/question]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2624/3282 [4:06:37<1:01:59,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2625/3282 [4:06:43<1:02:53,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2626/3282 [4:06:48<1:02:50,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2627/3282 [4:06:54<1:03:26,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2628/3282 [4:07:00<1:02:16,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2629/3282 [4:07:05<1:00:34,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2630/3282 [4:07:11<1:01:06,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2631/3282 [4:07:17<1:01:27,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2632/3282 [4:07:23<1:02:18,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2633/3282 [4:07:28<1:01:37,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2634/3282 [4:07:34<1:01:07,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2635/3282 [4:07:39<1:00:45,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2636/3282 [4:07:45<1:00:10,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2637/3282 [4:07:50<1:00:00,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2638/3282 [4:07:56<59:00,  5.50s/question]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2639/3282 [4:08:01<58:34,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2640/3282 [4:08:07<59:26,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2641/3282 [4:08:12<58:48,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2642/3282 [4:08:18<59:32,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2643/3282 [4:08:24<1:00:29,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2644/3282 [4:08:30<1:00:20,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2645/3282 [4:08:35<59:02,  5.56s/question]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2646/3282 [4:08:40<58:07,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2647/3282 [4:08:46<59:35,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2648/3282 [4:08:52<1:00:31,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2649/3282 [4:08:58<1:00:32,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2650/3282 [4:09:03<59:38,  5.66s/question]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2651/3282 [4:09:09<1:00:45,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2652/3282 [4:09:15<1:01:16,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2653/3282 [4:09:20<58:05,  5.54s/question]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2654/3282 [4:09:25<55:15,  5.28s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2655/3282 [4:09:30<54:38,  5.23s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2656/3282 [4:09:35<54:46,  5.25s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2657/3282 [4:09:41<57:10,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2658/3282 [4:09:46<55:40,  5.35s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2659/3282 [4:09:52<57:18,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2660/3282 [4:09:58<58:25,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2661/3282 [4:10:04<58:25,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2662/3282 [4:10:09<58:22,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2663/3282 [4:10:15<59:06,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2664/3282 [4:10:22<1:00:14,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2665/3282 [4:10:27<1:00:19,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2666/3282 [4:10:33<59:01,  5.75s/question]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████▏ | 2667/3282 [4:10:37<55:19,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████▏ | 2668/3282 [4:10:43<54:38,  5.34s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████▏ | 2669/3282 [4:10:48<53:54,  5.28s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████▏ | 2670/3282 [4:10:54<55:16,  5.42s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████▏ | 2671/3282 [4:11:00<57:04,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████▏ | 2672/3282 [4:11:06<58:32,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████▏ | 2673/3282 [4:11:12<59:16,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████▏ | 2674/3282 [4:11:18<59:46,  5.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2675/3282 [4:11:23<58:24,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2676/3282 [4:11:29<58:14,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2677/3282 [4:11:35<57:15,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2678/3282 [4:11:40<57:05,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2679/3282 [4:11:45<55:01,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2680/3282 [4:11:51<55:12,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2681/3282 [4:11:56<55:52,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2682/3282 [4:12:02<55:45,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2683/3282 [4:12:08<55:39,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2684/3282 [4:12:13<54:11,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2685/3282 [4:12:19<56:10,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2686/3282 [4:12:25<57:18,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2687/3282 [4:12:31<56:39,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2688/3282 [4:12:36<55:52,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2689/3282 [4:12:42<55:36,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2690/3282 [4:12:47<54:50,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2691/3282 [4:12:53<55:21,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2692/3282 [4:12:59<56:06,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2693/3282 [4:13:04<55:53,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2694/3282 [4:13:11<57:17,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2695/3282 [4:13:16<57:29,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2696/3282 [4:13:23<58:19,  5.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2697/3282 [4:13:28<57:17,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2698/3282 [4:13:33<54:57,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2699/3282 [4:13:39<55:59,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2700/3282 [4:13:45<55:50,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2701/3282 [4:13:51<55:41,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2702/3282 [4:13:57<55:35,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2703/3282 [4:14:03<56:50,  5.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2704/3282 [4:14:07<51:04,  5.30s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2705/3282 [4:14:13<52:01,  5.41s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2706/3282 [4:14:18<52:54,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2707/3282 [4:14:24<54:33,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2708/3282 [4:14:30<55:12,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2709/3282 [4:14:36<55:39,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2710/3282 [4:14:41<53:31,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2711/3282 [4:14:47<53:35,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2712/3282 [4:14:53<53:36,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2713/3282 [4:14:59<54:52,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2714/3282 [4:15:04<53:39,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2715/3282 [4:15:10<53:33,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2716/3282 [4:15:15<51:39,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2717/3282 [4:15:21<52:21,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2718/3282 [4:15:26<52:17,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2719/3282 [4:15:32<51:59,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2720/3282 [4:15:37<52:14,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2721/3282 [4:15:43<53:04,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2722/3282 [4:15:49<52:40,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2723/3282 [4:15:54<52:23,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2724/3282 [4:16:01<53:27,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2725/3282 [4:16:06<53:06,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2726/3282 [4:16:12<53:38,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2727/3282 [4:16:17<50:25,  5.45s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2728/3282 [4:16:22<50:53,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2729/3282 [4:16:28<52:00,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2730/3282 [4:16:34<51:58,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2731/3282 [4:16:40<52:57,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2732/3282 [4:16:46<53:49,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2733/3282 [4:16:52<54:51,  6.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2734/3282 [4:16:58<53:37,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2735/3282 [4:17:04<54:41,  6.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2736/3282 [4:17:10<52:54,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2737/3282 [4:17:15<52:24,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2738/3282 [4:17:19<47:32,  5.24s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2739/3282 [4:17:25<47:50,  5.29s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2740/3282 [4:17:30<48:01,  5.32s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▎ | 2741/3282 [4:17:36<48:38,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▎ | 2742/3282 [4:17:42<49:30,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▎ | 2743/3282 [4:17:47<50:37,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▎ | 2744/3282 [4:17:53<49:20,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▎ | 2745/3282 [4:17:58<49:40,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▎ | 2746/3282 [4:18:04<50:38,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▎ | 2747/3282 [4:18:10<50:16,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▎ | 2748/3282 [4:18:16<50:52,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2749/3282 [4:18:22<51:51,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2750/3282 [4:18:28<51:56,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2751/3282 [4:18:33<48:53,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2752/3282 [4:18:38<48:54,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2753/3282 [4:18:44<49:54,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2754/3282 [4:18:50<50:48,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2755/3282 [4:18:56<51:09,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2756/3282 [4:19:02<52:15,  5.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2757/3282 [4:19:07<48:30,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2758/3282 [4:19:13<49:54,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2759/3282 [4:19:18<47:18,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2760/3282 [4:19:24<48:47,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2761/3282 [4:19:30<49:02,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2762/3282 [4:19:35<48:56,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2763/3282 [4:19:41<49:37,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2764/3282 [4:19:47<49:56,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2765/3282 [4:19:53<50:07,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2766/3282 [4:19:59<50:34,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2767/3282 [4:20:04<48:57,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2768/3282 [4:20:10<48:58,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2769/3282 [4:20:16<48:29,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2770/3282 [4:20:21<48:21,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2771/3282 [4:20:27<48:27,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2772/3282 [4:20:32<47:33,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2773/3282 [4:20:38<48:14,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2774/3282 [4:20:44<47:20,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2775/3282 [4:20:49<48:02,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2776/3282 [4:20:55<48:35,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2777/3282 [4:21:01<47:58,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2778/3282 [4:21:07<47:45,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2779/3282 [4:21:12<47:34,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2780/3282 [4:21:18<48:04,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2781/3282 [4:21:23<46:23,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2782/3282 [4:21:29<46:19,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2783/3282 [4:21:35<47:25,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2784/3282 [4:21:41<48:09,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2785/3282 [4:21:47<47:41,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2786/3282 [4:21:53<48:03,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2787/3282 [4:21:58<46:00,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2788/3282 [4:22:04<47:03,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2789/3282 [4:22:09<46:08,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2790/3282 [4:22:15<46:09,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2791/3282 [4:22:20<45:53,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2792/3282 [4:22:26<45:41,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2793/3282 [4:22:31<45:18,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2794/3282 [4:22:37<46:35,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2795/3282 [4:22:43<46:34,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2796/3282 [4:22:48<45:21,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2797/3282 [4:22:53<43:12,  5.35s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2798/3282 [4:22:59<44:35,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2799/3282 [4:23:05<44:48,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2800/3282 [4:23:11<45:09,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2801/3282 [4:23:16<44:42,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2802/3282 [4:23:21<44:21,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2803/3282 [4:23:27<45:06,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2804/3282 [4:23:33<45:37,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2805/3282 [4:23:39<46:15,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2806/3282 [4:23:45<46:00,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2807/3282 [4:23:51<45:46,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2808/3282 [4:23:56<44:18,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2809/3282 [4:24:02<44:54,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2810/3282 [4:24:08<44:56,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2811/3282 [4:24:14<45:16,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2812/3282 [4:24:19<44:54,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2813/3282 [4:24:25<44:13,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2814/3282 [4:24:31<45:12,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2815/3282 [4:24:36<44:47,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2816/3282 [4:24:42<44:40,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2817/3282 [4:24:48<44:33,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2818/3282 [4:24:52<40:51,  5.28s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2819/3282 [4:24:58<42:42,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2820/3282 [4:25:04<42:41,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2821/3282 [4:25:09<41:34,  5.41s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2822/3282 [4:25:13<38:56,  5.08s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2823/3282 [4:25:18<37:16,  4.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2824/3282 [4:25:24<40:14,  5.27s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2825/3282 [4:25:29<40:38,  5.34s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2826/3282 [4:25:35<41:56,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2827/3282 [4:25:41<42:09,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2828/3282 [4:25:47<42:49,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2829/3282 [4:25:52<42:17,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2830/3282 [4:25:58<41:30,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▋ | 2831/3282 [4:26:03<41:46,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▋ | 2832/3282 [4:26:09<42:06,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▋ | 2833/3282 [4:26:15<41:53,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▋ | 2834/3282 [4:26:20<42:07,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▋ | 2835/3282 [4:26:26<41:13,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▋ | 2836/3282 [4:26:31<41:13,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▋ | 2837/3282 [4:26:37<41:10,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▋ | 2838/3282 [4:26:43<41:50,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2839/3282 [4:26:48<40:20,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2840/3282 [4:26:54<41:31,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2841/3282 [4:27:00<42:05,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2842/3282 [4:27:05<41:01,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2843/3282 [4:27:11<41:41,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2844/3282 [4:27:16<39:43,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2845/3282 [4:27:20<37:30,  5.15s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2846/3282 [4:27:25<37:32,  5.17s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2847/3282 [4:27:31<39:21,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2848/3282 [4:27:37<40:35,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2849/3282 [4:27:43<41:07,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2850/3282 [4:27:49<41:27,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2851/3282 [4:27:55<41:40,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2852/3282 [4:28:01<41:16,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2853/3282 [4:28:06<40:23,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2854/3282 [4:28:12<40:08,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2855/3282 [4:28:17<39:32,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2856/3282 [4:28:23<39:28,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2857/3282 [4:28:28<39:48,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2858/3282 [4:28:34<40:18,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2859/3282 [4:28:40<39:44,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2860/3282 [4:28:45<38:44,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2861/3282 [4:28:51<39:35,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2862/3282 [4:28:57<40:02,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2863/3282 [4:29:03<39:49,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2864/3282 [4:29:09<40:15,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2865/3282 [4:29:14<39:43,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2866/3282 [4:29:20<39:42,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2867/3282 [4:29:26<40:37,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2868/3282 [4:29:32<39:53,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2869/3282 [4:29:37<39:10,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2870/3282 [4:29:43<39:32,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2871/3282 [4:29:49<39:50,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2872/3282 [4:29:55<40:01,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2873/3282 [4:30:01<40:00,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2874/3282 [4:30:07<40:14,  5.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2875/3282 [4:30:13<39:49,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2876/3282 [4:30:18<38:23,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2877/3282 [4:30:23<37:11,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2878/3282 [4:30:28<37:02,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2879/3282 [4:30:34<37:05,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2880/3282 [4:30:40<38:22,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2881/3282 [4:30:46<38:56,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2882/3282 [4:30:52<39:05,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2883/3282 [4:30:58<39:05,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2884/3282 [4:31:04<39:27,  5.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2885/3282 [4:31:10<38:04,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2886/3282 [4:31:15<36:55,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2887/3282 [4:31:20<36:25,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2888/3282 [4:31:25<35:52,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2889/3282 [4:31:31<36:00,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2890/3282 [4:31:36<35:42,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2891/3282 [4:31:42<35:50,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2892/3282 [4:31:47<35:00,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2893/3282 [4:31:53<35:38,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2894/3282 [4:31:58<35:41,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2895/3282 [4:32:03<34:38,  5.37s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2896/3282 [4:32:09<35:35,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2897/3282 [4:32:16<36:39,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2898/3282 [4:32:22<37:13,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2899/3282 [4:32:27<36:08,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2900/3282 [4:32:33<36:31,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2901/3282 [4:32:39<36:59,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2902/3282 [4:32:45<37:03,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2903/3282 [4:32:51<37:20,  5.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2904/3282 [4:32:56<36:36,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▊ | 2905/3282 [4:33:02<35:52,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▊ | 2906/3282 [4:33:07<34:19,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▊ | 2907/3282 [4:33:13<35:36,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▊ | 2908/3282 [4:33:19<36:10,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▊ | 2909/3282 [4:33:25<36:16,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▊ | 2910/3282 [4:33:31<36:33,  5.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▊ | 2911/3282 [4:33:36<34:31,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▊ | 2912/3282 [4:33:42<35:25,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2913/3282 [4:33:47<34:50,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2914/3282 [4:33:52<33:05,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2915/3282 [4:33:58<32:58,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2916/3282 [4:34:02<31:53,  5.23s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2917/3282 [4:34:08<32:16,  5.30s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2918/3282 [4:34:14<33:00,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2919/3282 [4:34:18<31:30,  5.21s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2920/3282 [4:34:24<31:54,  5.29s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2921/3282 [4:34:30<32:56,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2922/3282 [4:34:35<33:01,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2923/3282 [4:34:41<32:23,  5.41s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2924/3282 [4:34:46<32:55,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2925/3282 [4:34:52<33:05,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2926/3282 [4:34:57<32:02,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2927/3282 [4:35:03<32:57,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2928/3282 [4:35:09<33:42,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2929/3282 [4:35:15<33:32,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2930/3282 [4:35:21<33:53,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2931/3282 [4:35:27<34:06,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2932/3282 [4:35:32<34:13,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2933/3282 [4:35:39<34:51,  5.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2934/3282 [4:35:45<34:51,  6.01s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2935/3282 [4:35:51<35:15,  6.10s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2936/3282 [4:35:56<32:59,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2937/3282 [4:36:02<33:17,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2938/3282 [4:36:07<32:10,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2939/3282 [4:36:13<32:01,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2940/3282 [4:36:18<32:11,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2941/3282 [4:36:24<32:37,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2942/3282 [4:36:30<32:48,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2943/3282 [4:36:36<32:53,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2944/3282 [4:36:42<32:12,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2945/3282 [4:36:48<32:26,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2946/3282 [4:36:54<33:05,  5.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2947/3282 [4:36:59<32:25,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2948/3282 [4:37:05<31:56,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2949/3282 [4:37:10<30:57,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2950/3282 [4:37:16<31:29,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2951/3282 [4:37:22<31:45,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2952/3282 [4:37:28<31:20,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2953/3282 [4:37:34<31:36,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2954/3282 [4:37:39<30:17,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2955/3282 [4:37:44<29:48,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2956/3282 [4:37:50<30:26,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2957/3282 [4:37:55<29:51,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2958/3282 [4:38:01<29:43,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2959/3282 [4:38:06<29:01,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2960/3282 [4:38:11<29:31,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2961/3282 [4:38:17<29:32,  5.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2962/3282 [4:38:23<30:16,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2963/3282 [4:38:29<30:00,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2964/3282 [4:38:34<30:05,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2965/3282 [4:38:40<30:21,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2966/3282 [4:38:46<30:52,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2967/3282 [4:38:52<31:04,  5.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2968/3282 [4:38:58<30:17,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2969/3282 [4:39:04<30:27,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2970/3282 [4:39:10<30:27,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2971/3282 [4:39:15<29:46,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2972/3282 [4:39:21<29:33,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2973/3282 [4:39:26<28:39,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2974/3282 [4:39:32<28:17,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2975/3282 [4:39:37<28:33,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2976/3282 [4:39:43<28:57,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2977/3282 [4:39:49<29:12,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2978/3282 [4:39:55<29:25,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2979/3282 [4:40:01<29:28,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2980/3282 [4:40:06<28:33,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2981/3282 [4:40:12<28:01,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2982/3282 [4:40:18<28:36,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2983/3282 [4:40:23<28:32,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2984/3282 [4:40:29<28:42,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2985/3282 [4:40:35<28:51,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2986/3282 [4:40:40<27:49,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2987/3282 [4:40:46<28:07,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2988/3282 [4:40:52<27:23,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2989/3282 [4:40:57<27:16,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2990/3282 [4:41:03<27:17,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2991/3282 [4:41:08<26:59,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2992/3282 [4:41:14<27:03,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2993/3282 [4:41:20<27:02,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2994/3282 [4:41:25<27:01,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████▏| 2995/3282 [4:41:31<26:57,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████▏| 2996/3282 [4:41:37<26:46,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████▏| 2997/3282 [4:41:42<27:09,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████▏| 2998/3282 [4:41:48<27:07,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████▏| 2999/3282 [4:41:54<26:48,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████▏| 3000/3282 [4:41:59<26:25,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████▏| 3001/3282 [4:42:05<26:48,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████▏| 3002/3282 [4:42:11<26:29,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████▏| 3003/3282 [4:42:17<26:48,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3004/3282 [4:42:23<27:05,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3005/3282 [4:42:29<26:52,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3006/3282 [4:42:34<25:55,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3007/3282 [4:42:40<26:12,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3008/3282 [4:42:45<25:54,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3009/3282 [4:42:50<24:48,  5.45s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3010/3282 [4:42:56<24:46,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3011/3282 [4:43:02<25:21,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3012/3282 [4:43:07<25:04,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3013/3282 [4:43:13<25:29,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3014/3282 [4:43:19<25:59,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3015/3282 [4:43:25<26:12,  5.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3016/3282 [4:43:31<26:18,  5.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3017/3282 [4:43:36<25:08,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3018/3282 [4:43:43<25:43,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3019/3282 [4:43:48<25:24,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3020/3282 [4:43:54<24:39,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3021/3282 [4:44:00<24:58,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3022/3282 [4:44:05<24:10,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3023/3282 [4:44:11<24:30,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3024/3282 [4:44:17<24:53,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3025/3282 [4:44:23<24:45,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3026/3282 [4:44:28<24:23,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3027/3282 [4:44:33<23:31,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3028/3282 [4:44:38<22:05,  5.22s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3029/3282 [4:44:44<22:53,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3030/3282 [4:44:50<23:34,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3031/3282 [4:44:55<23:12,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3032/3282 [4:45:01<23:37,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3033/3282 [4:45:07<23:31,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3034/3282 [4:45:13<23:59,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3035/3282 [4:45:19<24:17,  5.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3036/3282 [4:45:25<24:01,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3037/3282 [4:45:31<24:09,  5.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3038/3282 [4:45:36<23:12,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3039/3282 [4:45:41<22:43,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3040/3282 [4:45:47<22:42,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3041/3282 [4:45:53<22:56,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3042/3282 [4:45:59<22:47,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3043/3282 [4:46:04<22:13,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3044/3282 [4:46:10<22:41,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3045/3282 [4:46:15<22:12,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3046/3282 [4:46:21<22:30,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3047/3282 [4:46:27<22:01,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3048/3282 [4:46:33<22:25,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3049/3282 [4:46:38<21:47,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3050/3282 [4:46:44<22:11,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3051/3282 [4:46:50<21:53,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3052/3282 [4:46:55<21:13,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3053/3282 [4:47:01<21:54,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3054/3282 [4:47:07<21:36,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3055/3282 [4:47:12<21:48,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3056/3282 [4:47:18<21:10,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3057/3282 [4:47:23<20:24,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3058/3282 [4:47:29<20:53,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3059/3282 [4:47:34<20:40,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3060/3282 [4:47:40<20:47,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3061/3282 [4:47:45<20:32,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3062/3282 [4:47:51<20:48,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3063/3282 [4:47:57<20:42,  5.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3064/3282 [4:48:03<20:55,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3065/3282 [4:48:09<21:08,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3066/3282 [4:48:15<21:10,  5.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3067/3282 [4:48:20<20:14,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3068/3282 [4:48:26<19:52,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▎| 3069/3282 [4:48:31<20:08,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▎| 3070/3282 [4:48:37<20:06,  5.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▎| 3071/3282 [4:48:43<20:13,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▎| 3072/3282 [4:48:49<20:07,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▎| 3073/3282 [4:48:54<19:55,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▎| 3074/3282 [4:49:00<19:39,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▎| 3075/3282 [4:49:05<19:16,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▎| 3076/3282 [4:49:11<19:09,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3077/3282 [4:49:17<19:02,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3078/3282 [4:49:22<19:08,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3079/3282 [4:49:27<17:52,  5.28s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3080/3282 [4:49:32<18:09,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3081/3282 [4:49:38<18:03,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3082/3282 [4:49:44<18:31,  5.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3083/3282 [4:49:49<17:48,  5.37s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3084/3282 [4:49:54<17:17,  5.24s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3085/3282 [4:49:59<17:31,  5.34s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3086/3282 [4:50:04<17:23,  5.33s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3087/3282 [4:50:10<17:38,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3088/3282 [4:50:16<18:03,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3089/3282 [4:50:22<17:56,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3090/3282 [4:50:27<17:55,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3091/3282 [4:50:33<18:15,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3092/3282 [4:50:39<18:18,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3093/3282 [4:50:45<18:22,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3094/3282 [4:50:51<17:50,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3095/3282 [4:50:55<16:52,  5.41s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3096/3282 [4:51:00<16:14,  5.24s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3097/3282 [4:51:05<15:57,  5.17s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3098/3282 [4:51:11<16:23,  5.35s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3099/3282 [4:51:17<16:56,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3100/3282 [4:51:23<17:10,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3101/3282 [4:51:28<16:59,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3102/3282 [4:51:34<16:56,  5.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3103/3282 [4:51:39<16:31,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3104/3282 [4:51:45<16:49,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3105/3282 [4:51:51<16:29,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3106/3282 [4:51:57<16:42,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3107/3282 [4:52:02<16:30,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3108/3282 [4:52:08<16:06,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3109/3282 [4:52:14<16:26,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3110/3282 [4:52:20<16:31,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3111/3282 [4:52:26<16:40,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3112/3282 [4:52:31<16:30,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3113/3282 [4:52:37<16:35,  5.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3114/3282 [4:52:43<16:13,  5.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3115/3282 [4:52:49<16:15,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3116/3282 [4:52:55<16:23,  5.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3117/3282 [4:53:01<16:16,  5.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3118/3282 [4:53:06<15:48,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3119/3282 [4:53:12<15:40,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3120/3282 [4:53:18<15:28,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3121/3282 [4:53:23<14:44,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3122/3282 [4:53:28<14:11,  5.32s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3123/3282 [4:53:33<14:17,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3124/3282 [4:53:39<14:35,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3125/3282 [4:53:44<14:13,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3126/3282 [4:53:50<14:23,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3127/3282 [4:53:56<14:48,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3128/3282 [4:54:02<14:43,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3129/3282 [4:54:07<14:13,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3130/3282 [4:54:13<14:11,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3131/3282 [4:54:19<14:08,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3132/3282 [4:54:25<14:17,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3133/3282 [4:54:31<14:26,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3134/3282 [4:54:37<14:38,  5.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3135/3282 [4:54:42<14:20,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3136/3282 [4:54:47<13:13,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3137/3282 [4:54:53<13:18,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3138/3282 [4:54:59<13:46,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3139/3282 [4:55:03<12:50,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3140/3282 [4:55:08<12:14,  5.17s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3141/3282 [4:55:13<12:03,  5.13s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3142/3282 [4:55:19<12:12,  5.23s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3143/3282 [4:55:24<12:10,  5.26s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3144/3282 [4:55:29<12:10,  5.30s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3145/3282 [4:55:34<11:39,  5.11s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3146/3282 [4:55:40<12:07,  5.35s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3147/3282 [4:55:46<12:14,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3148/3282 [4:55:51<12:03,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3149/3282 [4:55:56<12:01,  5.42s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3150/3282 [4:56:02<12:14,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3151/3282 [4:56:08<12:16,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3152/3282 [4:56:14<12:21,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3153/3282 [4:56:20<12:17,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3154/3282 [4:56:25<12:13,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3155/3282 [4:56:31<12:08,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3156/3282 [4:56:36<11:46,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3157/3282 [4:56:41<11:02,  5.30s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3158/3282 [4:56:47<11:07,  5.38s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▋| 3159/3282 [4:56:52<11:12,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▋| 3160/3282 [4:56:58<11:23,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▋| 3161/3282 [4:57:04<11:19,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▋| 3162/3282 [4:57:08<10:39,  5.33s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▋| 3163/3282 [4:57:14<10:39,  5.38s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▋| 3164/3282 [4:57:20<10:41,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▋| 3165/3282 [4:57:25<10:54,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▋| 3166/3282 [4:57:31<10:51,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▋| 3167/3282 [4:57:37<10:47,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3168/3282 [4:57:42<10:39,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3169/3282 [4:57:47<10:01,  5.33s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3170/3282 [4:57:53<10:07,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3171/3282 [4:57:59<10:19,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3172/3282 [4:58:03<09:49,  5.36s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3173/3282 [4:58:10<10:06,  5.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3174/3282 [4:58:14<09:35,  5.32s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3175/3282 [4:58:20<09:52,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3176/3282 [4:58:26<10:05,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3177/3282 [4:58:32<09:49,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3178/3282 [4:58:38<09:48,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3179/3282 [4:58:43<09:23,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3180/3282 [4:58:49<09:35,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3181/3282 [4:58:55<09:37,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3182/3282 [4:59:00<09:37,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3183/3282 [4:59:06<09:37,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3184/3282 [4:59:12<09:23,  5.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3185/3282 [4:59:18<09:10,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3186/3282 [4:59:23<09:12,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3187/3282 [4:59:29<09:01,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3188/3282 [4:59:35<09:01,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3189/3282 [4:59:41<09:00,  5.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3190/3282 [4:59:47<08:57,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3191/3282 [4:59:52<08:43,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3192/3282 [4:59:58<08:33,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3193/3282 [5:00:04<08:36,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3194/3282 [5:00:10<08:33,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3195/3282 [5:00:16<08:37,  5.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3196/3282 [5:00:22<08:24,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3197/3282 [5:00:27<08:11,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3198/3282 [5:00:33<08:09,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3199/3282 [5:00:39<08:05,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3200/3282 [5:00:45<07:50,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3201/3282 [5:00:50<07:34,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3202/3282 [5:00:56<07:35,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3203/3282 [5:01:01<07:27,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3204/3282 [5:01:07<07:17,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3205/3282 [5:01:13<07:19,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3206/3282 [5:01:18<06:52,  5.42s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3207/3282 [5:01:24<06:58,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3208/3282 [5:01:30<07:01,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3209/3282 [5:01:35<06:51,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3210/3282 [5:01:41<06:51,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3211/3282 [5:01:47<06:42,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3212/3282 [5:01:52<06:31,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3213/3282 [5:01:58<06:27,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3214/3282 [5:02:03<06:13,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3215/3282 [5:02:08<06:05,  5.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3216/3282 [5:02:14<06:17,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3217/3282 [5:02:20<06:08,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3218/3282 [5:02:26<05:59,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3219/3282 [5:02:31<05:52,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3220/3282 [5:02:37<05:53,  5.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3221/3282 [5:02:43<05:49,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3222/3282 [5:02:49<05:52,  5.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3223/3282 [5:02:55<05:44,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3224/3282 [5:03:01<05:39,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3225/3282 [5:03:06<05:21,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3226/3282 [5:03:12<05:22,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3227/3282 [5:03:17<05:01,  5.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3228/3282 [5:03:22<04:51,  5.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3229/3282 [5:03:28<04:50,  5.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3230/3282 [5:03:33<04:46,  5.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3231/3282 [5:03:39<04:43,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3232/3282 [5:03:44<04:39,  5.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▊| 3233/3282 [5:03:50<04:29,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▊| 3234/3282 [5:03:56<04:30,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▊| 3235/3282 [5:04:01<04:23,  5.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▊| 3236/3282 [5:04:07<04:20,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▊| 3237/3282 [5:04:13<04:18,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▊| 3238/3282 [5:04:19<04:11,  5.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▊| 3239/3282 [5:04:23<03:49,  5.35s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▊| 3240/3282 [5:04:29<03:48,  5.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3241/3282 [5:04:35<03:48,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3242/3282 [5:04:40<03:43,  5.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3243/3282 [5:04:45<03:31,  5.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3244/3282 [5:04:51<03:27,  5.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3245/3282 [5:04:56<03:19,  5.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3246/3282 [5:05:02<03:21,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3247/3282 [5:05:08<03:19,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3248/3282 [5:05:14<03:16,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3249/3282 [5:05:19<03:05,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3250/3282 [5:05:25<03:00,  5.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3251/3282 [5:05:31<02:54,  5.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3252/3282 [5:05:36<02:46,  5.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3253/3282 [5:05:41<02:40,  5.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3254/3282 [5:05:48<02:39,  5.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3255/3282 [5:05:53<02:29,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3256/3282 [5:05:59<02:27,  5.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3257/3282 [5:06:04<02:19,  5.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3258/3282 [5:06:10<02:15,  5.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3259/3282 [5:06:16<02:12,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3260/3282 [5:06:22<02:06,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3261/3282 [5:06:28<02:02,  5.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3262/3282 [5:06:34<01:57,  5.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3263/3282 [5:06:39<01:51,  5.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3264/3282 [5:06:45<01:45,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3265/3282 [5:06:51<01:40,  5.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3266/3282 [5:06:57<01:34,  5.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3267/3282 [5:07:03<01:29,  5.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3268/3282 [5:07:09<01:21,  5.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3269/3282 [5:07:14<01:14,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3270/3282 [5:07:20<01:10,  5.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3271/3282 [5:07:26<01:03,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3272/3282 [5:07:32<00:57,  5.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3273/3282 [5:07:37<00:51,  5.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3274/3282 [5:07:43<00:46,  5.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3275/3282 [5:07:49<00:40,  5.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3276/3282 [5:07:55<00:35,  5.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3277/3282 [5:08:01<00:28,  5.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3278/3282 [5:08:06<00:21,  5.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3279/3282 [5:08:11<00:16,  5.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3280/3282 [5:08:17<00:11,  5.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3281/3282 [5:08:23<00:05,  5.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|██████████| 3282/3282 [5:08:29<00:00,  5.64s/question]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import csv\n\n# Open the CSV file in write mode\nwith open(\"output.csv\", \"w\", newline=\"\") as f:\n    writer = csv.writer(f)\n    \n    # Optional: Write a header if needed\n    writer.writerow([\"Prediction\"])\n\n    # Write each item from the predictions list\n    for item in predictions:\n        writer.writerow([item])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T22:28:52.781377Z","iopub.execute_input":"2024-11-17T22:28:52.782055Z","iopub.status.idle":"2024-11-17T22:28:52.832987Z","shell.execute_reply.started":"2024-11-17T22:28:52.782004Z","shell.execute_reply":"2024-11-17T22:28:52.831989Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"import csv\n\n# Open the CSV file in write mode\nwith open(\"true_output.csv\", \"w\", newline=\"\") as f:\n    writer = csv.writer(f)\n    \n    # Optional: Write a header if needed\n    writer.writerow([\"Prediction\"])\n\n    # Write each item from the predictions list\n    for item in test_dataset['Answer']:\n        writer.writerow([item])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T22:28:53.045342Z","iopub.execute_input":"2024-11-17T22:28:53.045668Z","iopub.status.idle":"2024-11-17T22:28:53.670330Z","shell.execute_reply.started":"2024-11-17T22:28:53.045634Z","shell.execute_reply":"2024-11-17T22:28:53.669335Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"!pip -q install evaluate\n!pip -q install rouge-score\n# Load ROUGE for evaluation\nimport evaluate\n\n# Load ROUGE for evaluation\nrouge = evaluate.load(\"rouge\")\n\n# Evaluate predictions\n\n\n# Prepare references (ground-truth answers)\nreferences = test_dataset['Answer']\n\n# Evaluate predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T17:20:21.082754Z","iopub.status.idle":"2024-11-17T17:20:21.083093Z","shell.execute_reply.started":"2024-11-17T17:20:21.082922Z","shell.execute_reply":"2024-11-17T17:20:21.082939Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scores = rouge.compute(predictions=predictions, references=references)\nprint(scores)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T17:20:21.084352Z","iopub.status.idle":"2024-11-17T17:20:21.084725Z","shell.execute_reply.started":"2024-11-17T17:20:21.084520Z","shell.execute_reply":"2024-11-17T17:20:21.084537Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bleu = evaluate.load(\"bleu\")\nscores = bleu.compute(predictions=predictions, references=references)\nprint(scores)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T17:20:21.086034Z","iopub.status.idle":"2024-11-17T17:20:21.086401Z","shell.execute_reply.started":"2024-11-17T17:20:21.086214Z","shell.execute_reply":"2024-11-17T17:20:21.086233Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\n\nmodel.eval()  # Set the model to evaluation mode\npredictions = []\nall_preds = []  # Ensure this is defined for appending predictions\ndevice = next(model.parameters()).device  # Ensure device compatibility\nbatch_size = 1  # Set a batch size if needed\n\nfor i, question in enumerate(tqdm(test_dataset, desc=\"Generating predictions\", unit=\"question\")):\n    # Prepare inputs for the model\n#     print(question)\n#     break\n    prompt = question['Question']\n#     instruction = f\"### Instruction: {prompt} \"\n#     print(instruction)\n    \n#     pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n#     result = pipe(instruction)\n#     print(result[0]['generated_text'][len(instruction):])\n\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n    outputs = model.generate(inputs['input_ids'], max_length=70)\n    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n    # Store the response\n#     print(response)\n#     print(response.split(instruction))\n    predictions.append(response)\n\n    # Optionally, append predictions to all_preds every 500 questions\n#     if (i + 1) % 500 == 0:\n#         all_preds.append(predictions)\n#     break\n# return predictions\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T17:20:21.087626Z","iopub.status.idle":"2024-11-17T17:20:21.087967Z","shell.execute_reply.started":"2024-11-17T17:20:21.087794Z","shell.execute_reply":"2024-11-17T17:20:21.087812Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T17:20:21.089188Z","iopub.status.idle":"2024-11-17T17:20:21.089563Z","shell.execute_reply.started":"2024-11-17T17:20:21.089355Z","shell.execute_reply":"2024-11-17T17:20:21.089389Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !pip -q install evaluate\n# !pip -q install rouge-score\n# # Load ROUGE for evaluation\n# import evaluate\n\n# # Load ROUGE for evaluation\n# rouge = evaluate.load(\"rouge\")\n\n# # Evaluate predictions\n\n\n# # Prepare references (ground-truth answers)\n# references = test_dataset['Answer']\n\n# # Evaluate predictions\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T17:20:21.090901Z","iopub.status.idle":"2024-11-17T17:20:21.091265Z","shell.execute_reply.started":"2024-11-17T17:20:21.091078Z","shell.execute_reply":"2024-11-17T17:20:21.091097Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# scores = rouge.compute(predictions=predictions, references=references)\n# print(scores)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T17:20:21.092253Z","iopub.status.idle":"2024-11-17T17:20:21.092611Z","shell.execute_reply.started":"2024-11-17T17:20:21.092415Z","shell.execute_reply":"2024-11-17T17:20:21.092432Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# bleu = evaluate.load(\"bleu\")\n# scores = bleu.compute(predictions=predictions, references=references)\n# print(scores)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T17:20:21.093474Z","iopub.status.idle":"2024-11-17T17:20:21.093838Z","shell.execute_reply.started":"2024-11-17T17:20:21.093661Z","shell.execute_reply":"2024-11-17T17:20:21.093679Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !pip install nltk\n# import nltk\n# nltk.download('wordnet')\n# nltk.download('omw-1.4')\n# meteor = evaluate.load(\"meteor\")\n# scores = meteor.compute(predictions=predictions, references=references)\n# print(scores)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T17:20:21.095405Z","iopub.status.idle":"2024-11-17T17:20:21.095800Z","shell.execute_reply.started":"2024-11-17T17:20:21.095606Z","shell.execute_reply":"2024-11-17T17:20:21.095627Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !pip -q install bert_score\n# from bert_score import score\n\n# P, R, F1 = score(predictions, references, lang=\"en\")\n# print(f\"BERTScore F1: {F1.mean().item()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T17:20:21.097234Z","iopub.status.idle":"2024-11-17T17:20:21.097616Z","shell.execute_reply.started":"2024-11-17T17:20:21.097412Z","shell.execute_reply":"2024-11-17T17:20:21.097431Z"}},"outputs":[],"execution_count":null}]}