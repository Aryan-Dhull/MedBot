{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"62f68fdb808b4f61b3ca1413149be8cd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6fff938c635447389f1da62a05335b73","IPY_MODEL_393029e4fb3647c08979241ec8e7d5d2","IPY_MODEL_697b2620933d4761b2fb152025f54422"],"layout":"IPY_MODEL_b2cba9d8253d4cb3bbed8e15f6012f16"}},"6fff938c635447389f1da62a05335b73":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1273d9a3ee0b4271813644f40622a61c","placeholder":"​","style":"IPY_MODEL_7ac400995146492aa08d221afd2f6fd9","value":"Loading checkpoint shards: 100%"}},"393029e4fb3647c08979241ec8e7d5d2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_25f68dab2a2c4b74a41a264439575e8d","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_16459c8ae7664b31858b3dba201f3801","value":2}},"697b2620933d4761b2fb152025f54422":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c95900b4a1934a909a491a06fc897cc5","placeholder":"​","style":"IPY_MODEL_f4bf55404ca048978eccf62a7861c1cc","value":" 2/2 [00:13&lt;00:00,  5.74s/it]"}},"b2cba9d8253d4cb3bbed8e15f6012f16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1273d9a3ee0b4271813644f40622a61c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ac400995146492aa08d221afd2f6fd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25f68dab2a2c4b74a41a264439575e8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16459c8ae7664b31858b3dba201f3801":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c95900b4a1934a909a491a06fc897cc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4bf55404ca048978eccf62a7861c1cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"224660411b33488b8070f702ee6f259e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_533e70493bde46319b2a701710bb7234","IPY_MODEL_af00cda72d8e4f7b80773a24fe9ff99e","IPY_MODEL_b3bb1699ac0a462bb20da1e759366a81"],"layout":"IPY_MODEL_f5236eb4124b44f282588e2051b4839e"}},"533e70493bde46319b2a701710bb7234":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1f6d333fa1d4c608107da2a49912dc0","placeholder":"​","style":"IPY_MODEL_f736aa29d82d49b391a2e9f240c59792","value":"Map: 100%"}},"af00cda72d8e4f7b80773a24fe9ff99e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ecc3ac785eea4ad693986b75fefe65cb","max":13125,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c431103e4134c4f8d81fa2229dba4a3","value":13125}},"b3bb1699ac0a462bb20da1e759366a81":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5266779c2967413d9fb32d3eb4373f65","placeholder":"​","style":"IPY_MODEL_b282da4544b849c1b1284ddb60126764","value":" 13125/13125 [00:17&lt;00:00, 1117.86 examples/s]"}},"f5236eb4124b44f282588e2051b4839e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1f6d333fa1d4c608107da2a49912dc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f736aa29d82d49b391a2e9f240c59792":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ecc3ac785eea4ad693986b75fefe65cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c431103e4134c4f8d81fa2229dba4a3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5266779c2967413d9fb32d3eb4373f65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b282da4544b849c1b1284ddb60126764":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e8f818c31eb4030808d35f91e93dbc4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99f13844164d42bca880ab298ae84869","IPY_MODEL_b504d9c7b0444967a18538634d1dfed5","IPY_MODEL_f78f68f0571b4c079cca8c4bf7c427fb"],"layout":"IPY_MODEL_3ebba0a98f1f470fb49606d6e422929b"}},"99f13844164d42bca880ab298ae84869":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f73f1b83156d4e6496f6fd481ef10931","placeholder":"​","style":"IPY_MODEL_9a6e8d194a4e464a81c958e940c51e05","value":"Map: 100%"}},"b504d9c7b0444967a18538634d1dfed5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a58c7c99d694c3197e1dec300f240eb","max":13125,"min":0,"orientation":"horizontal","style":"IPY_MODEL_27deb6ed10f64526a9a3d47b77612087","value":13125}},"f78f68f0571b4c079cca8c4bf7c427fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b296317f9d384eaab2652c115d90f57f","placeholder":"​","style":"IPY_MODEL_1f9c92ce500c4a9ba031421979c218de","value":" 13125/13125 [00:10&lt;00:00, 1467.15 examples/s]"}},"3ebba0a98f1f470fb49606d6e422929b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f73f1b83156d4e6496f6fd481ef10931":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a6e8d194a4e464a81c958e940c51e05":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a58c7c99d694c3197e1dec300f240eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27deb6ed10f64526a9a3d47b77612087":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b296317f9d384eaab2652c115d90f57f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f9c92ce500c4a9ba031421979c218de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b865ac44a9a8436a91c617d000d91848":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7df5a775d3cf468b90e069ca6a61be04","IPY_MODEL_65ea478d6eb64a9c8f5ab607b8c86d22","IPY_MODEL_6026ec7263dd40a1a8539eeef16725f0"],"layout":"IPY_MODEL_5ed79d8f9c2f490fadf7d3067f21f635"}},"7df5a775d3cf468b90e069ca6a61be04":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_31f46be033b44e60b00ec4dc3346cf21","placeholder":"​","style":"IPY_MODEL_667fb313df2b4a5b807c83453ef684f1","value":"Map: 100%"}},"65ea478d6eb64a9c8f5ab607b8c86d22":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f64805f9cb749de88315e3f76235ca2","max":13125,"min":0,"orientation":"horizontal","style":"IPY_MODEL_683bf4ba85e74a7da4f11f0fbbfce881","value":13125}},"6026ec7263dd40a1a8539eeef16725f0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9786d63b370248b1b0fad0b8b20d80d9","placeholder":"​","style":"IPY_MODEL_9a3f49090d464f6e9950f0fd3aabab67","value":" 13125/13125 [00:13&lt;00:00, 956.11 examples/s]"}},"5ed79d8f9c2f490fadf7d3067f21f635":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31f46be033b44e60b00ec4dc3346cf21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"667fb313df2b4a5b807c83453ef684f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f64805f9cb749de88315e3f76235ca2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"683bf4ba85e74a7da4f11f0fbbfce881":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9786d63b370248b1b0fad0b8b20d80d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a3f49090d464f6e9950f0fd3aabab67":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install and import the necessary libraries\n!pip install -q torch\n!pip install -q -U accelerate peft bitsandbytes transformers trl einops","metadata":{"id":"yQAVFua5xIP0","execution":{"iopub.status.busy":"2024-11-17T12:14:21.030025Z","iopub.execute_input":"2024-11-17T12:14:21.030350Z","iopub.status.idle":"2024-11-17T12:15:04.173572Z","shell.execute_reply.started":"2024-11-17T12:14:21.030311Z","shell.execute_reply":"2024-11-17T12:15:04.172318Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nfrom datasets import load_dataset\nfrom datasets import load_from_disk\nfrom peft import LoraConfig, prepare_model_for_kbit_training, PeftModel\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    GPTNeoForCausalLM, \n    GPT2Tokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    AutoTokenizer,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\n\nfrom trl import SFTTrainer","metadata":{"id":"qktqRakcz7KR","execution":{"iopub.status.busy":"2024-11-17T12:15:04.175452Z","iopub.execute_input":"2024-11-17T12:15:04.175800Z","iopub.status.idle":"2024-11-17T12:15:27.484167Z","shell.execute_reply.started":"2024-11-17T12:15:04.175763Z","shell.execute_reply":"2024-11-17T12:15:27.483393Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Model\nbase_model = \"EleutherAI/gpt-neo-2.7B\"\n\n# Tokenizer\ntokenizer = GPT2Tokenizer.from_pretrained(base_model)\ntokenizer.pad_token=tokenizer.eos_token\ntokenizer.padding_side=\"right\"","metadata":{"id":"XainoHg40CN8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1bd62b41-faf0-4443-e17c-c7c1aa461388","execution":{"iopub.status.busy":"2024-11-17T12:15:27.485473Z","iopub.execute_input":"2024-11-17T12:15:27.485939Z","iopub.status.idle":"2024-11-17T12:15:28.394480Z","shell.execute_reply.started":"2024-11-17T12:15:27.485895Z","shell.execute_reply":"2024-11-17T12:15:28.393724Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b53b31c71364d349a7d52eedcc1e3a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"323ff6da131842ed82230583d964a217"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79c3a316487c4621a666a89af4c9c13f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cedc494b43d432cb90564e3509aa7a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f7547db66914a24b81f799c1cd29422"}},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset, DatasetDict, Dataset\ndataset = load_dataset(\"keivalya/MedQuad-MedicalQnADataset\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Define a function to transform the dataset\ndef format_example(example):\n    # Use the specified format for text\n    example[\"text\"] = f\"### Instruction: {example['Question']} ### Assistant: {example['Answer']}\"\n    return example\n\ntrain_test_split = dataset['train'].train_test_split(test_size=0.2)\ntrain_dataset=train_test_split[\"train\"]\ntrain_dataset = train_dataset\ntest_dataset=train_test_split[\"test\"]\ntest_dataset = test_dataset\n\n# Apply the transformation to both the train and test datasets\ntrain_dataset = train_dataset.map(format_example)\n\n# Remove unnecessary columns and keep only the \"text\" column\ntrain_dataset = train_dataset.remove_columns([\"qtype\", \"Question\", \"Answer\"])\n# print(formatted_dataset)\n\n# Preview the dataset\nprint(train_dataset)\nprint(test_dataset)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j4ljJCJBBYq5","outputId":"98f308f9-6047-4ccd-a5d2-0d2782ecbbb6","execution":{"iopub.status.busy":"2024-11-17T12:15:28.396980Z","iopub.execute_input":"2024-11-17T12:15:28.397729Z","iopub.status.idle":"2024-11-17T12:15:32.117339Z","shell.execute_reply.started":"2024-11-17T12:15:28.397662Z","shell.execute_reply":"2024-11-17T12:15:32.116250Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/233 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37e0711e0ca44dcab949a700cb4a4839"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"medDataset_processed.csv:   0%|          | 0.00/22.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f73d7abd68f43d7b4fe8558c65b9afb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/16407 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9637b2789794b66ad51cfa55d07ca94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/13125 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"448cc62c55e742ff88d792a7254aacc3"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['text'],\n    num_rows: 13125\n})\nDataset({\n    features: ['qtype', 'Question', 'Answer'],\n    num_rows: 3282\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"# Quantization configuration\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=False,\n)\n\n# Load base moodel\nmodel = GPTNeoForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    trust_remote_code=True,\n    low_cpu_mem_usage=True,\n    device_map='auto',\n)","metadata":{"id":"ZBtEMcxWyhjM","colab":{"base_uri":"https://localhost:8080/","height":138,"referenced_widgets":["62f68fdb808b4f61b3ca1413149be8cd","6fff938c635447389f1da62a05335b73","393029e4fb3647c08979241ec8e7d5d2","697b2620933d4761b2fb152025f54422","b2cba9d8253d4cb3bbed8e15f6012f16","1273d9a3ee0b4271813644f40622a61c","7ac400995146492aa08d221afd2f6fd9","25f68dab2a2c4b74a41a264439575e8d","16459c8ae7664b31858b3dba201f3801","c95900b4a1934a909a491a06fc897cc5","f4bf55404ca048978eccf62a7861c1cc"]},"outputId":"c1ca4f4e-9ef2-4e30-f314-6145f58ddf14","execution":{"iopub.status.busy":"2024-11-17T12:15:32.119238Z","iopub.execute_input":"2024-11-17T12:15:32.119840Z","iopub.status.idle":"2024-11-17T12:16:30.124911Z","shell.execute_reply.started":"2024-11-17T12:15:32.119794Z","shell.execute_reply":"2024-11-17T12:16:30.123920Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/10.7G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b22041f51ed49be8adb0d373defee60"}},"metadata":{}}]},{"cell_type":"code","source":"model.config.use_cache = False\nmodel.config.pretraining_tp = 1\nmodel = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":243,"referenced_widgets":["224660411b33488b8070f702ee6f259e","533e70493bde46319b2a701710bb7234","af00cda72d8e4f7b80773a24fe9ff99e","b3bb1699ac0a462bb20da1e759366a81","f5236eb4124b44f282588e2051b4839e","b1f6d333fa1d4c608107da2a49912dc0","f736aa29d82d49b391a2e9f240c59792","ecc3ac785eea4ad693986b75fefe65cb","9c431103e4134c4f8d81fa2229dba4a3","5266779c2967413d9fb32d3eb4373f65","b282da4544b849c1b1284ddb60126764"]},"id":"2qGb6_AiF6ss","outputId":"eacee662-f469-4e70-d88b-14b33048eab1","execution":{"iopub.status.busy":"2024-11-17T12:16:30.126502Z","iopub.execute_input":"2024-11-17T12:16:30.127150Z","iopub.status.idle":"2024-11-17T12:16:30.157071Z","shell.execute_reply.started":"2024-11-17T12:16:30.127101Z","shell.execute_reply":"2024-11-17T12:16:30.156337Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Set training arguments\ntraining_arguments = TrainingArguments(\n    output_dir = \"./results\",\n    num_train_epochs = 1,\n    fp16 = False,\n    bf16 = False,\n    per_device_train_batch_size = 2,\n    per_device_eval_batch_size = 2,\n    gradient_accumulation_steps = 1,\n    gradient_checkpointing = True,\n    max_grad_norm = 0.3,\n    learning_rate = 2e-4,\n    weight_decay = 0.001,\n    optim = \"paged_adamw_32bit\",\n    lr_scheduler_type = \"cosine\",\n    max_steps = -1,\n    warmup_ratio = 0.03,\n    group_by_length = True,\n    save_steps = 0,\n    logging_steps = 100,\n)\n\n# LoRA configuration\npeft_config = LoraConfig(\n    r=64,                   #default=8\n    lora_alpha= 16,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules= [\"Wqkv\", \"out_proj\"] #[\"Wqkv\", \"fc1\", \"fc2\" ] # [\"Wqkv\", \"out_proj\", \"fc1\", \"fc2\" ]\n)\n","metadata":{"id":"2c8cNUYkGb3V","outputId":"2cb24bf2-f44f-4325-c5db-2f8ff663dc0d","colab":{"base_uri":"https://localhost:8080/","height":225,"referenced_widgets":["6e8f818c31eb4030808d35f91e93dbc4","99f13844164d42bca880ab298ae84869","b504d9c7b0444967a18538634d1dfed5","f78f68f0571b4c079cca8c4bf7c427fb","3ebba0a98f1f470fb49606d6e422929b","f73f1b83156d4e6496f6fd481ef10931","9a6e8d194a4e464a81c958e940c51e05","4a58c7c99d694c3197e1dec300f240eb","27deb6ed10f64526a9a3d47b77612087","b296317f9d384eaab2652c115d90f57f","1f9c92ce500c4a9ba031421979c218de"]},"execution":{"iopub.status.busy":"2024-11-17T12:16:30.158134Z","iopub.execute_input":"2024-11-17T12:16:30.158432Z","iopub.status.idle":"2024-11-17T12:16:34.087752Z","shell.execute_reply.started":"2024-11-17T12:16:30.158400Z","shell.execute_reply":"2024-11-17T12:16:34.086742Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#print_trainable_parameters(model)\n\n# Set supervised fine-tuning parameters\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=train_dataset,\n    peft_config=peft_config,\n    dataset_text_field=\"text\",\n    max_seq_length= 512,\n    tokenizer=tokenizer,\n    args=training_arguments,\n)","metadata":{"id":"d8ga7V-aGvBn","outputId":"b8af5204-d4c3-4b9e-b92f-9ab77067aed6","colab":{"base_uri":"https://localhost:8080/","height":225,"referenced_widgets":["b865ac44a9a8436a91c617d000d91848","7df5a775d3cf468b90e069ca6a61be04","65ea478d6eb64a9c8f5ab607b8c86d22","6026ec7263dd40a1a8539eeef16725f0","5ed79d8f9c2f490fadf7d3067f21f635","31f46be033b44e60b00ec4dc3346cf21","667fb313df2b4a5b807c83453ef684f1","3f64805f9cb749de88315e3f76235ca2","683bf4ba85e74a7da4f11f0fbbfce881","9786d63b370248b1b0fad0b8b20d80d9","9a3f49090d464f6e9950f0fd3aabab67"]},"execution":{"iopub.status.busy":"2024-11-17T12:16:34.088922Z","iopub.execute_input":"2024-11-17T12:16:34.089267Z","iopub.status.idle":"2024-11-17T12:17:13.791729Z","shell.execute_reply.started":"2024-11-17T12:16:34.089231Z","shell.execute_reply":"2024-11-17T12:17:13.790917Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/13125 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e261604138cd4a8884b9b9a618adbd87"}},"metadata":{}}]},{"cell_type":"code","source":"# Train model\ntrainer.train()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":362},"id":"45UAm35t0TKZ","outputId":"bf886eb6-00dd-4791-b40e-e0c50645afad","execution":{"iopub.status.busy":"2024-11-17T12:17:13.792853Z","iopub.execute_input":"2024-11-17T12:17:13.793176Z","iopub.status.idle":"2024-11-17T17:23:27.329630Z","shell.execute_reply.started":"2024-11-17T12:17:13.793141Z","shell.execute_reply":"2024-11-17T17:23:27.328748Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112619433333748, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc2145001d5a4573bb3315e16178aeec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241117_121757-8v0h8nf3</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/prerak21552-indraprastha-institute-of-information-techno/huggingface/runs/8v0h8nf3' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/prerak21552-indraprastha-institute-of-information-techno/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/prerak21552-indraprastha-institute-of-information-techno/huggingface' target=\"_blank\">https://wandb.ai/prerak21552-indraprastha-institute-of-information-techno/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/prerak21552-indraprastha-institute-of-information-techno/huggingface/runs/8v0h8nf3' target=\"_blank\">https://wandb.ai/prerak21552-indraprastha-institute-of-information-techno/huggingface/runs/8v0h8nf3</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6563' max='6563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6563/6563 5:05:21, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>2.124200</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.619700</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.539500</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.408200</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.349600</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.329300</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>1.295400</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>1.332900</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>1.343000</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.265900</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>1.235000</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>1.296200</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>1.298700</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>1.314200</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>1.297500</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>1.302200</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>1.296000</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>1.287100</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>1.277900</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>1.331200</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>1.326100</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>1.245300</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>1.216500</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>1.327000</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>1.290100</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>1.244100</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>1.246900</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>1.253400</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>1.234800</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>1.233200</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>1.255300</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>1.239700</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>1.306700</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>1.258100</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>1.293900</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>1.222200</td>\n    </tr>\n    <tr>\n      <td>3700</td>\n      <td>1.246400</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>1.235900</td>\n    </tr>\n    <tr>\n      <td>3900</td>\n      <td>1.213400</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>1.174200</td>\n    </tr>\n    <tr>\n      <td>4100</td>\n      <td>1.243600</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>1.175100</td>\n    </tr>\n    <tr>\n      <td>4300</td>\n      <td>1.259300</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>1.214400</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>1.182300</td>\n    </tr>\n    <tr>\n      <td>4600</td>\n      <td>1.283700</td>\n    </tr>\n    <tr>\n      <td>4700</td>\n      <td>1.234800</td>\n    </tr>\n    <tr>\n      <td>4800</td>\n      <td>1.220000</td>\n    </tr>\n    <tr>\n      <td>4900</td>\n      <td>1.175900</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>1.228200</td>\n    </tr>\n    <tr>\n      <td>5100</td>\n      <td>1.184200</td>\n    </tr>\n    <tr>\n      <td>5200</td>\n      <td>1.191800</td>\n    </tr>\n    <tr>\n      <td>5300</td>\n      <td>1.182500</td>\n    </tr>\n    <tr>\n      <td>5400</td>\n      <td>1.180500</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>1.221300</td>\n    </tr>\n    <tr>\n      <td>5600</td>\n      <td>1.203300</td>\n    </tr>\n    <tr>\n      <td>5700</td>\n      <td>1.214800</td>\n    </tr>\n    <tr>\n      <td>5800</td>\n      <td>1.266000</td>\n    </tr>\n    <tr>\n      <td>5900</td>\n      <td>1.206300</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>1.123300</td>\n    </tr>\n    <tr>\n      <td>6100</td>\n      <td>1.213000</td>\n    </tr>\n    <tr>\n      <td>6200</td>\n      <td>1.177900</td>\n    </tr>\n    <tr>\n      <td>6300</td>\n      <td>1.194600</td>\n    </tr>\n    <tr>\n      <td>6400</td>\n      <td>1.220000</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>1.142300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=6563, training_loss=1.2725923390862928, metrics={'train_runtime': 18368.6402, 'train_samples_per_second': 0.715, 'train_steps_per_second': 0.357, 'total_flos': 5.001239612802048e+16, 'train_loss': 1.2725923390862928, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.model.save_pretrained(\"./gptneo_finetuned_subjective/final_model\")","metadata":{"id":"MLMlfccP0Ur-","execution":{"iopub.status.busy":"2024-11-17T17:23:27.333158Z","iopub.execute_input":"2024-11-17T17:23:27.333573Z","iopub.status.idle":"2024-11-17T17:23:27.580851Z","shell.execute_reply.started":"2024-11-17T17:23:27.333539Z","shell.execute_reply":"2024-11-17T17:23:27.580077Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from peft import PeftModel\nf_model = PeftModel.from_pretrained(model,'/kaggle/working/gptneo_finetuned_subjective/final_model')\nf_model = f_model.merge_and_unload()","metadata":{"execution":{"iopub.status.busy":"2024-11-17T17:23:27.581901Z","iopub.execute_input":"2024-11-17T17:23:27.582196Z","iopub.status.idle":"2024-11-17T17:23:28.402263Z","shell.execute_reply.started":"2024-11-17T17:23:27.582164Z","shell.execute_reply":"2024-11-17T17:23:28.401288Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:336: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"print(test_dataset[0])","metadata":{"execution":{"iopub.status.busy":"2024-11-17T17:23:28.403652Z","iopub.execute_input":"2024-11-17T17:23:28.404398Z","iopub.status.idle":"2024-11-17T17:23:28.410976Z","shell.execute_reply.started":"2024-11-17T17:23:28.404353Z","shell.execute_reply":"2024-11-17T17:23:28.410134Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"{'qtype': 'frequency', 'Question': 'How many people are affected by microcephaly-capillary malformation syndrome ?', 'Answer': 'Microcephaly-capillary malformation syndrome is rare. About a dozen people have been diagnosed with the disorder.'}\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm import tqdm\n\nf_model.eval()  # Set the model to evaluation mode\npredictions = []\nall_preds = []  # Ensure this is defined for appending predictions\ndevice = next(f_model.parameters()).device  # Ensure device compatibility\nbatch_size = 1  # Set a batch size if needed\n\nfor i, question in enumerate(tqdm(test_dataset, desc=\"Generating predictions\", unit=\"question\")):\n    prompt = question['Question']\n\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n    outputs = f_model.generate(inputs['input_ids'], max_length=70)\n    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    predictions.append(response)","metadata":{"execution":{"iopub.status.busy":"2024-11-17T17:50:24.604374Z","iopub.execute_input":"2024-11-17T17:50:24.605240Z","iopub.status.idle":"2024-11-17T21:19:08.976083Z","shell.execute_reply.started":"2024-11-17T17:50:24.605198Z","shell.execute_reply":"2024-11-17T21:19:08.975202Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"Generating predictions:   0%|          | 0/3282 [00:00<?, ?question/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 1/3282 [00:03<3:30:32,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 2/3282 [00:07<3:25:29,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 3/3282 [00:11<3:19:03,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 4/3282 [00:14<3:20:27,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 5/3282 [00:18<3:19:44,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 6/3282 [00:22<3:21:00,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 7/3282 [00:26<3:26:45,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 8/3282 [00:30<3:30:50,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 9/3282 [00:34<3:34:39,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 10/3282 [00:38<3:32:32,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 11/3282 [00:42<3:36:58,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 12/3282 [00:46<3:36:26,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 13/3282 [00:49<3:28:58,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 14/3282 [00:53<3:25:21,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 15/3282 [00:57<3:29:20,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   0%|          | 16/3282 [01:01<3:31:45,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 17/3282 [01:05<3:34:37,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 18/3282 [01:09<3:39:18,  4.03s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 19/3282 [01:13<3:40:10,  4.05s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 20/3282 [01:17<3:32:50,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 21/3282 [01:20<3:28:29,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 22/3282 [01:24<3:29:37,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 23/3282 [01:28<3:32:05,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 24/3282 [01:32<3:25:43,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 25/3282 [01:36<3:28:21,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 26/3282 [01:40<3:25:57,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 27/3282 [01:43<3:23:37,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 28/3282 [01:47<3:29:18,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 29/3282 [01:51<3:24:25,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 30/3282 [01:55<3:22:54,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 31/3282 [01:58<3:23:21,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 32/3282 [02:02<3:27:29,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 33/3282 [02:06<3:22:46,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 34/3282 [02:10<3:28:45,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 35/3282 [02:13<3:21:51,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 36/3282 [02:17<3:23:46,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 37/3282 [02:21<3:28:01,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 38/3282 [02:25<3:25:41,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 39/3282 [02:29<3:28:46,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 40/3282 [02:33<3:34:27,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|          | 41/3282 [02:37<3:33:29,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|▏         | 42/3282 [02:41<3:35:14,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|▏         | 43/3282 [02:45<3:30:54,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|▏         | 44/3282 [02:48<3:24:33,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|▏         | 45/3282 [02:52<3:23:18,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|▏         | 46/3282 [02:55<3:13:47,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|▏         | 47/3282 [02:59<3:16:23,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|▏         | 48/3282 [03:03<3:18:08,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   1%|▏         | 49/3282 [03:07<3:20:24,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 50/3282 [03:11<3:22:48,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 51/3282 [03:14<3:24:32,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 52/3282 [03:18<3:26:36,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 53/3282 [03:23<3:31:31,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 54/3282 [03:26<3:27:46,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 55/3282 [03:30<3:28:59,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 56/3282 [03:34<3:32:38,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 57/3282 [03:38<3:28:44,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 58/3282 [03:42<3:29:16,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 59/3282 [03:46<3:31:30,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 60/3282 [03:50<3:30:50,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 61/3282 [03:53<3:21:59,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 62/3282 [03:57<3:21:34,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 63/3282 [04:01<3:25:33,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 64/3282 [04:05<3:23:07,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 65/3282 [04:09<3:24:04,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 66/3282 [04:13<3:26:43,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 67/3282 [04:16<3:24:28,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 68/3282 [04:20<3:22:51,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 69/3282 [04:24<3:22:32,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 70/3282 [04:28<3:24:00,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 71/3282 [04:32<3:27:49,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 72/3282 [04:36<3:31:14,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 73/3282 [04:39<3:25:10,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 74/3282 [04:43<3:24:09,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 75/3282 [04:47<3:25:32,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 76/3282 [04:51<3:22:46,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 77/3282 [04:54<3:15:33,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 78/3282 [04:58<3:14:26,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 79/3282 [05:02<3:20:12,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 80/3282 [05:06<3:22:26,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 81/3282 [05:09<3:22:50,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   2%|▏         | 82/3282 [05:14<3:30:49,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 83/3282 [05:18<3:31:48,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 84/3282 [05:21<3:23:23,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 85/3282 [05:25<3:20:02,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 86/3282 [05:28<3:17:41,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 87/3282 [05:32<3:17:18,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 88/3282 [05:36<3:21:02,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 89/3282 [05:40<3:18:27,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 90/3282 [05:44<3:27:03,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 91/3282 [05:48<3:28:27,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 92/3282 [05:52<3:32:07,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 93/3282 [05:56<3:31:31,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 94/3282 [06:00<3:30:00,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 95/3282 [06:04<3:32:04,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 96/3282 [06:08<3:33:05,  4.01s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 97/3282 [06:12<3:33:14,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 98/3282 [06:16<3:30:43,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 99/3282 [06:20<3:27:38,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 100/3282 [06:24<3:28:43,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 101/3282 [06:27<3:21:21,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 102/3282 [06:31<3:21:39,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 103/3282 [06:35<3:24:46,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 104/3282 [06:38<3:18:27,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 105/3282 [06:42<3:14:12,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 106/3282 [06:46<3:19:08,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 107/3282 [06:50<3:25:57,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 108/3282 [06:54<3:23:29,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 109/3282 [06:58<3:20:39,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 110/3282 [07:00<3:06:36,  3.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 111/3282 [07:04<3:12:26,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 112/3282 [07:08<3:13:24,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 113/3282 [07:12<3:21:11,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   3%|▎         | 114/3282 [07:16<3:22:12,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▎         | 115/3282 [07:20<3:26:52,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▎         | 116/3282 [07:24<3:19:38,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▎         | 117/3282 [07:28<3:22:51,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▎         | 118/3282 [07:32<3:25:13,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▎         | 119/3282 [07:35<3:21:02,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▎         | 120/3282 [07:39<3:24:06,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▎         | 121/3282 [07:43<3:27:55,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▎         | 122/3282 [07:47<3:29:40,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▎         | 123/3282 [07:51<3:28:11,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 124/3282 [07:55<3:25:39,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 125/3282 [07:59<3:27:21,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 126/3282 [08:03<3:30:13,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 127/3282 [08:07<3:23:04,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 128/3282 [08:11<3:19:50,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 129/3282 [08:14<3:16:42,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 130/3282 [08:18<3:16:52,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 131/3282 [08:22<3:20:07,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 132/3282 [08:26<3:24:55,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 133/3282 [08:30<3:28:37,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 134/3282 [08:34<3:21:17,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 135/3282 [08:38<3:25:49,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 136/3282 [08:42<3:25:49,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 137/3282 [08:45<3:19:29,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 138/3282 [08:49<3:23:47,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 139/3282 [08:53<3:25:08,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 140/3282 [08:57<3:21:22,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 141/3282 [09:01<3:19:26,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 142/3282 [09:05<3:19:49,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 143/3282 [09:08<3:21:50,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 144/3282 [09:12<3:20:36,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 145/3282 [09:16<3:21:36,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 146/3282 [09:20<3:25:43,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   4%|▍         | 147/3282 [09:24<3:28:41,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 148/3282 [09:28<3:20:12,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 149/3282 [09:32<3:24:08,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 150/3282 [09:36<3:26:13,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 151/3282 [09:40<3:27:53,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 152/3282 [09:44<3:29:12,  4.01s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 153/3282 [09:48<3:29:52,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 154/3282 [09:52<3:27:31,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 155/3282 [09:56<3:24:02,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 156/3282 [10:00<3:28:58,  4.01s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 157/3282 [10:04<3:25:53,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 158/3282 [10:07<3:18:59,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 159/3282 [10:11<3:18:37,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 160/3282 [10:15<3:22:43,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 161/3282 [10:19<3:26:04,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 162/3282 [10:24<3:28:13,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 163/3282 [10:27<3:25:11,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▍         | 164/3282 [10:31<3:25:32,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 165/3282 [10:35<3:24:16,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 166/3282 [10:39<3:19:06,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 167/3282 [10:43<3:20:46,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 168/3282 [10:47<3:21:54,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 169/3282 [10:50<3:05:51,  3.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 170/3282 [10:53<3:10:59,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 171/3282 [10:57<3:14:53,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 172/3282 [11:01<3:17:33,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 173/3282 [11:05<3:20:15,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 174/3282 [11:10<3:25:26,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 175/3282 [11:13<3:24:35,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 176/3282 [11:17<3:22:39,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 177/3282 [11:21<3:15:50,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 178/3282 [11:24<3:14:17,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 179/3282 [11:28<3:16:09,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   5%|▌         | 180/3282 [11:32<3:16:39,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 181/3282 [11:36<3:10:52,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 182/3282 [11:40<3:15:04,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 183/3282 [11:43<3:09:50,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 184/3282 [11:47<3:12:06,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 185/3282 [11:51<3:13:32,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 186/3282 [11:54<3:10:50,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 187/3282 [11:58<3:14:39,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 188/3282 [12:02<3:20:28,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 189/3282 [12:06<3:15:27,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 190/3282 [12:10<3:16:49,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 191/3282 [12:13<3:15:20,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 192/3282 [12:18<3:22:12,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 193/3282 [12:21<3:18:58,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 194/3282 [12:25<3:16:25,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 195/3282 [12:28<3:04:43,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 196/3282 [12:33<3:18:12,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 197/3282 [12:37<3:21:51,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 198/3282 [12:40<3:15:16,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 199/3282 [12:44<3:14:51,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 200/3282 [12:48<3:15:25,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 201/3282 [12:52<3:19:17,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 202/3282 [12:56<3:20:48,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 203/3282 [13:00<3:27:29,  4.04s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 204/3282 [13:04<3:25:31,  4.01s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▌         | 205/3282 [13:08<3:23:42,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▋         | 206/3282 [13:12<3:17:46,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▋         | 207/3282 [13:16<3:17:11,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▋         | 208/3282 [13:19<3:17:18,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▋         | 209/3282 [13:23<3:19:32,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▋         | 210/3282 [13:27<3:18:36,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▋         | 211/3282 [13:31<3:15:11,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▋         | 212/3282 [13:35<3:19:34,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   6%|▋         | 213/3282 [13:39<3:21:23,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 214/3282 [13:42<3:11:33,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 215/3282 [13:46<3:12:52,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 216/3282 [13:50<3:14:27,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 217/3282 [13:53<3:08:44,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 218/3282 [13:57<3:09:02,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 219/3282 [14:01<3:11:42,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 220/3282 [14:05<3:13:48,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 221/3282 [14:09<3:18:18,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 222/3282 [14:13<3:21:38,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 223/3282 [14:17<3:12:50,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 224/3282 [14:20<3:07:16,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 225/3282 [14:24<3:08:50,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 226/3282 [14:28<3:12:27,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 227/3282 [14:32<3:14:48,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 228/3282 [14:36<3:17:15,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 229/3282 [14:39<3:14:27,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 230/3282 [14:43<3:19:10,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 231/3282 [14:47<3:19:56,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 232/3282 [14:51<3:20:26,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 233/3282 [14:55<3:16:01,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 234/3282 [14:59<3:19:27,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 235/3282 [15:03<3:11:46,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 236/3282 [15:06<3:13:58,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 237/3282 [15:10<3:12:05,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 238/3282 [15:15<3:20:42,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 239/3282 [15:18<3:17:24,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 240/3282 [15:22<3:17:01,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 241/3282 [15:26<3:11:09,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 242/3282 [15:30<3:16:36,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 243/3282 [15:33<3:08:38,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 244/3282 [15:37<3:11:13,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 245/3282 [15:40<3:01:39,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   7%|▋         | 246/3282 [15:43<2:56:47,  3.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 247/3282 [15:47<3:00:36,  3.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 248/3282 [15:51<3:04:18,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 249/3282 [15:55<3:10:01,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 250/3282 [15:59<3:12:52,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 251/3282 [16:03<3:14:15,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 252/3282 [16:07<3:19:45,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 253/3282 [16:11<3:19:26,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 254/3282 [16:15<3:23:18,  4.03s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 255/3282 [16:19<3:23:25,  4.03s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 256/3282 [16:23<3:22:37,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 257/3282 [16:27<3:23:40,  4.04s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 258/3282 [16:31<3:19:24,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 259/3282 [16:35<3:17:57,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 260/3282 [16:39<3:14:53,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 261/3282 [16:43<3:18:47,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 262/3282 [16:47<3:16:12,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 263/3282 [16:51<3:16:37,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 264/3282 [16:54<3:15:45,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 265/3282 [16:58<3:13:06,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 266/3282 [17:02<3:13:00,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 267/3282 [17:05<3:07:35,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 268/3282 [17:09<3:11:31,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 269/3282 [17:14<3:18:12,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 270/3282 [17:17<3:13:27,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 271/3282 [17:21<3:08:46,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 272/3282 [17:25<3:07:26,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 273/3282 [17:28<3:07:23,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 274/3282 [17:32<3:12:19,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 275/3282 [17:36<3:08:49,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 276/3282 [17:40<3:11:49,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 277/3282 [17:44<3:15:33,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   8%|▊         | 278/3282 [17:48<3:17:35,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▊         | 279/3282 [17:52<3:12:19,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▊         | 280/3282 [17:56<3:14:09,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▊         | 281/3282 [18:00<3:13:11,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▊         | 282/3282 [18:03<3:14:29,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▊         | 283/3282 [18:08<3:19:57,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▊         | 284/3282 [18:12<3:21:26,  4.03s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▊         | 285/3282 [18:15<3:15:55,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▊         | 286/3282 [18:20<3:19:15,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▊         | 287/3282 [18:23<3:09:11,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 288/3282 [18:26<3:02:58,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 289/3282 [18:30<3:04:49,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 290/3282 [18:34<3:09:46,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 291/3282 [18:38<3:12:34,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 292/3282 [18:42<3:16:22,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 293/3282 [18:46<3:08:05,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 294/3282 [18:50<3:14:41,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 295/3282 [18:54<3:18:21,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 296/3282 [18:58<3:15:24,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 297/3282 [19:02<3:13:24,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 298/3282 [19:05<3:09:40,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 299/3282 [19:09<3:09:48,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 300/3282 [19:13<3:10:57,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 301/3282 [19:17<3:13:11,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 302/3282 [19:21<3:15:47,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 303/3282 [19:25<3:13:01,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 304/3282 [19:29<3:10:14,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 305/3282 [19:33<3:15:18,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 306/3282 [19:37<3:13:17,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 307/3282 [19:41<3:15:17,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 308/3282 [19:44<3:07:58,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 309/3282 [19:48<3:09:48,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 310/3282 [19:51<3:03:57,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:   9%|▉         | 311/3282 [19:55<3:05:49,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 312/3282 [19:59<3:06:59,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 313/3282 [20:03<3:04:53,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 314/3282 [20:06<3:04:47,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 315/3282 [20:10<3:02:46,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 316/3282 [20:14<3:06:31,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 317/3282 [20:18<3:06:45,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 318/3282 [20:22<3:10:56,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 319/3282 [20:25<3:03:46,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 320/3282 [20:29<3:10:10,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 321/3282 [20:33<3:11:50,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 322/3282 [20:37<3:08:12,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 323/3282 [20:41<3:06:08,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 324/3282 [20:45<3:12:00,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 325/3282 [20:49<3:13:35,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 326/3282 [20:53<3:16:34,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 327/3282 [20:57<3:14:15,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|▉         | 328/3282 [21:00<3:05:10,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 329/3282 [21:03<2:57:58,  3.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 330/3282 [21:07<3:00:17,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 331/3282 [21:11<2:57:57,  3.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 332/3282 [21:14<2:51:20,  3.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 333/3282 [21:18<2:58:12,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 334/3282 [21:22<3:02:31,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 335/3282 [21:26<3:08:22,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 336/3282 [21:30<3:04:43,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 337/3282 [21:34<3:10:09,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 338/3282 [21:38<3:11:53,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 339/3282 [21:41<3:07:33,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 340/3282 [21:45<3:02:27,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 341/3282 [21:48<2:58:24,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 342/3282 [21:52<3:02:51,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 343/3282 [21:56<3:07:18,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  10%|█         | 344/3282 [22:00<3:04:17,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 345/3282 [22:04<3:09:28,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 346/3282 [22:08<3:07:54,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 347/3282 [22:11<3:04:47,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 348/3282 [22:15<3:02:53,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 349/3282 [22:18<2:53:18,  3.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 350/3282 [22:22<3:00:43,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 351/3282 [22:26<3:03:41,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 352/3282 [22:30<3:08:08,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 353/3282 [22:34<3:10:20,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 354/3282 [22:38<3:10:36,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 355/3282 [22:41<2:55:08,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 356/3282 [22:45<2:58:50,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 357/3282 [22:48<2:59:46,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 358/3282 [22:52<3:03:27,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 359/3282 [22:56<2:57:17,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 360/3282 [23:00<3:04:40,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 361/3282 [23:03<2:58:49,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 362/3282 [23:07<2:58:02,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 363/3282 [23:10<2:55:29,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 364/3282 [23:14<2:55:33,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 365/3282 [23:18<3:00:26,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 366/3282 [23:22<3:03:18,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 367/3282 [23:26<3:08:55,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 368/3282 [23:30<3:07:52,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█         | 369/3282 [23:34<3:05:34,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█▏        | 370/3282 [23:37<3:04:52,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█▏        | 371/3282 [23:42<3:13:19,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█▏        | 372/3282 [23:46<3:13:21,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█▏        | 373/3282 [23:50<3:14:48,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█▏        | 374/3282 [23:53<3:05:04,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█▏        | 375/3282 [23:58<3:12:37,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█▏        | 376/3282 [24:01<3:10:10,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  11%|█▏        | 377/3282 [24:05<3:09:07,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 378/3282 [24:08<2:59:53,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 379/3282 [24:12<2:59:52,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 380/3282 [24:16<3:05:29,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 381/3282 [24:20<3:09:37,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 382/3282 [24:25<3:13:25,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 383/3282 [24:29<3:15:49,  4.05s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 384/3282 [24:33<3:15:17,  4.04s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 385/3282 [24:37<3:13:00,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 386/3282 [24:41<3:13:39,  4.01s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 387/3282 [24:44<3:07:32,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 388/3282 [24:48<3:00:39,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 389/3282 [24:52<3:00:36,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 390/3282 [24:55<3:01:35,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 391/3282 [24:59<3:01:44,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 392/3282 [25:03<3:04:00,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 393/3282 [25:07<3:12:32,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 394/3282 [25:12<3:14:24,  4.04s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 395/3282 [25:15<3:07:02,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 396/3282 [25:19<3:10:31,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 397/3282 [25:23<3:08:17,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 398/3282 [25:26<3:00:02,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 399/3282 [25:30<2:58:58,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 400/3282 [25:34<3:00:10,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 401/3282 [25:37<2:54:31,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 402/3282 [25:41<2:54:17,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 403/3282 [25:45<2:55:29,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 404/3282 [25:48<2:57:12,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 405/3282 [25:53<3:03:41,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 406/3282 [25:56<3:04:03,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 407/3282 [26:00<3:04:43,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 408/3282 [26:04<3:04:42,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 409/3282 [26:08<3:05:29,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  12%|█▏        | 410/3282 [26:12<3:05:48,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 411/3282 [26:16<3:05:05,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 412/3282 [26:20<3:03:46,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 413/3282 [26:24<3:06:21,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 414/3282 [26:28<3:11:05,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 415/3282 [26:32<3:10:36,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 416/3282 [26:36<3:13:06,  4.04s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 417/3282 [26:40<3:14:51,  4.08s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 418/3282 [26:44<3:04:54,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 419/3282 [26:47<3:05:10,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 420/3282 [26:52<3:08:13,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 421/3282 [26:55<3:03:18,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 422/3282 [26:59<3:03:18,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 423/3282 [27:03<3:03:44,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 424/3282 [27:07<3:01:28,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 425/3282 [27:10<2:59:45,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 426/3282 [27:14<3:00:48,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 427/3282 [27:18<3:03:11,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 428/3282 [27:22<3:07:50,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 429/3282 [27:26<2:57:34,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 430/3282 [27:30<3:01:57,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 431/3282 [27:33<3:01:17,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 432/3282 [27:36<2:45:06,  3.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 433/3282 [27:40<2:52:02,  3.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 434/3282 [27:44<2:55:51,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 435/3282 [27:48<3:02:53,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 436/3282 [27:52<3:04:25,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 437/3282 [27:56<3:05:03,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 438/3282 [28:00<3:02:21,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 439/3282 [28:04<3:04:26,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 440/3282 [28:07<3:01:15,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 441/3282 [28:11<3:01:50,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 442/3282 [28:15<2:58:58,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  13%|█▎        | 443/3282 [28:19<3:02:43,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▎        | 444/3282 [28:23<3:04:47,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▎        | 445/3282 [28:27<3:06:56,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▎        | 446/3282 [28:30<3:00:07,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▎        | 447/3282 [28:35<3:05:38,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▎        | 448/3282 [28:39<3:09:12,  4.01s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▎        | 449/3282 [28:43<3:05:35,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▎        | 450/3282 [28:46<3:02:35,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▎        | 451/3282 [28:50<3:05:06,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 452/3282 [28:54<3:04:15,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 453/3282 [28:58<2:57:16,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 454/3282 [29:02<2:57:48,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 455/3282 [29:06<3:02:05,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 456/3282 [29:10<3:04:43,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 457/3282 [29:14<3:12:07,  4.08s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 458/3282 [29:18<3:14:35,  4.13s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 459/3282 [29:22<3:09:40,  4.03s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 460/3282 [29:26<3:11:26,  4.07s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 461/3282 [29:30<3:10:47,  4.06s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 462/3282 [29:34<3:12:11,  4.09s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 463/3282 [29:38<3:09:00,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 464/3282 [29:42<3:06:49,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 465/3282 [29:46<3:09:38,  4.04s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 466/3282 [29:50<3:04:37,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 467/3282 [29:54<3:05:39,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 468/3282 [29:57<2:56:56,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 469/3282 [30:01<3:00:25,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 470/3282 [30:06<3:04:19,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 471/3282 [30:09<2:58:28,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 472/3282 [30:13<3:01:15,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 473/3282 [30:17<3:05:53,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 474/3282 [30:21<3:01:54,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  14%|█▍        | 475/3282 [30:25<3:00:07,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 476/3282 [30:28<2:55:59,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 477/3282 [30:32<2:52:30,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 478/3282 [30:36<2:53:39,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 479/3282 [30:39<2:53:54,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 480/3282 [30:43<2:57:12,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 481/3282 [30:47<2:55:09,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 482/3282 [30:51<2:52:57,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 483/3282 [30:55<2:56:30,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 484/3282 [30:59<3:05:26,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 485/3282 [31:03<3:02:55,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 486/3282 [31:07<3:03:17,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 487/3282 [31:10<2:59:25,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 488/3282 [31:15<3:03:09,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 489/3282 [31:18<2:59:54,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 490/3282 [31:22<3:00:54,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 491/3282 [31:26<3:02:52,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▍        | 492/3282 [31:30<3:00:03,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 493/3282 [31:34<2:59:13,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 494/3282 [31:38<3:03:42,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 495/3282 [31:42<3:06:31,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 496/3282 [31:46<3:07:15,  4.03s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 497/3282 [31:50<3:01:19,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 498/3282 [31:54<3:01:01,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 499/3282 [31:58<3:01:29,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 500/3282 [32:02<3:02:50,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 501/3282 [32:06<3:04:29,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 502/3282 [32:09<2:59:58,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 503/3282 [32:13<3:00:49,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 504/3282 [32:17<2:56:59,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 505/3282 [32:21<3:01:41,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 506/3282 [32:26<3:08:20,  4.07s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 507/3282 [32:30<3:11:25,  4.14s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  15%|█▌        | 508/3282 [32:34<3:08:27,  4.08s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 509/3282 [32:38<3:09:57,  4.11s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 510/3282 [32:42<3:08:35,  4.08s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 511/3282 [32:46<3:07:24,  4.06s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 512/3282 [32:50<3:07:33,  4.06s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 513/3282 [32:54<3:07:02,  4.05s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 514/3282 [32:58<3:07:38,  4.07s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 515/3282 [33:02<3:07:05,  4.06s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 516/3282 [33:06<2:57:45,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 517/3282 [33:08<2:38:34,  3.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 518/3282 [33:12<2:49:48,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 519/3282 [33:16<2:55:00,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 520/3282 [33:21<3:03:35,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 521/3282 [33:25<3:00:38,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 522/3282 [33:29<3:03:51,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 523/3282 [33:33<3:07:15,  4.07s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 524/3282 [33:37<3:02:23,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 525/3282 [33:41<3:00:44,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 526/3282 [33:44<3:00:07,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 527/3282 [33:48<3:01:09,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 528/3282 [33:52<2:55:43,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 529/3282 [33:55<2:49:32,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 530/3282 [33:59<2:53:19,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 531/3282 [34:03<2:55:09,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 532/3282 [34:07<2:57:40,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▌        | 533/3282 [34:11<2:59:56,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▋        | 534/3282 [34:16<3:04:37,  4.03s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▋        | 535/3282 [34:20<3:06:09,  4.07s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▋        | 536/3282 [34:24<3:05:16,  4.05s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▋        | 537/3282 [34:28<3:05:41,  4.06s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▋        | 538/3282 [34:32<3:04:50,  4.04s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▋        | 539/3282 [34:36<3:03:12,  4.01s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▋        | 540/3282 [34:40<3:00:40,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  16%|█▋        | 541/3282 [34:43<2:53:06,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 542/3282 [34:47<2:49:36,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 543/3282 [34:50<2:48:41,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 544/3282 [34:54<2:51:57,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 545/3282 [34:58<2:52:28,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 546/3282 [35:02<2:55:27,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 547/3282 [35:06<3:00:34,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 548/3282 [35:09<2:43:29,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 549/3282 [35:13<2:45:51,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 550/3282 [35:17<2:48:15,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 551/3282 [35:20<2:47:45,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 552/3282 [35:24<2:52:41,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 553/3282 [35:29<2:59:30,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 554/3282 [35:32<2:57:04,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 555/3282 [35:36<2:56:37,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 556/3282 [35:40<2:54:44,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 557/3282 [35:44<2:53:03,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 558/3282 [35:47<2:44:50,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 559/3282 [35:50<2:35:45,  3.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 560/3282 [35:53<2:38:44,  3.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 561/3282 [35:57<2:40:09,  3.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 562/3282 [36:01<2:44:18,  3.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 563/3282 [36:04<2:39:54,  3.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 564/3282 [36:09<2:50:15,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 565/3282 [36:12<2:52:37,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 566/3282 [36:16<2:52:11,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 567/3282 [36:20<2:53:52,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 568/3282 [36:24<2:57:16,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 569/3282 [36:28<2:59:50,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 570/3282 [36:32<2:59:47,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 571/3282 [36:36<2:57:18,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 572/3282 [36:40<2:58:48,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 573/3282 [36:44<2:52:12,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  17%|█▋        | 574/3282 [36:48<2:52:44,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 575/3282 [36:52<2:59:06,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 576/3282 [36:56<2:57:26,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 577/3282 [36:59<2:46:11,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 578/3282 [37:03<2:48:25,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 579/3282 [37:06<2:45:20,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 580/3282 [37:10<2:45:59,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 581/3282 [37:14<2:52:21,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 582/3282 [37:18<2:52:03,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 583/3282 [37:22<2:56:26,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 584/3282 [37:26<2:54:01,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 585/3282 [37:30<2:53:05,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 586/3282 [37:33<2:46:09,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 587/3282 [37:37<2:46:49,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 588/3282 [37:40<2:45:52,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 589/3282 [37:44<2:48:19,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 590/3282 [37:48<2:52:17,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 591/3282 [37:52<2:48:00,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 592/3282 [37:55<2:46:29,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 593/3282 [37:59<2:44:34,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 594/3282 [38:03<2:49:21,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 595/3282 [38:07<2:53:19,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 596/3282 [38:11<2:56:33,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 597/3282 [38:15<2:58:43,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 598/3282 [38:20<3:02:36,  4.08s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 599/3282 [38:23<2:53:28,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 600/3282 [38:26<2:44:38,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 601/3282 [38:29<2:28:00,  3.31s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 602/3282 [38:32<2:33:01,  3.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 603/3282 [38:37<2:42:12,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 604/3282 [38:40<2:42:50,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 605/3282 [38:44<2:44:58,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 606/3282 [38:48<2:46:38,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  18%|█▊        | 607/3282 [38:52<2:53:12,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▊        | 608/3282 [38:55<2:45:38,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▊        | 609/3282 [39:00<2:51:38,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▊        | 610/3282 [39:04<2:55:49,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▊        | 611/3282 [39:07<2:46:28,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▊        | 612/3282 [39:11<2:47:23,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▊        | 613/3282 [39:15<2:47:45,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▊        | 614/3282 [39:18<2:47:30,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▊        | 615/3282 [39:22<2:48:09,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 616/3282 [39:26<2:44:09,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 617/3282 [39:30<2:46:09,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 618/3282 [39:33<2:39:27,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 619/3282 [39:36<2:38:52,  3.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 620/3282 [39:40<2:43:30,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 621/3282 [39:44<2:42:28,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 622/3282 [39:48<2:43:06,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 623/3282 [39:52<2:49:21,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 624/3282 [39:56<2:50:28,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 625/3282 [39:59<2:46:10,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 626/3282 [40:03<2:49:50,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 627/3282 [40:06<2:42:33,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 628/3282 [40:10<2:41:49,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 629/3282 [40:14<2:47:59,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 630/3282 [40:18<2:48:08,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 631/3282 [40:22<2:50:02,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 632/3282 [40:26<2:53:40,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 633/3282 [40:30<2:53:02,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 634/3282 [40:34<2:47:49,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 635/3282 [40:37<2:42:53,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 636/3282 [40:41<2:40:53,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 637/3282 [40:44<2:44:24,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 638/3282 [40:48<2:46:49,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  19%|█▉        | 639/3282 [40:52<2:49:57,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 640/3282 [40:57<2:53:21,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 641/3282 [41:01<2:57:15,  4.03s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 642/3282 [41:05<2:57:42,  4.04s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 643/3282 [41:09<2:56:52,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 644/3282 [41:13<2:54:39,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 645/3282 [41:16<2:48:33,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 646/3282 [41:20<2:42:57,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 647/3282 [41:24<2:47:34,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 648/3282 [41:27<2:40:01,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 649/3282 [41:31<2:43:10,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 650/3282 [41:34<2:40:06,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 651/3282 [41:38<2:43:37,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 652/3282 [41:42<2:47:50,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 653/3282 [41:46<2:48:43,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 654/3282 [41:50<2:42:29,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 655/3282 [41:54<2:47:34,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|█▉        | 656/3282 [41:58<2:49:41,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 657/3282 [42:01<2:45:06,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 658/3282 [42:05<2:49:53,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 659/3282 [42:09<2:52:53,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 660/3282 [42:13<2:53:31,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 661/3282 [42:18<2:56:36,  4.04s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 662/3282 [42:21<2:54:03,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 663/3282 [42:25<2:53:46,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 664/3282 [42:29<2:51:21,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 665/3282 [42:33<2:54:42,  4.01s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 666/3282 [42:37<2:55:06,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 667/3282 [42:41<2:54:41,  4.01s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 668/3282 [42:45<2:53:43,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 669/3282 [42:49<2:47:43,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 670/3282 [42:53<2:49:50,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 671/3282 [42:57<2:50:37,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  20%|██        | 672/3282 [43:01<2:50:16,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 673/3282 [43:05<2:48:43,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 674/3282 [43:08<2:45:35,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 675/3282 [43:12<2:43:04,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 676/3282 [43:16<2:41:46,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 677/3282 [43:20<2:47:09,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 678/3282 [43:24<2:49:20,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 679/3282 [43:27<2:44:21,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 680/3282 [43:31<2:49:42,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 681/3282 [43:35<2:50:55,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 682/3282 [43:40<2:53:48,  4.01s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 683/3282 [43:44<2:53:13,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 684/3282 [43:47<2:50:30,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 685/3282 [43:51<2:51:42,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 686/3282 [43:55<2:45:58,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 687/3282 [43:59<2:42:03,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 688/3282 [44:02<2:41:39,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 689/3282 [44:06<2:36:36,  3.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 690/3282 [44:10<2:42:35,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 691/3282 [44:13<2:38:52,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 692/3282 [44:17<2:42:10,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 693/3282 [44:21<2:41:51,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 694/3282 [44:24<2:40:00,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 695/3282 [44:28<2:40:23,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 696/3282 [44:32<2:40:42,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██        | 697/3282 [44:35<2:28:03,  3.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██▏       | 698/3282 [44:38<2:26:05,  3.39s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██▏       | 699/3282 [44:41<2:26:26,  3.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██▏       | 700/3282 [44:45<2:31:40,  3.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██▏       | 701/3282 [44:49<2:33:17,  3.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██▏       | 702/3282 [44:53<2:34:16,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██▏       | 703/3282 [44:57<2:39:30,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██▏       | 704/3282 [45:00<2:39:25,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  21%|██▏       | 705/3282 [45:04<2:43:25,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 706/3282 [45:07<2:34:34,  3.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 707/3282 [45:11<2:37:44,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 708/3282 [45:15<2:42:11,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 709/3282 [45:19<2:44:49,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 710/3282 [45:23<2:45:33,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 711/3282 [45:27<2:48:49,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 712/3282 [45:31<2:48:45,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 713/3282 [45:35<2:43:04,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 714/3282 [45:38<2:41:45,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 715/3282 [45:42<2:41:17,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 716/3282 [45:46<2:42:51,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 717/3282 [45:50<2:38:58,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 718/3282 [45:53<2:36:33,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 719/3282 [45:57<2:40:27,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 720/3282 [46:01<2:39:16,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 721/3282 [46:05<2:44:00,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 722/3282 [46:09<2:47:27,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 723/3282 [46:13<2:48:44,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 724/3282 [46:17<2:54:24,  4.09s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 725/3282 [46:21<2:45:58,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 726/3282 [46:25<2:48:34,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 727/3282 [46:29<2:44:33,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 728/3282 [46:33<2:45:08,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 729/3282 [46:36<2:45:47,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 730/3282 [46:39<2:30:50,  3.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 731/3282 [46:43<2:36:16,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 732/3282 [46:47<2:42:37,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 733/3282 [46:51<2:44:55,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 734/3282 [46:55<2:47:06,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 735/3282 [46:59<2:48:31,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 736/3282 [47:04<2:51:41,  4.05s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 737/3282 [47:07<2:47:36,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  22%|██▏       | 738/3282 [47:11<2:44:24,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 739/3282 [47:15<2:40:15,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 740/3282 [47:19<2:42:18,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 741/3282 [47:22<2:42:49,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 742/3282 [47:26<2:42:15,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 743/3282 [47:30<2:44:54,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 744/3282 [47:34<2:43:07,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 745/3282 [47:38<2:43:27,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 746/3282 [47:42<2:41:53,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 747/3282 [47:45<2:37:37,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 748/3282 [47:49<2:36:01,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 749/3282 [47:53<2:36:34,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 750/3282 [47:57<2:41:09,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 751/3282 [48:00<2:40:52,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 752/3282 [48:04<2:39:05,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 753/3282 [48:08<2:36:01,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 754/3282 [48:12<2:40:45,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 755/3282 [48:16<2:43:57,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 756/3282 [48:20<2:45:03,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 757/3282 [48:24<2:42:39,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 758/3282 [48:27<2:40:55,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 759/3282 [48:31<2:41:29,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 760/3282 [48:35<2:36:13,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 761/3282 [48:39<2:41:19,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 762/3282 [48:42<2:36:16,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 763/3282 [48:46<2:36:12,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 764/3282 [48:50<2:38:27,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 765/3282 [48:54<2:38:44,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 766/3282 [48:57<2:38:48,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 767/3282 [49:01<2:36:16,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 768/3282 [49:05<2:35:06,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 769/3282 [49:08<2:34:31,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 770/3282 [49:12<2:35:13,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  23%|██▎       | 771/3282 [49:16<2:35:58,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▎       | 772/3282 [49:20<2:38:51,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▎       | 773/3282 [49:24<2:38:49,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▎       | 774/3282 [49:28<2:42:27,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▎       | 775/3282 [49:31<2:39:02,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▎       | 776/3282 [49:35<2:40:41,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▎       | 777/3282 [49:39<2:40:37,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▎       | 778/3282 [49:43<2:46:21,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▎       | 779/3282 [49:47<2:47:55,  4.03s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 780/3282 [49:52<2:48:00,  4.03s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 781/3282 [49:55<2:41:58,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 782/3282 [49:59<2:42:28,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 783/3282 [50:03<2:37:35,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 784/3282 [50:06<2:37:49,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 785/3282 [50:10<2:33:35,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 786/3282 [50:14<2:37:33,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 787/3282 [50:17<2:32:51,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 788/3282 [50:21<2:31:30,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 789/3282 [50:25<2:35:06,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 790/3282 [50:29<2:36:48,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 791/3282 [50:33<2:38:54,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 792/3282 [50:36<2:38:55,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 793/3282 [50:40<2:37:03,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 794/3282 [50:44<2:38:21,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 795/3282 [50:48<2:36:09,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 796/3282 [50:51<2:33:44,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 797/3282 [50:54<2:26:29,  3.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 798/3282 [50:58<2:29:11,  3.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 799/3282 [51:02<2:31:14,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 800/3282 [51:05<2:28:34,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 801/3282 [51:09<2:29:04,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 802/3282 [51:13<2:34:07,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 803/3282 [51:17<2:41:03,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  24%|██▍       | 804/3282 [51:21<2:40:29,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 805/3282 [51:25<2:38:21,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 806/3282 [51:28<2:35:18,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 807/3282 [51:33<2:39:41,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 808/3282 [51:37<2:40:44,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 809/3282 [51:41<2:42:14,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 810/3282 [51:45<2:43:57,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 811/3282 [51:48<2:40:38,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 812/3282 [51:52<2:38:12,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 813/3282 [51:56<2:38:43,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 814/3282 [52:00<2:41:21,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 815/3282 [52:04<2:42:28,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 816/3282 [52:08<2:37:02,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 817/3282 [52:11<2:34:02,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 818/3282 [52:15<2:36:18,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 819/3282 [52:19<2:31:57,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▍       | 820/3282 [52:22<2:31:09,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 821/3282 [52:26<2:29:28,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 822/3282 [52:29<2:24:13,  3.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 823/3282 [52:33<2:27:56,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 824/3282 [52:36<2:27:01,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 825/3282 [52:40<2:28:59,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 826/3282 [52:44<2:33:48,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 827/3282 [52:48<2:39:46,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 828/3282 [52:52<2:42:09,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 829/3282 [52:57<2:44:10,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 830/3282 [53:00<2:37:15,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 831/3282 [53:04<2:38:48,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 832/3282 [53:08<2:38:18,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 833/3282 [53:12<2:40:19,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 834/3282 [53:16<2:38:23,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 835/3282 [53:19<2:32:37,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  25%|██▌       | 836/3282 [53:22<2:26:58,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 837/3282 [53:27<2:33:25,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 838/3282 [53:31<2:37:14,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 839/3282 [53:34<2:35:45,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 840/3282 [53:38<2:32:11,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 841/3282 [53:41<2:26:39,  3.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 842/3282 [53:45<2:29:25,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 843/3282 [53:49<2:35:48,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 844/3282 [53:52<2:24:57,  3.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 845/3282 [53:56<2:26:32,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 846/3282 [53:59<2:22:28,  3.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 847/3282 [54:03<2:29:37,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 848/3282 [54:07<2:33:11,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 849/3282 [54:11<2:35:35,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 850/3282 [54:15<2:34:20,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 851/3282 [54:19<2:33:44,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 852/3282 [54:23<2:33:44,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 853/3282 [54:26<2:33:12,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 854/3282 [54:30<2:37:45,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 855/3282 [54:35<2:41:29,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 856/3282 [54:38<2:37:58,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 857/3282 [54:41<2:28:13,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 858/3282 [54:45<2:29:56,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 859/3282 [54:49<2:27:33,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 860/3282 [54:53<2:30:34,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▌       | 861/3282 [54:57<2:33:53,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▋       | 862/3282 [55:00<2:25:48,  3.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▋       | 863/3282 [55:04<2:27:24,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▋       | 864/3282 [55:07<2:19:41,  3.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▋       | 865/3282 [55:11<2:25:56,  3.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▋       | 866/3282 [55:15<2:30:50,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▋       | 867/3282 [55:19<2:34:23,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▋       | 868/3282 [55:22<2:33:30,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  26%|██▋       | 869/3282 [55:26<2:33:31,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 870/3282 [55:30<2:35:18,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 871/3282 [55:34<2:36:16,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 872/3282 [55:38<2:31:56,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 873/3282 [55:42<2:34:31,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 874/3282 [55:46<2:37:53,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 875/3282 [55:49<2:32:22,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 876/3282 [55:53<2:35:40,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 877/3282 [55:57<2:34:17,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 878/3282 [56:01<2:28:40,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 879/3282 [56:05<2:33:16,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 880/3282 [56:09<2:33:57,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 881/3282 [56:13<2:38:17,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 882/3282 [56:17<2:35:59,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 883/3282 [56:21<2:39:05,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 884/3282 [56:25<2:36:32,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 885/3282 [56:28<2:26:48,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 886/3282 [56:32<2:29:57,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 887/3282 [56:36<2:34:27,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 888/3282 [56:40<2:33:31,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 889/3282 [56:44<2:35:47,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 890/3282 [56:47<2:32:07,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 891/3282 [56:51<2:31:31,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 892/3282 [56:55<2:28:55,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 893/3282 [56:59<2:32:32,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 894/3282 [57:02<2:26:41,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 895/3282 [57:06<2:28:27,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 896/3282 [57:09<2:26:24,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 897/3282 [57:13<2:32:00,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 898/3282 [57:17<2:27:42,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 899/3282 [57:21<2:26:17,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 900/3282 [57:24<2:28:45,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 901/3282 [57:28<2:29:57,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  27%|██▋       | 902/3282 [57:32<2:29:54,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 903/3282 [57:36<2:29:19,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 904/3282 [57:40<2:33:07,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 905/3282 [57:44<2:32:19,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 906/3282 [57:48<2:32:53,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 907/3282 [57:51<2:32:33,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 908/3282 [57:55<2:33:22,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 909/3282 [57:59<2:35:24,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 910/3282 [58:03<2:33:58,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 911/3282 [58:07<2:33:58,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 912/3282 [58:11<2:34:02,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 913/3282 [58:15<2:32:43,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 914/3282 [58:19<2:33:12,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 915/3282 [58:23<2:34:02,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 916/3282 [58:27<2:37:05,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 917/3282 [58:30<2:31:56,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 918/3282 [58:35<2:34:54,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 919/3282 [58:38<2:34:41,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 920/3282 [58:43<2:38:17,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 921/3282 [58:47<2:36:33,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 922/3282 [58:50<2:33:19,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 923/3282 [58:54<2:36:45,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 924/3282 [58:58<2:30:29,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 925/3282 [59:02<2:31:45,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 926/3282 [59:06<2:31:42,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 927/3282 [59:10<2:33:16,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 928/3282 [59:14<2:35:56,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 929/3282 [59:18<2:35:41,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 930/3282 [59:22<2:32:04,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 931/3282 [59:25<2:28:13,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 932/3282 [59:29<2:30:25,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 933/3282 [59:33<2:26:46,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 934/3282 [59:36<2:21:47,  3.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  28%|██▊       | 935/3282 [59:40<2:22:55,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▊       | 936/3282 [59:44<2:26:50,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▊       | 937/3282 [59:47<2:26:01,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▊       | 938/3282 [59:51<2:27:32,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▊       | 939/3282 [59:55<2:29:52,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▊       | 940/3282 [59:59<2:25:40,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▊       | 941/3282 [1:00:02<2:25:10,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▊       | 942/3282 [1:00:06<2:28:43,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▊       | 943/3282 [1:00:10<2:31:17,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 944/3282 [1:00:14<2:31:15,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 945/3282 [1:00:18<2:26:22,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 946/3282 [1:00:22<2:27:33,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 947/3282 [1:00:26<2:31:08,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 948/3282 [1:00:30<2:32:23,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 949/3282 [1:00:33<2:30:26,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 950/3282 [1:00:37<2:30:50,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 951/3282 [1:00:41<2:29:00,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 952/3282 [1:00:45<2:27:18,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 953/3282 [1:00:49<2:27:34,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 954/3282 [1:00:52<2:26:22,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 955/3282 [1:00:56<2:29:02,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 956/3282 [1:00:59<2:19:39,  3.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 957/3282 [1:01:03<2:24:43,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 958/3282 [1:01:07<2:25:00,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 959/3282 [1:01:11<2:28:44,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 960/3282 [1:01:15<2:28:53,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 961/3282 [1:01:19<2:30:07,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 962/3282 [1:01:23<2:32:43,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 963/3282 [1:01:27<2:33:15,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 964/3282 [1:01:31<2:33:19,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 965/3282 [1:01:35<2:33:58,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 966/3282 [1:01:39<2:29:28,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 967/3282 [1:01:43<2:28:27,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  29%|██▉       | 968/3282 [1:01:46<2:20:41,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 969/3282 [1:01:50<2:22:47,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 970/3282 [1:01:53<2:24:18,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 971/3282 [1:01:57<2:23:52,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 972/3282 [1:02:01<2:23:46,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 973/3282 [1:02:04<2:20:06,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 974/3282 [1:02:08<2:22:15,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 975/3282 [1:02:12<2:25:10,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 976/3282 [1:02:15<2:19:41,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 977/3282 [1:02:19<2:23:03,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 978/3282 [1:02:23<2:26:04,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 979/3282 [1:02:27<2:29:45,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 980/3282 [1:02:32<2:31:21,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 981/3282 [1:02:36<2:33:49,  4.01s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 982/3282 [1:02:40<2:35:44,  4.06s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 983/3282 [1:02:44<2:35:51,  4.07s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|██▉       | 984/3282 [1:02:48<2:35:29,  4.06s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 985/3282 [1:02:52<2:33:31,  4.01s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 986/3282 [1:02:56<2:28:55,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 987/3282 [1:02:59<2:24:39,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 988/3282 [1:03:03<2:23:40,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 989/3282 [1:03:06<2:20:10,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 990/3282 [1:03:10<2:22:06,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 991/3282 [1:03:14<2:27:05,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 992/3282 [1:03:18<2:24:36,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 993/3282 [1:03:22<2:29:41,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 994/3282 [1:03:26<2:29:23,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 995/3282 [1:03:29<2:21:27,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 996/3282 [1:03:33<2:21:06,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 997/3282 [1:03:37<2:22:50,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 998/3282 [1:03:41<2:22:54,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 999/3282 [1:03:44<2:24:23,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 1000/3282 [1:03:48<2:24:45,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  30%|███       | 1001/3282 [1:03:52<2:26:44,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1002/3282 [1:03:56<2:26:12,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1003/3282 [1:04:00<2:26:27,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1004/3282 [1:04:04<2:27:28,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1005/3282 [1:04:08<2:27:52,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1006/3282 [1:04:11<2:25:13,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1007/3282 [1:04:16<2:27:46,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1008/3282 [1:04:20<2:29:57,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1009/3282 [1:04:22<2:16:04,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1010/3282 [1:04:26<2:15:28,  3.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1011/3282 [1:04:30<2:21:17,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1012/3282 [1:04:34<2:22:08,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1013/3282 [1:04:38<2:25:11,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1014/3282 [1:04:42<2:23:48,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1015/3282 [1:04:46<2:25:47,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1016/3282 [1:04:49<2:26:32,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1017/3282 [1:04:54<2:28:45,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1018/3282 [1:04:57<2:28:20,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1019/3282 [1:05:01<2:24:34,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1020/3282 [1:05:05<2:26:02,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1021/3282 [1:05:09<2:25:40,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1022/3282 [1:05:13<2:27:17,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1023/3282 [1:05:17<2:26:58,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1024/3282 [1:05:21<2:26:19,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███       | 1025/3282 [1:05:24<2:22:32,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███▏      | 1026/3282 [1:05:28<2:17:05,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███▏      | 1027/3282 [1:05:31<2:20:32,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███▏      | 1028/3282 [1:05:35<2:21:24,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███▏      | 1029/3282 [1:05:39<2:23:12,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███▏      | 1030/3282 [1:05:43<2:22:21,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███▏      | 1031/3282 [1:05:47<2:23:23,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███▏      | 1032/3282 [1:05:50<2:19:52,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  31%|███▏      | 1033/3282 [1:05:54<2:18:57,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1034/3282 [1:05:58<2:23:57,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1035/3282 [1:06:02<2:20:57,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1036/3282 [1:06:06<2:26:10,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1037/3282 [1:06:10<2:23:08,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1038/3282 [1:06:14<2:29:08,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1039/3282 [1:06:18<2:23:59,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1040/3282 [1:06:21<2:21:19,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1041/3282 [1:06:25<2:18:55,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1042/3282 [1:06:29<2:23:08,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1043/3282 [1:06:33<2:22:48,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1044/3282 [1:06:36<2:19:28,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1045/3282 [1:06:40<2:20:52,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1046/3282 [1:06:44<2:21:18,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1047/3282 [1:06:48<2:20:40,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1048/3282 [1:06:51<2:19:19,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1049/3282 [1:06:55<2:20:48,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1050/3282 [1:06:59<2:20:44,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1051/3282 [1:07:03<2:21:29,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1052/3282 [1:07:07<2:25:15,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1053/3282 [1:07:10<2:12:58,  3.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1054/3282 [1:07:14<2:17:24,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1055/3282 [1:07:18<2:18:35,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1056/3282 [1:07:22<2:23:07,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1057/3282 [1:07:26<2:24:00,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1058/3282 [1:07:29<2:22:12,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1059/3282 [1:07:33<2:21:10,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1060/3282 [1:07:37<2:20:53,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1061/3282 [1:07:41<2:23:46,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1062/3282 [1:07:45<2:22:20,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1063/3282 [1:07:49<2:23:01,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1064/3282 [1:07:52<2:20:17,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1065/3282 [1:07:57<2:26:46,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  32%|███▏      | 1066/3282 [1:08:00<2:25:07,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1067/3282 [1:08:04<2:25:28,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1068/3282 [1:08:08<2:22:46,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1069/3282 [1:08:12<2:20:52,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1070/3282 [1:08:15<2:14:54,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1071/3282 [1:08:19<2:15:37,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1072/3282 [1:08:23<2:17:01,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1073/3282 [1:08:27<2:19:48,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1074/3282 [1:08:31<2:20:20,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1075/3282 [1:08:34<2:18:01,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1076/3282 [1:08:38<2:18:41,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1077/3282 [1:08:41<2:10:01,  3.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1078/3282 [1:08:45<2:12:13,  3.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1079/3282 [1:08:48<2:09:42,  3.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1080/3282 [1:08:51<2:07:45,  3.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1081/3282 [1:08:55<2:05:22,  3.42s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1082/3282 [1:08:59<2:12:08,  3.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1083/3282 [1:09:02<2:13:28,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1084/3282 [1:09:07<2:19:38,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1085/3282 [1:09:10<2:16:35,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1086/3282 [1:09:14<2:20:28,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1087/3282 [1:09:18<2:14:28,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1088/3282 [1:09:21<2:13:41,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1089/3282 [1:09:25<2:13:21,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1090/3282 [1:09:29<2:18:04,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1091/3282 [1:09:33<2:19:44,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1092/3282 [1:09:37<2:19:58,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1093/3282 [1:09:40<2:19:09,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1094/3282 [1:09:44<2:18:32,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1095/3282 [1:09:48<2:21:06,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1096/3282 [1:09:52<2:24:41,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1097/3282 [1:09:56<2:22:40,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1098/3282 [1:10:00<2:22:38,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  33%|███▎      | 1099/3282 [1:10:04<2:19:14,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▎      | 1100/3282 [1:10:08<2:20:03,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▎      | 1101/3282 [1:10:11<2:12:36,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▎      | 1102/3282 [1:10:15<2:12:11,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▎      | 1103/3282 [1:10:18<2:12:52,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▎      | 1104/3282 [1:10:22<2:17:43,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▎      | 1105/3282 [1:10:26<2:15:40,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▎      | 1106/3282 [1:10:30<2:16:53,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▎      | 1107/3282 [1:10:33<2:10:40,  3.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1108/3282 [1:10:37<2:13:29,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1109/3282 [1:10:41<2:13:59,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1110/3282 [1:10:44<2:09:52,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1111/3282 [1:10:48<2:11:53,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1112/3282 [1:10:52<2:15:12,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1113/3282 [1:10:55<2:15:49,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1114/3282 [1:10:59<2:14:45,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1115/3282 [1:11:03<2:17:19,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1116/3282 [1:11:07<2:15:59,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1117/3282 [1:11:11<2:18:42,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1118/3282 [1:11:15<2:22:28,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1119/3282 [1:11:19<2:23:09,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1120/3282 [1:11:23<2:20:05,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1121/3282 [1:11:26<2:16:32,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1122/3282 [1:11:30<2:19:09,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1123/3282 [1:11:34<2:20:04,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1124/3282 [1:11:38<2:19:32,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1125/3282 [1:11:42<2:22:54,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1126/3282 [1:11:46<2:23:40,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1127/3282 [1:11:50<2:18:14,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1128/3282 [1:11:54<2:15:56,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1129/3282 [1:11:58<2:18:14,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1130/3282 [1:12:02<2:21:42,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1131/3282 [1:12:06<2:20:41,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  34%|███▍      | 1132/3282 [1:12:09<2:19:04,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1133/3282 [1:12:13<2:16:56,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1134/3282 [1:12:17<2:17:58,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1135/3282 [1:12:21<2:17:47,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1136/3282 [1:12:24<2:15:47,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1137/3282 [1:12:28<2:17:04,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1138/3282 [1:12:32<2:14:11,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1139/3282 [1:12:35<2:09:48,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1140/3282 [1:12:39<2:12:42,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1141/3282 [1:12:43<2:15:31,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1142/3282 [1:12:47<2:18:07,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1143/3282 [1:12:51<2:13:58,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1144/3282 [1:12:55<2:15:36,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1145/3282 [1:12:59<2:17:22,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1146/3282 [1:13:02<2:16:40,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1147/3282 [1:13:07<2:19:53,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▍      | 1148/3282 [1:13:11<2:19:59,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1149/3282 [1:13:15<2:20:16,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1150/3282 [1:13:19<2:20:39,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1151/3282 [1:13:22<2:20:18,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1152/3282 [1:13:26<2:18:38,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1153/3282 [1:13:30<2:18:39,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1154/3282 [1:13:34<2:18:03,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1155/3282 [1:13:38<2:20:05,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1156/3282 [1:13:42<2:18:51,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1157/3282 [1:13:46<2:19:50,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1158/3282 [1:13:50<2:22:13,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1159/3282 [1:13:54<2:16:37,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1160/3282 [1:13:57<2:12:46,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1161/3282 [1:14:01<2:13:59,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1162/3282 [1:14:05<2:17:23,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1163/3282 [1:14:09<2:16:56,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1164/3282 [1:14:12<2:11:27,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  35%|███▌      | 1165/3282 [1:14:16<2:11:11,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1166/3282 [1:14:20<2:11:53,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1167/3282 [1:14:24<2:14:10,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1168/3282 [1:14:28<2:15:34,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1169/3282 [1:14:32<2:15:43,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1170/3282 [1:14:35<2:14:56,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1171/3282 [1:14:39<2:17:14,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1172/3282 [1:14:43<2:18:27,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1173/3282 [1:14:48<2:21:17,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1174/3282 [1:14:51<2:17:09,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1175/3282 [1:14:55<2:16:08,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1176/3282 [1:14:59<2:12:30,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1177/3282 [1:15:02<2:12:35,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1178/3282 [1:15:07<2:17:48,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1179/3282 [1:15:10<2:14:53,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1180/3282 [1:15:14<2:09:42,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1181/3282 [1:15:17<2:09:14,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1182/3282 [1:15:22<2:13:13,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1183/3282 [1:15:26<2:17:13,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1184/3282 [1:15:30<2:17:33,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1185/3282 [1:15:33<2:16:02,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1186/3282 [1:15:37<2:11:07,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1187/3282 [1:15:41<2:13:30,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1188/3282 [1:15:45<2:14:53,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▌      | 1189/3282 [1:15:48<2:12:06,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▋      | 1190/3282 [1:15:53<2:16:44,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▋      | 1191/3282 [1:15:57<2:15:42,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▋      | 1192/3282 [1:16:00<2:13:04,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▋      | 1193/3282 [1:16:04<2:14:55,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▋      | 1194/3282 [1:16:08<2:15:13,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▋      | 1195/3282 [1:16:12<2:16:51,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▋      | 1196/3282 [1:16:16<2:14:04,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  36%|███▋      | 1197/3282 [1:16:20<2:16:00,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1198/3282 [1:16:23<2:10:31,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1199/3282 [1:16:27<2:07:00,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1200/3282 [1:16:31<2:11:31,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1201/3282 [1:16:35<2:14:50,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1202/3282 [1:16:39<2:17:01,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1203/3282 [1:16:43<2:17:20,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1204/3282 [1:16:47<2:20:20,  4.05s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1205/3282 [1:16:51<2:21:11,  4.08s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1206/3282 [1:16:55<2:19:52,  4.04s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1207/3282 [1:16:59<2:20:50,  4.07s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1208/3282 [1:17:03<2:18:59,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1209/3282 [1:17:07<2:18:16,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1210/3282 [1:17:11<2:15:26,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1211/3282 [1:17:15<2:17:33,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1212/3282 [1:17:19<2:17:57,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1213/3282 [1:17:23<2:15:38,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1214/3282 [1:17:27<2:13:44,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1215/3282 [1:17:31<2:15:23,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1216/3282 [1:17:35<2:14:22,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1217/3282 [1:17:38<2:08:17,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1218/3282 [1:17:42<2:10:55,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1219/3282 [1:17:45<2:04:06,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1220/3282 [1:17:49<2:05:06,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1221/3282 [1:17:53<2:06:28,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1222/3282 [1:17:56<2:04:29,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1223/3282 [1:18:00<2:04:09,  3.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1224/3282 [1:18:03<2:03:00,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1225/3282 [1:18:07<2:00:05,  3.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1226/3282 [1:18:11<2:05:02,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1227/3282 [1:18:14<2:06:21,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1228/3282 [1:18:18<2:08:51,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1229/3282 [1:18:22<2:09:37,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  37%|███▋      | 1230/3282 [1:18:26<2:10:19,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1231/3282 [1:18:30<2:10:03,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1232/3282 [1:18:34<2:10:48,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1233/3282 [1:18:37<2:02:19,  3.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1234/3282 [1:18:41<2:07:57,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1235/3282 [1:18:45<2:08:56,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1236/3282 [1:18:48<2:09:46,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1237/3282 [1:18:52<2:11:40,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1238/3282 [1:18:56<2:10:15,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1239/3282 [1:19:00<2:08:56,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1240/3282 [1:19:04<2:09:54,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1241/3282 [1:19:07<2:08:09,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1242/3282 [1:19:11<2:02:32,  3.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1243/3282 [1:19:15<2:05:08,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1244/3282 [1:19:19<2:09:33,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1245/3282 [1:19:23<2:11:57,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1246/3282 [1:19:26<2:07:19,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1247/3282 [1:19:30<2:08:14,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1248/3282 [1:19:34<2:12:37,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1249/3282 [1:19:38<2:14:16,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1250/3282 [1:19:42<2:11:30,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1251/3282 [1:19:46<2:09:59,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1252/3282 [1:19:50<2:09:12,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1253/3282 [1:19:54<2:11:58,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1254/3282 [1:19:57<2:11:33,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1255/3282 [1:20:01<2:06:17,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1256/3282 [1:20:04<2:01:49,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1257/3282 [1:20:08<2:02:34,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1258/3282 [1:20:12<2:06:03,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1259/3282 [1:20:16<2:06:32,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1260/3282 [1:20:20<2:09:18,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1261/3282 [1:20:23<2:09:02,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1262/3282 [1:20:27<2:00:58,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  38%|███▊      | 1263/3282 [1:20:30<2:01:52,  3.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▊      | 1264/3282 [1:20:33<1:57:40,  3.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▊      | 1265/3282 [1:20:37<1:59:46,  3.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▊      | 1266/3282 [1:20:41<2:00:01,  3.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▊      | 1267/3282 [1:20:45<2:03:48,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▊      | 1268/3282 [1:20:49<2:05:35,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▊      | 1269/3282 [1:20:53<2:09:01,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▊      | 1270/3282 [1:20:56<2:07:08,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▊      | 1271/3282 [1:21:00<2:06:31,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1272/3282 [1:21:03<2:01:04,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1273/3282 [1:21:07<2:00:10,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1274/3282 [1:21:10<2:00:06,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1275/3282 [1:21:14<2:04:49,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1276/3282 [1:21:18<2:05:29,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1277/3282 [1:21:22<2:04:01,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1278/3282 [1:21:26<2:09:48,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1279/3282 [1:21:30<2:05:39,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1280/3282 [1:21:34<2:09:54,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1281/3282 [1:21:38<2:08:19,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1282/3282 [1:21:42<2:10:58,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1283/3282 [1:21:46<2:10:52,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1284/3282 [1:21:49<2:10:02,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1285/3282 [1:21:53<2:10:00,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1286/3282 [1:21:57<2:07:48,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1287/3282 [1:22:01<2:06:51,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1288/3282 [1:22:05<2:07:55,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1289/3282 [1:22:09<2:07:08,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1290/3282 [1:22:12<2:07:59,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1291/3282 [1:22:16<2:09:10,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1292/3282 [1:22:20<2:03:43,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1293/3282 [1:22:24<2:04:08,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1294/3282 [1:22:27<2:04:27,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1295/3282 [1:22:31<2:05:34,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  39%|███▉      | 1296/3282 [1:22:35<2:06:53,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1297/3282 [1:22:39<2:03:02,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1298/3282 [1:22:42<1:59:19,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1299/3282 [1:22:46<2:04:00,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1300/3282 [1:22:49<2:00:50,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1301/3282 [1:22:53<2:03:17,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1302/3282 [1:22:57<1:58:18,  3.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1303/3282 [1:23:01<2:04:34,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1304/3282 [1:23:05<2:07:50,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1305/3282 [1:23:09<2:06:08,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1306/3282 [1:23:13<2:08:09,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1307/3282 [1:23:17<2:08:48,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1308/3282 [1:23:21<2:09:22,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1309/3282 [1:23:25<2:13:18,  4.05s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1310/3282 [1:23:29<2:12:02,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1311/3282 [1:23:33<2:09:22,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|███▉      | 1312/3282 [1:23:37<2:09:08,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1313/3282 [1:23:41<2:10:37,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1314/3282 [1:23:44<2:01:00,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1315/3282 [1:23:47<1:59:26,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1316/3282 [1:23:51<1:58:47,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1317/3282 [1:23:54<1:57:15,  3.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1318/3282 [1:23:58<1:55:37,  3.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1319/3282 [1:24:02<2:01:29,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1320/3282 [1:24:06<2:05:24,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1321/3282 [1:24:10<2:04:56,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1322/3282 [1:24:13<1:59:15,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1323/3282 [1:24:17<1:59:25,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1324/3282 [1:24:21<2:04:37,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1325/3282 [1:24:25<2:05:51,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1326/3282 [1:24:29<2:07:43,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1327/3282 [1:24:32<2:02:41,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1328/3282 [1:24:36<1:57:45,  3.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  40%|████      | 1329/3282 [1:24:39<1:58:04,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1330/3282 [1:24:43<1:59:18,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1331/3282 [1:24:47<2:03:43,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1332/3282 [1:24:51<2:06:13,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1333/3282 [1:24:55<2:05:29,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1334/3282 [1:24:59<2:03:31,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1335/3282 [1:25:02<2:01:02,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1336/3282 [1:25:05<1:55:52,  3.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1337/3282 [1:25:08<1:47:14,  3.31s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1338/3282 [1:25:12<1:54:52,  3.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1339/3282 [1:25:16<1:53:51,  3.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1340/3282 [1:25:20<1:57:27,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1341/3282 [1:25:23<1:58:20,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1342/3282 [1:25:28<2:04:34,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1343/3282 [1:25:32<2:05:26,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1344/3282 [1:25:36<2:10:52,  4.05s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1345/3282 [1:25:40<2:09:49,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1346/3282 [1:25:44<2:09:03,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1347/3282 [1:25:48<2:06:41,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1348/3282 [1:25:52<2:07:56,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1349/3282 [1:25:56<2:07:57,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1350/3282 [1:25:59<2:03:58,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1351/3282 [1:26:03<2:03:11,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1352/3282 [1:26:07<2:01:03,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████      | 1353/3282 [1:26:11<2:02:42,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████▏     | 1354/3282 [1:26:14<2:02:52,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████▏     | 1355/3282 [1:26:18<2:01:53,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████▏     | 1356/3282 [1:26:22<2:02:17,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████▏     | 1357/3282 [1:26:26<2:02:15,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████▏     | 1358/3282 [1:26:30<2:05:07,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████▏     | 1359/3282 [1:26:34<2:04:56,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████▏     | 1360/3282 [1:26:37<2:01:48,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████▏     | 1361/3282 [1:26:42<2:06:28,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  41%|████▏     | 1362/3282 [1:26:46<2:08:50,  4.03s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1363/3282 [1:26:50<2:08:57,  4.03s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1364/3282 [1:26:53<2:01:45,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1365/3282 [1:26:57<2:01:30,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1366/3282 [1:27:01<2:03:12,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1367/3282 [1:27:05<2:04:50,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1368/3282 [1:27:08<1:59:51,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1369/3282 [1:27:12<1:59:20,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1370/3282 [1:27:16<2:02:44,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1371/3282 [1:27:20<2:03:39,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1372/3282 [1:27:24<2:06:03,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1373/3282 [1:27:28<2:01:48,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1374/3282 [1:27:32<2:02:43,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1375/3282 [1:27:36<2:05:06,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1376/3282 [1:27:40<2:04:49,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1377/3282 [1:27:44<2:05:50,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1378/3282 [1:27:48<2:05:17,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1379/3282 [1:27:52<2:05:10,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1380/3282 [1:27:56<2:07:30,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1381/3282 [1:28:00<2:08:14,  4.05s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1382/3282 [1:28:04<2:07:05,  4.01s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1383/3282 [1:28:08<2:04:13,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1384/3282 [1:28:12<2:04:00,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1385/3282 [1:28:15<2:01:00,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1386/3282 [1:28:19<2:03:51,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1387/3282 [1:28:24<2:06:15,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1388/3282 [1:28:27<2:04:47,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1389/3282 [1:28:31<2:00:41,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1390/3282 [1:28:35<2:04:26,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1391/3282 [1:28:39<2:01:54,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1392/3282 [1:28:43<2:01:33,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1393/3282 [1:28:46<2:00:52,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  42%|████▏     | 1394/3282 [1:28:50<2:02:08,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1395/3282 [1:28:54<2:00:02,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1396/3282 [1:28:58<2:00:27,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1397/3282 [1:29:02<1:59:34,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1398/3282 [1:29:05<1:54:48,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1399/3282 [1:29:09<1:55:09,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1400/3282 [1:29:12<1:54:51,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1401/3282 [1:29:15<1:46:52,  3.41s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1402/3282 [1:29:19<1:51:35,  3.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1403/3282 [1:29:23<1:54:38,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1404/3282 [1:29:27<1:56:15,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1405/3282 [1:29:30<1:52:27,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1406/3282 [1:29:34<1:53:32,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1407/3282 [1:29:38<1:57:52,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1408/3282 [1:29:42<1:58:18,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1409/3282 [1:29:45<1:57:14,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1410/3282 [1:29:49<1:56:45,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1411/3282 [1:29:53<1:56:29,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1412/3282 [1:29:56<1:50:03,  3.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1413/3282 [1:30:00<1:50:52,  3.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1414/3282 [1:30:04<1:57:18,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1415/3282 [1:30:08<2:00:01,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1416/3282 [1:30:12<2:00:07,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1417/3282 [1:30:16<2:02:31,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1418/3282 [1:30:20<2:00:13,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1419/3282 [1:30:23<1:58:41,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1420/3282 [1:30:27<1:56:57,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1421/3282 [1:30:31<1:58:37,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1422/3282 [1:30:34<1:54:01,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1423/3282 [1:30:38<1:56:55,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1424/3282 [1:30:42<1:55:27,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1425/3282 [1:30:46<1:58:10,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1426/3282 [1:30:50<1:59:50,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  43%|████▎     | 1427/3282 [1:30:54<2:01:04,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▎     | 1428/3282 [1:30:58<2:00:40,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▎     | 1429/3282 [1:31:02<2:00:01,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▎     | 1430/3282 [1:31:05<1:59:42,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▎     | 1431/3282 [1:31:09<1:57:13,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▎     | 1432/3282 [1:31:13<1:59:21,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▎     | 1433/3282 [1:31:17<1:59:11,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▎     | 1434/3282 [1:31:21<1:58:35,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▎     | 1435/3282 [1:31:24<1:55:03,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1436/3282 [1:31:27<1:49:15,  3.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1437/3282 [1:31:30<1:43:00,  3.35s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1438/3282 [1:31:34<1:46:36,  3.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1439/3282 [1:31:38<1:50:45,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1440/3282 [1:31:42<1:56:26,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1441/3282 [1:31:46<1:54:56,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1442/3282 [1:31:49<1:51:25,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1443/3282 [1:31:53<1:51:31,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1444/3282 [1:31:57<1:53:01,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1445/3282 [1:32:00<1:50:59,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1446/3282 [1:32:04<1:50:33,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1447/3282 [1:32:07<1:49:16,  3.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1448/3282 [1:32:11<1:51:37,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1449/3282 [1:32:15<1:56:51,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1450/3282 [1:32:19<1:56:12,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1451/3282 [1:32:23<1:56:40,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1452/3282 [1:32:27<1:55:53,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1453/3282 [1:32:30<1:56:00,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1454/3282 [1:32:34<1:57:29,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1455/3282 [1:32:38<1:51:14,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1456/3282 [1:32:42<1:53:46,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1457/3282 [1:32:46<1:58:44,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1458/3282 [1:32:50<1:58:45,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1459/3282 [1:32:53<1:55:18,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  44%|████▍     | 1460/3282 [1:32:57<1:54:55,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1461/3282 [1:33:01<1:57:40,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1462/3282 [1:33:05<1:58:03,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1463/3282 [1:33:09<1:59:43,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1464/3282 [1:33:13<2:01:06,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1465/3282 [1:33:17<1:55:48,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1466/3282 [1:33:20<1:54:56,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1467/3282 [1:33:24<1:48:43,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1468/3282 [1:33:28<1:52:32,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1469/3282 [1:33:31<1:51:07,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1470/3282 [1:33:35<1:51:32,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1471/3282 [1:33:39<1:53:14,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1472/3282 [1:33:42<1:47:42,  3.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1473/3282 [1:33:45<1:45:13,  3.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1474/3282 [1:33:49<1:45:41,  3.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1475/3282 [1:33:52<1:45:18,  3.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▍     | 1476/3282 [1:33:56<1:48:56,  3.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1477/3282 [1:33:59<1:45:41,  3.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1478/3282 [1:34:03<1:50:49,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1479/3282 [1:34:08<1:54:45,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1480/3282 [1:34:11<1:53:01,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1481/3282 [1:34:15<1:50:22,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1482/3282 [1:34:18<1:50:35,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1483/3282 [1:34:22<1:51:55,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1484/3282 [1:34:26<1:53:59,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1485/3282 [1:34:30<1:53:40,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1486/3282 [1:34:33<1:50:44,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1487/3282 [1:34:37<1:51:58,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1488/3282 [1:34:41<1:53:27,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1489/3282 [1:34:45<1:53:09,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1490/3282 [1:34:48<1:48:56,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1491/3282 [1:34:52<1:48:11,  3.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1492/3282 [1:34:56<1:50:46,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  45%|████▌     | 1493/3282 [1:35:00<1:53:18,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1494/3282 [1:35:04<1:53:59,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1495/3282 [1:35:07<1:52:48,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1496/3282 [1:35:11<1:49:59,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1497/3282 [1:35:15<1:50:57,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1498/3282 [1:35:19<1:53:32,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1499/3282 [1:35:23<1:54:28,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1500/3282 [1:35:27<1:55:35,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1501/3282 [1:35:30<1:52:12,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1502/3282 [1:35:34<1:50:49,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1503/3282 [1:35:38<1:53:37,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1504/3282 [1:35:42<1:52:42,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1505/3282 [1:35:46<1:54:48,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1506/3282 [1:35:49<1:54:28,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1507/3282 [1:35:54<1:56:00,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1508/3282 [1:35:57<1:55:50,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1509/3282 [1:36:02<1:57:33,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1510/3282 [1:36:06<1:58:43,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1511/3282 [1:36:09<1:53:46,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1512/3282 [1:36:13<1:54:17,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1513/3282 [1:36:16<1:49:30,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1514/3282 [1:36:20<1:51:04,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1515/3282 [1:36:24<1:51:09,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1516/3282 [1:36:27<1:47:13,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▌     | 1517/3282 [1:36:31<1:47:39,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▋     | 1518/3282 [1:36:35<1:45:09,  3.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▋     | 1519/3282 [1:36:38<1:44:25,  3.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▋     | 1520/3282 [1:36:41<1:40:31,  3.42s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▋     | 1521/3282 [1:36:45<1:44:08,  3.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▋     | 1522/3282 [1:36:49<1:45:10,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▋     | 1524/3282 [1:36:56<1:49:34,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▋     | 1525/3282 [1:37:00<1:49:20,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  46%|████▋     | 1526/3282 [1:37:04<1:48:31,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1527/3282 [1:37:08<1:48:40,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1528/3282 [1:37:11<1:47:08,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1529/3282 [1:37:15<1:49:36,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1530/3282 [1:37:19<1:52:12,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1531/3282 [1:37:23<1:48:30,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1532/3282 [1:37:26<1:48:31,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1533/3282 [1:37:30<1:51:46,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1534/3282 [1:37:34<1:52:58,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1535/3282 [1:37:38<1:54:11,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1536/3282 [1:37:42<1:51:37,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1537/3282 [1:37:45<1:46:43,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1538/3282 [1:37:49<1:47:15,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1539/3282 [1:37:53<1:49:21,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1540/3282 [1:37:57<1:50:23,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1541/3282 [1:38:01<1:51:36,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1542/3282 [1:38:05<1:51:13,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1543/3282 [1:38:08<1:49:35,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1544/3282 [1:38:12<1:46:30,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1545/3282 [1:38:15<1:44:56,  3.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1546/3282 [1:38:19<1:48:40,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1547/3282 [1:38:24<1:53:01,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1548/3282 [1:38:27<1:50:37,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1549/3282 [1:38:31<1:48:36,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1550/3282 [1:38:34<1:45:56,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1551/3282 [1:38:38<1:46:26,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1552/3282 [1:38:42<1:49:36,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1553/3282 [1:38:46<1:47:01,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1554/3282 [1:38:49<1:47:08,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1555/3282 [1:38:53<1:48:40,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1556/3282 [1:38:57<1:50:39,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1557/3282 [1:39:01<1:49:42,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  47%|████▋     | 1558/3282 [1:39:05<1:49:22,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1559/3282 [1:39:08<1:41:28,  3.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1560/3282 [1:39:11<1:43:15,  3.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1561/3282 [1:39:15<1:39:55,  3.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1562/3282 [1:39:18<1:37:35,  3.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1563/3282 [1:39:21<1:39:17,  3.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1564/3282 [1:39:25<1:40:03,  3.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1565/3282 [1:39:28<1:39:23,  3.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1566/3282 [1:39:32<1:40:22,  3.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1567/3282 [1:39:35<1:39:21,  3.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1568/3282 [1:39:39<1:43:47,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1569/3282 [1:39:43<1:46:38,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1570/3282 [1:39:47<1:49:41,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1571/3282 [1:39:51<1:46:58,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1572/3282 [1:39:55<1:50:07,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1573/3282 [1:39:59<1:47:50,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1574/3282 [1:40:03<1:49:18,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1575/3282 [1:40:06<1:48:22,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1576/3282 [1:40:10<1:49:01,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1577/3282 [1:40:14<1:48:17,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1578/3282 [1:40:18<1:47:42,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1579/3282 [1:40:22<1:46:59,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1580/3282 [1:40:25<1:44:15,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1581/3282 [1:40:29<1:43:45,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1582/3282 [1:40:32<1:43:01,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1583/3282 [1:40:36<1:41:00,  3.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1584/3282 [1:40:39<1:43:26,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1585/3282 [1:40:44<1:47:14,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1586/3282 [1:40:47<1:45:19,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1587/3282 [1:40:51<1:43:55,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1588/3282 [1:40:54<1:44:48,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1589/3282 [1:40:58<1:45:08,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1590/3282 [1:41:02<1:45:13,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  48%|████▊     | 1591/3282 [1:41:06<1:47:50,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▊     | 1592/3282 [1:41:10<1:50:18,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▊     | 1593/3282 [1:41:13<1:44:27,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▊     | 1594/3282 [1:41:17<1:44:41,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▊     | 1595/3282 [1:41:21<1:46:54,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▊     | 1596/3282 [1:41:25<1:46:42,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▊     | 1597/3282 [1:41:29<1:48:53,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▊     | 1598/3282 [1:41:32<1:45:45,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▊     | 1599/3282 [1:41:37<1:48:24,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1600/3282 [1:41:40<1:45:23,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1601/3282 [1:41:44<1:50:20,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1602/3282 [1:41:48<1:50:56,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1603/3282 [1:41:52<1:46:50,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1604/3282 [1:41:56<1:48:35,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1605/3282 [1:41:59<1:43:43,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1606/3282 [1:42:03<1:44:26,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1607/3282 [1:42:07<1:46:16,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1608/3282 [1:42:11<1:44:21,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1609/3282 [1:42:15<1:46:45,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1610/3282 [1:42:18<1:46:29,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1611/3282 [1:42:22<1:46:31,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1612/3282 [1:42:26<1:46:38,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1613/3282 [1:42:30<1:47:28,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1614/3282 [1:42:34<1:48:14,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1615/3282 [1:42:38<1:45:58,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1616/3282 [1:42:42<1:47:50,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1617/3282 [1:42:45<1:46:11,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1618/3282 [1:42:49<1:44:34,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1619/3282 [1:42:52<1:41:25,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1620/3282 [1:42:56<1:43:22,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1621/3282 [1:43:00<1:45:38,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1622/3282 [1:43:04<1:47:48,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1623/3282 [1:43:08<1:45:43,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  49%|████▉     | 1624/3282 [1:43:12<1:45:22,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1625/3282 [1:43:16<1:46:03,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1626/3282 [1:43:20<1:47:52,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1627/3282 [1:43:24<1:50:14,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1628/3282 [1:43:28<1:53:25,  4.11s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1629/3282 [1:43:32<1:48:11,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1630/3282 [1:43:36<1:49:05,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1631/3282 [1:43:40<1:49:14,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1632/3282 [1:43:44<1:49:25,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1633/3282 [1:43:48<1:52:15,  4.08s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1634/3282 [1:43:52<1:50:55,  4.04s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1635/3282 [1:43:56<1:48:33,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1636/3282 [1:44:00<1:50:28,  4.03s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1637/3282 [1:44:04<1:48:54,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1638/3282 [1:44:08<1:44:57,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1639/3282 [1:44:11<1:41:49,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|████▉     | 1640/3282 [1:44:14<1:37:56,  3.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1641/3282 [1:44:17<1:34:01,  3.44s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1642/3282 [1:44:21<1:33:50,  3.43s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1643/3282 [1:44:25<1:38:30,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1644/3282 [1:44:29<1:39:59,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1645/3282 [1:44:32<1:36:02,  3.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1646/3282 [1:44:36<1:40:45,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1647/3282 [1:44:40<1:44:00,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1648/3282 [1:44:44<1:45:09,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1649/3282 [1:44:48<1:43:05,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1650/3282 [1:44:51<1:38:13,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1651/3282 [1:44:55<1:40:52,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1652/3282 [1:44:58<1:40:56,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1653/3282 [1:45:03<1:44:41,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1654/3282 [1:45:07<1:45:52,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1655/3282 [1:45:10<1:43:49,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1656/3282 [1:45:14<1:44:38,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  50%|█████     | 1657/3282 [1:45:18<1:39:49,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1658/3282 [1:45:22<1:42:08,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1659/3282 [1:45:25<1:42:35,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1660/3282 [1:45:29<1:43:24,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1661/3282 [1:45:33<1:44:49,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1662/3282 [1:45:38<1:47:57,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1663/3282 [1:45:41<1:44:18,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1664/3282 [1:45:45<1:46:24,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1665/3282 [1:45:49<1:47:22,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1666/3282 [1:45:53<1:46:22,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1667/3282 [1:45:57<1:42:32,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1668/3282 [1:46:00<1:40:22,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1669/3282 [1:46:04<1:38:48,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1670/3282 [1:46:08<1:42:14,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1671/3282 [1:46:11<1:40:50,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1672/3282 [1:46:15<1:39:35,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1673/3282 [1:46:19<1:38:58,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1674/3282 [1:46:23<1:41:24,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1675/3282 [1:46:26<1:41:03,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1676/3282 [1:46:31<1:43:32,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1677/3282 [1:46:34<1:43:32,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1678/3282 [1:46:38<1:44:31,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1679/3282 [1:46:43<1:45:40,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1680/3282 [1:46:46<1:45:17,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1681/3282 [1:46:50<1:43:06,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████     | 1682/3282 [1:46:54<1:44:50,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████▏    | 1683/3282 [1:46:58<1:45:01,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████▏    | 1684/3282 [1:47:02<1:40:44,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████▏    | 1685/3282 [1:47:05<1:41:45,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████▏    | 1686/3282 [1:47:09<1:42:05,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████▏    | 1687/3282 [1:47:13<1:38:54,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████▏    | 1688/3282 [1:47:17<1:40:28,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████▏    | 1689/3282 [1:47:20<1:39:54,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  51%|█████▏    | 1690/3282 [1:47:24<1:38:05,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1691/3282 [1:47:28<1:39:13,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1692/3282 [1:47:32<1:42:08,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1693/3282 [1:47:36<1:40:24,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1694/3282 [1:47:39<1:35:15,  3.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1695/3282 [1:47:42<1:33:53,  3.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1696/3282 [1:47:46<1:34:55,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1697/3282 [1:47:50<1:37:29,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1698/3282 [1:47:53<1:36:53,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1699/3282 [1:47:58<1:40:12,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1700/3282 [1:48:01<1:36:49,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1701/3282 [1:48:05<1:36:21,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1702/3282 [1:48:08<1:36:59,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1703/3282 [1:48:12<1:34:55,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1704/3282 [1:48:15<1:35:43,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1705/3282 [1:48:19<1:37:10,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1706/3282 [1:48:23<1:40:58,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1707/3282 [1:48:28<1:45:03,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1708/3282 [1:48:31<1:40:55,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1709/3282 [1:48:36<1:44:17,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1710/3282 [1:48:39<1:39:15,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1711/3282 [1:48:43<1:39:33,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1712/3282 [1:48:47<1:40:25,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1713/3282 [1:48:50<1:38:36,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1714/3282 [1:48:54<1:38:49,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1715/3282 [1:48:58<1:38:42,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1716/3282 [1:49:02<1:38:25,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1717/3282 [1:49:06<1:41:50,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1718/3282 [1:49:10<1:41:31,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1719/3282 [1:49:13<1:40:40,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1720/3282 [1:49:17<1:38:58,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1721/3282 [1:49:21<1:40:18,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1722/3282 [1:49:25<1:40:00,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  52%|█████▏    | 1723/3282 [1:49:29<1:39:56,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1724/3282 [1:49:33<1:38:44,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1725/3282 [1:49:36<1:39:53,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1726/3282 [1:49:41<1:43:10,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1727/3282 [1:49:45<1:42:04,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1728/3282 [1:49:49<1:44:45,  4.04s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1729/3282 [1:49:53<1:42:01,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1730/3282 [1:49:56<1:41:27,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1731/3282 [1:50:00<1:39:42,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1732/3282 [1:50:04<1:40:11,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1733/3282 [1:50:08<1:42:20,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1734/3282 [1:50:12<1:44:03,  4.03s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1735/3282 [1:50:17<1:44:36,  4.06s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1736/3282 [1:50:20<1:41:01,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1737/3282 [1:50:24<1:41:15,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1738/3282 [1:50:28<1:41:26,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1739/3282 [1:50:32<1:39:50,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1740/3282 [1:50:35<1:37:14,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1741/3282 [1:50:40<1:40:01,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1742/3282 [1:50:44<1:41:24,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1743/3282 [1:50:47<1:38:58,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1744/3282 [1:50:51<1:37:29,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1745/3282 [1:50:55<1:38:18,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1746/3282 [1:50:59<1:38:48,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1747/3282 [1:51:03<1:40:30,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1748/3282 [1:51:07<1:41:52,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1749/3282 [1:51:11<1:43:33,  4.05s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1750/3282 [1:51:15<1:41:40,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1751/3282 [1:51:19<1:39:17,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1752/3282 [1:51:22<1:36:07,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1753/3282 [1:51:26<1:35:27,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1754/3282 [1:51:29<1:32:58,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  53%|█████▎    | 1755/3282 [1:51:33<1:36:56,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▎    | 1756/3282 [1:51:37<1:37:34,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▎    | 1757/3282 [1:51:41<1:37:28,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▎    | 1758/3282 [1:51:45<1:36:17,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▎    | 1759/3282 [1:51:48<1:32:34,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▎    | 1760/3282 [1:51:52<1:35:25,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▎    | 1761/3282 [1:51:56<1:35:31,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▎    | 1762/3282 [1:52:00<1:36:58,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▎    | 1763/3282 [1:52:03<1:31:24,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▎    | 1764/3282 [1:52:07<1:33:36,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1765/3282 [1:52:11<1:36:39,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1766/3282 [1:52:15<1:39:40,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1767/3282 [1:52:20<1:41:23,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1768/3282 [1:52:23<1:41:04,  4.01s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1769/3282 [1:52:27<1:39:39,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1770/3282 [1:52:31<1:38:23,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1771/3282 [1:52:35<1:37:50,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1772/3282 [1:52:39<1:37:59,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1773/3282 [1:52:42<1:33:31,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1774/3282 [1:52:46<1:36:17,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1775/3282 [1:52:50<1:34:58,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1776/3282 [1:52:54<1:36:09,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1777/3282 [1:52:57<1:33:00,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1778/3282 [1:53:01<1:33:34,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1779/3282 [1:53:05<1:36:03,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1780/3282 [1:53:09<1:34:33,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1781/3282 [1:53:13<1:36:30,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1782/3282 [1:53:17<1:37:00,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1783/3282 [1:53:21<1:38:17,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1784/3282 [1:53:25<1:37:16,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1785/3282 [1:53:28<1:35:43,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1786/3282 [1:53:32<1:32:27,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1787/3282 [1:53:36<1:33:20,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  54%|█████▍    | 1788/3282 [1:53:39<1:31:55,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1789/3282 [1:53:43<1:35:10,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1790/3282 [1:53:47<1:33:41,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1791/3282 [1:53:51<1:32:28,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1792/3282 [1:53:55<1:35:46,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1793/3282 [1:53:58<1:34:25,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1794/3282 [1:54:02<1:35:22,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1795/3282 [1:54:06<1:36:46,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1796/3282 [1:54:10<1:35:35,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1797/3282 [1:54:14<1:35:39,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1798/3282 [1:54:18<1:36:26,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1799/3282 [1:54:21<1:32:07,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1800/3282 [1:54:25<1:34:16,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1801/3282 [1:54:29<1:36:37,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1802/3282 [1:54:33<1:34:35,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1803/3282 [1:54:37<1:34:51,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1804/3282 [1:54:41<1:36:25,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▍    | 1805/3282 [1:54:44<1:32:17,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1806/3282 [1:54:48<1:33:34,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1807/3282 [1:54:52<1:31:21,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1808/3282 [1:54:56<1:32:49,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1809/3282 [1:55:00<1:33:04,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1810/3282 [1:55:03<1:30:20,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1811/3282 [1:55:06<1:27:19,  3.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1812/3282 [1:55:10<1:30:55,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1813/3282 [1:55:14<1:28:47,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1814/3282 [1:55:17<1:28:48,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1815/3282 [1:55:21<1:30:42,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1816/3282 [1:55:26<1:34:05,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1817/3282 [1:55:30<1:36:37,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1818/3282 [1:55:33<1:33:13,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1819/3282 [1:55:37<1:30:45,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1820/3282 [1:55:40<1:28:44,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  55%|█████▌    | 1821/3282 [1:55:44<1:30:51,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1822/3282 [1:55:48<1:31:14,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1823/3282 [1:55:52<1:30:37,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1824/3282 [1:55:55<1:31:03,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1825/3282 [1:55:59<1:29:54,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1826/3282 [1:56:03<1:31:00,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1827/3282 [1:56:06<1:29:01,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1828/3282 [1:56:10<1:32:09,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1829/3282 [1:56:14<1:33:29,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1830/3282 [1:56:18<1:32:02,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1831/3282 [1:56:22<1:30:18,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1832/3282 [1:56:26<1:30:54,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1833/3282 [1:56:30<1:32:48,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1834/3282 [1:56:34<1:34:32,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1835/3282 [1:56:38<1:37:00,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1836/3282 [1:56:41<1:33:21,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1837/3282 [1:56:45<1:31:55,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1838/3282 [1:56:49<1:33:07,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1839/3282 [1:56:53<1:35:43,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1840/3282 [1:56:57<1:36:15,  4.01s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1841/3282 [1:57:01<1:34:06,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1842/3282 [1:57:05<1:34:29,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1843/3282 [1:57:09<1:33:06,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1844/3282 [1:57:13<1:31:30,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1845/3282 [1:57:16<1:30:53,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▌    | 1846/3282 [1:57:20<1:31:40,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▋    | 1847/3282 [1:57:24<1:33:23,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▋    | 1848/3282 [1:57:28<1:33:52,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▋    | 1849/3282 [1:57:32<1:35:29,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▋    | 1850/3282 [1:57:36<1:34:50,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▋    | 1851/3282 [1:57:40<1:30:12,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▋    | 1852/3282 [1:57:44<1:32:15,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▋    | 1853/3282 [1:57:48<1:34:34,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  56%|█████▋    | 1854/3282 [1:57:52<1:33:43,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1855/3282 [1:57:56<1:34:29,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1856/3282 [1:58:00<1:33:06,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1857/3282 [1:58:04<1:34:16,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1858/3282 [1:58:08<1:33:02,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1859/3282 [1:58:12<1:34:50,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1860/3282 [1:58:15<1:32:19,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1861/3282 [1:58:19<1:32:42,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1862/3282 [1:58:23<1:31:53,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1863/3282 [1:58:27<1:31:29,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1864/3282 [1:58:31<1:32:46,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1865/3282 [1:58:35<1:32:20,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1866/3282 [1:58:39<1:31:17,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1867/3282 [1:58:42<1:29:36,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1868/3282 [1:58:46<1:30:59,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1869/3282 [1:58:51<1:33:41,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1870/3282 [1:58:55<1:36:05,  4.08s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1871/3282 [1:58:59<1:33:22,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1872/3282 [1:59:02<1:29:53,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1873/3282 [1:59:06<1:29:57,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1874/3282 [1:59:10<1:28:05,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1875/3282 [1:59:13<1:26:14,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1876/3282 [1:59:17<1:30:09,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1877/3282 [1:59:21<1:29:32,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1878/3282 [1:59:25<1:32:22,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1879/3282 [1:59:29<1:29:44,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1880/3282 [1:59:32<1:27:29,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1881/3282 [1:59:36<1:28:45,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1882/3282 [1:59:40<1:29:18,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1883/3282 [1:59:44<1:26:25,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1884/3282 [1:59:47<1:25:05,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1885/3282 [1:59:51<1:26:11,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1886/3282 [1:59:55<1:25:23,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  57%|█████▋    | 1887/3282 [1:59:58<1:26:02,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1888/3282 [2:00:02<1:26:14,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1889/3282 [2:00:06<1:26:35,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1890/3282 [2:00:10<1:30:38,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1891/3282 [2:00:13<1:24:02,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1892/3282 [2:00:17<1:23:40,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1893/3282 [2:00:20<1:24:03,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1894/3282 [2:00:24<1:24:45,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1895/3282 [2:00:28<1:25:52,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1896/3282 [2:00:32<1:29:01,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1897/3282 [2:00:36<1:30:13,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1898/3282 [2:00:40<1:31:26,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1899/3282 [2:00:44<1:30:36,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1900/3282 [2:00:48<1:29:39,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1901/3282 [2:00:52<1:29:35,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1902/3282 [2:00:56<1:29:06,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1903/3282 [2:01:00<1:32:06,  4.01s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1904/3282 [2:01:04<1:30:29,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1905/3282 [2:01:08<1:29:58,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1906/3282 [2:01:11<1:29:17,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1907/3282 [2:01:15<1:26:30,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1908/3282 [2:01:19<1:26:20,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1909/3282 [2:01:23<1:28:05,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1910/3282 [2:01:26<1:26:42,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1911/3282 [2:01:30<1:27:59,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1912/3282 [2:01:34<1:29:22,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1913/3282 [2:01:38<1:29:09,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1914/3282 [2:01:42<1:30:19,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1915/3282 [2:01:46<1:30:02,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1916/3282 [2:01:50<1:29:02,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1917/3282 [2:01:54<1:25:55,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1918/3282 [2:01:57<1:25:42,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  58%|█████▊    | 1919/3282 [2:02:01<1:25:51,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▊    | 1920/3282 [2:02:05<1:26:21,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▊    | 1921/3282 [2:02:09<1:26:49,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▊    | 1922/3282 [2:02:13<1:26:23,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▊    | 1923/3282 [2:02:17<1:28:24,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▊    | 1924/3282 [2:02:20<1:26:04,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▊    | 1925/3282 [2:02:25<1:27:54,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▊    | 1926/3282 [2:02:28<1:28:08,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▊    | 1927/3282 [2:02:33<1:29:46,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▊    | 1928/3282 [2:02:36<1:27:47,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1929/3282 [2:02:39<1:20:04,  3.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1930/3282 [2:02:43<1:20:56,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1931/3282 [2:02:46<1:21:55,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1932/3282 [2:02:50<1:22:41,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1933/3282 [2:02:54<1:23:52,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1934/3282 [2:02:58<1:25:59,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1935/3282 [2:03:02<1:26:17,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1936/3282 [2:03:06<1:24:57,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1937/3282 [2:03:09<1:25:02,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1938/3282 [2:03:13<1:25:53,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1939/3282 [2:03:17<1:26:31,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1940/3282 [2:03:21<1:27:07,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1941/3282 [2:03:25<1:23:12,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1942/3282 [2:03:28<1:23:10,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1943/3282 [2:03:32<1:23:23,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1944/3282 [2:03:35<1:19:55,  3.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1945/3282 [2:03:39<1:20:51,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1946/3282 [2:03:43<1:22:47,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1947/3282 [2:03:46<1:20:19,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1948/3282 [2:03:50<1:21:43,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1949/3282 [2:03:54<1:23:29,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1950/3282 [2:03:57<1:19:58,  3.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1951/3282 [2:04:01<1:21:36,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  59%|█████▉    | 1952/3282 [2:04:05<1:22:37,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1953/3282 [2:04:09<1:23:01,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1954/3282 [2:04:13<1:23:23,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1955/3282 [2:04:16<1:21:20,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1956/3282 [2:04:20<1:22:50,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1957/3282 [2:04:24<1:21:13,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1958/3282 [2:04:28<1:22:49,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1959/3282 [2:04:31<1:23:33,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1960/3282 [2:04:35<1:22:29,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1961/3282 [2:04:39<1:24:16,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1962/3282 [2:04:43<1:24:02,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1963/3282 [2:04:47<1:27:14,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1964/3282 [2:04:51<1:26:36,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1965/3282 [2:04:55<1:23:57,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1966/3282 [2:04:59<1:26:01,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1967/3282 [2:05:03<1:27:02,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1968/3282 [2:05:07<1:26:31,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|█████▉    | 1969/3282 [2:05:10<1:23:57,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1970/3282 [2:05:14<1:24:48,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1971/3282 [2:05:18<1:25:00,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1972/3282 [2:05:22<1:24:22,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1973/3282 [2:05:26<1:25:31,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1974/3282 [2:05:30<1:26:01,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1975/3282 [2:05:34<1:24:13,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1976/3282 [2:05:37<1:20:17,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1977/3282 [2:05:41<1:19:14,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1978/3282 [2:05:44<1:18:03,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1979/3282 [2:05:48<1:19:42,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1980/3282 [2:05:52<1:21:17,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1981/3282 [2:05:56<1:21:50,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1982/3282 [2:05:59<1:19:02,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1983/3282 [2:06:03<1:19:11,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1984/3282 [2:06:06<1:20:02,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  60%|██████    | 1985/3282 [2:06:10<1:21:20,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1986/3282 [2:06:14<1:21:37,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1987/3282 [2:06:18<1:23:55,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1988/3282 [2:06:22<1:23:11,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1989/3282 [2:06:26<1:24:39,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1990/3282 [2:06:30<1:24:47,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1991/3282 [2:06:34<1:25:39,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1992/3282 [2:06:39<1:27:52,  4.09s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1993/3282 [2:06:43<1:26:51,  4.04s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1994/3282 [2:06:46<1:25:50,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1995/3282 [2:06:50<1:25:22,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1996/3282 [2:06:54<1:23:37,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1997/3282 [2:06:58<1:24:09,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1998/3282 [2:07:02<1:23:22,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 1999/3282 [2:07:06<1:21:18,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 2000/3282 [2:07:09<1:20:21,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 2001/3282 [2:07:13<1:20:57,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 2002/3282 [2:07:17<1:21:37,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 2003/3282 [2:07:21<1:23:01,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 2004/3282 [2:07:24<1:17:55,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 2005/3282 [2:07:28<1:20:20,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 2006/3282 [2:07:32<1:18:56,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 2007/3282 [2:07:36<1:19:26,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 2008/3282 [2:07:39<1:17:45,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 2009/3282 [2:07:43<1:20:59,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████    | 2010/3282 [2:07:47<1:22:12,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████▏   | 2011/3282 [2:07:51<1:23:07,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████▏   | 2012/3282 [2:07:55<1:22:48,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████▏   | 2013/3282 [2:07:59<1:21:25,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████▏   | 2014/3282 [2:08:03<1:22:36,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████▏   | 2015/3282 [2:08:07<1:23:42,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████▏   | 2016/3282 [2:08:11<1:23:42,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████▏   | 2017/3282 [2:08:14<1:20:23,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  61%|██████▏   | 2018/3282 [2:08:18<1:20:37,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2019/3282 [2:08:22<1:19:21,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2020/3282 [2:08:26<1:22:07,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2021/3282 [2:08:30<1:21:37,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2022/3282 [2:08:34<1:22:40,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2023/3282 [2:08:38<1:22:30,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2024/3282 [2:08:41<1:17:32,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2025/3282 [2:08:44<1:11:19,  3.40s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2026/3282 [2:08:48<1:14:39,  3.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2027/3282 [2:08:51<1:15:22,  3.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2028/3282 [2:08:55<1:17:35,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2029/3282 [2:08:59<1:19:12,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2030/3282 [2:09:03<1:18:56,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2031/3282 [2:09:07<1:18:39,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2032/3282 [2:09:11<1:18:26,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2033/3282 [2:09:15<1:19:29,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2034/3282 [2:09:18<1:19:41,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2035/3282 [2:09:21<1:09:04,  3.32s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2036/3282 [2:09:24<1:12:22,  3.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2037/3282 [2:09:28<1:13:18,  3.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2038/3282 [2:09:32<1:14:04,  3.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2039/3282 [2:09:36<1:15:39,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2040/3282 [2:09:40<1:17:32,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2041/3282 [2:09:43<1:16:21,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2042/3282 [2:09:47<1:18:16,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2043/3282 [2:09:50<1:14:54,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2044/3282 [2:09:54<1:17:01,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2045/3282 [2:09:58<1:18:34,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2046/3282 [2:10:02<1:19:01,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2047/3282 [2:10:06<1:17:35,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2048/3282 [2:10:10<1:16:55,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2049/3282 [2:10:14<1:18:27,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2050/3282 [2:10:17<1:17:43,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  62%|██████▏   | 2051/3282 [2:10:21<1:16:26,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2052/3282 [2:10:24<1:15:48,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2053/3282 [2:10:28<1:14:12,  3.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2054/3282 [2:10:31<1:12:39,  3.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2055/3282 [2:10:35<1:12:04,  3.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2056/3282 [2:10:38<1:11:59,  3.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2057/3282 [2:10:42<1:15:48,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2058/3282 [2:10:46<1:16:08,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2059/3282 [2:10:50<1:18:47,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2060/3282 [2:10:54<1:19:04,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2061/3282 [2:10:58<1:18:11,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2062/3282 [2:11:02<1:21:00,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2063/3282 [2:11:06<1:20:15,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2064/3282 [2:11:10<1:19:42,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2065/3282 [2:11:13<1:15:31,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2066/3282 [2:11:17<1:15:09,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2067/3282 [2:11:20<1:13:30,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2068/3282 [2:11:24<1:15:44,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2069/3282 [2:11:28<1:16:36,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2070/3282 [2:11:32<1:18:08,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2071/3282 [2:11:37<1:19:50,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2072/3282 [2:11:41<1:20:20,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2073/3282 [2:11:44<1:18:11,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2074/3282 [2:11:48<1:18:47,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2075/3282 [2:11:52<1:19:01,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2076/3282 [2:11:56<1:17:59,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2077/3282 [2:12:00<1:19:28,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2078/3282 [2:12:03<1:13:36,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2079/3282 [2:12:07<1:16:17,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2080/3282 [2:12:11<1:18:27,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2081/3282 [2:12:15<1:17:35,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2082/3282 [2:12:19<1:16:33,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2083/3282 [2:12:23<1:17:10,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  63%|██████▎   | 2084/3282 [2:12:27<1:16:21,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▎   | 2085/3282 [2:12:30<1:14:39,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▎   | 2086/3282 [2:12:34<1:16:15,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▎   | 2087/3282 [2:12:38<1:14:00,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▎   | 2088/3282 [2:12:41<1:13:14,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▎   | 2089/3282 [2:12:45<1:15:38,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▎   | 2090/3282 [2:12:49<1:14:43,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▎   | 2091/3282 [2:12:53<1:15:39,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▎   | 2092/3282 [2:12:56<1:11:41,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2093/3282 [2:13:00<1:13:46,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2094/3282 [2:13:03<1:11:33,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2095/3282 [2:13:07<1:13:04,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2096/3282 [2:13:11<1:12:14,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2097/3282 [2:13:15<1:12:29,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2098/3282 [2:13:18<1:11:28,  3.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2099/3282 [2:13:22<1:12:03,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2100/3282 [2:13:26<1:13:53,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2101/3282 [2:13:29<1:10:22,  3.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2102/3282 [2:13:33<1:11:26,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2103/3282 [2:13:36<1:11:09,  3.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2104/3282 [2:13:40<1:13:12,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2105/3282 [2:13:44<1:15:26,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2106/3282 [2:13:47<1:08:36,  3.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2107/3282 [2:13:51<1:12:39,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2108/3282 [2:13:56<1:16:13,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2109/3282 [2:13:59<1:15:57,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2110/3282 [2:14:03<1:16:14,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2111/3282 [2:14:07<1:13:30,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2112/3282 [2:14:11<1:12:57,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2113/3282 [2:14:14<1:12:26,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2114/3282 [2:14:18<1:12:15,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2115/3282 [2:14:22<1:11:38,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  64%|██████▍   | 2116/3282 [2:14:24<1:05:31,  3.37s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2117/3282 [2:14:28<1:08:48,  3.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2118/3282 [2:14:32<1:09:33,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2119/3282 [2:14:35<1:07:47,  3.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2120/3282 [2:14:39<1:09:45,  3.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2121/3282 [2:14:43<1:10:28,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2122/3282 [2:14:46<1:09:33,  3.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2123/3282 [2:14:50<1:11:35,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2124/3282 [2:14:54<1:12:02,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2125/3282 [2:14:58<1:11:38,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2126/3282 [2:15:02<1:13:26,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2127/3282 [2:15:05<1:12:43,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2128/3282 [2:15:09<1:13:27,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2129/3282 [2:15:13<1:14:19,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2130/3282 [2:15:17<1:15:22,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2131/3282 [2:15:21<1:16:46,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2132/3282 [2:15:26<1:17:43,  4.06s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▍   | 2133/3282 [2:15:29<1:14:40,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2134/3282 [2:15:33<1:12:28,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2135/3282 [2:15:36<1:11:14,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2136/3282 [2:15:40<1:12:23,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2137/3282 [2:15:44<1:11:25,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2138/3282 [2:15:48<1:11:28,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2139/3282 [2:15:52<1:13:53,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2140/3282 [2:15:56<1:13:34,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2141/3282 [2:15:59<1:13:14,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2142/3282 [2:16:03<1:13:00,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2143/3282 [2:16:07<1:12:39,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2144/3282 [2:16:10<1:09:08,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2145/3282 [2:16:14<1:09:54,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2146/3282 [2:16:18<1:11:33,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2147/3282 [2:16:22<1:14:30,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2148/3282 [2:16:26<1:14:32,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  65%|██████▌   | 2149/3282 [2:16:30<1:14:22,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2150/3282 [2:16:34<1:14:25,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2151/3282 [2:16:38<1:12:53,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2152/3282 [2:16:42<1:14:25,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2153/3282 [2:16:46<1:15:00,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2154/3282 [2:16:50<1:15:24,  4.01s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2155/3282 [2:16:54<1:14:31,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2156/3282 [2:16:58<1:14:19,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2157/3282 [2:17:02<1:12:03,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2158/3282 [2:17:06<1:12:35,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2159/3282 [2:17:08<1:06:32,  3.56s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2160/3282 [2:17:11<1:02:54,  3.36s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2161/3282 [2:17:15<1:07:36,  3.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2162/3282 [2:17:19<1:05:34,  3.51s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2163/3282 [2:17:23<1:08:53,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2164/3282 [2:17:27<1:12:31,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2165/3282 [2:17:31<1:10:36,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2166/3282 [2:17:34<1:09:59,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2167/3282 [2:17:38<1:08:22,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2168/3282 [2:17:42<1:09:24,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2169/3282 [2:17:45<1:07:13,  3.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2170/3282 [2:17:49<1:08:53,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2171/3282 [2:17:53<1:08:34,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2172/3282 [2:17:56<1:07:49,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2173/3282 [2:18:00<1:09:42,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▌   | 2174/3282 [2:18:05<1:11:42,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▋   | 2175/3282 [2:18:09<1:12:19,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▋   | 2176/3282 [2:18:12<1:10:33,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▋   | 2177/3282 [2:18:16<1:08:10,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▋   | 2178/3282 [2:18:19<1:07:27,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▋   | 2179/3282 [2:18:23<1:09:26,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▋   | 2180/3282 [2:18:26<1:04:10,  3.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▋   | 2181/3282 [2:18:30<1:04:04,  3.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  66%|██████▋   | 2182/3282 [2:18:33<1:04:37,  3.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2183/3282 [2:18:37<1:08:00,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2184/3282 [2:18:41<1:08:30,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2185/3282 [2:18:44<1:04:59,  3.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2186/3282 [2:18:48<1:06:55,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2187/3282 [2:18:52<1:08:00,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2188/3282 [2:18:56<1:08:36,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2189/3282 [2:19:00<1:09:29,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2190/3282 [2:19:04<1:10:35,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2191/3282 [2:19:08<1:09:59,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2192/3282 [2:19:11<1:09:29,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2193/3282 [2:19:15<1:08:07,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2194/3282 [2:19:19<1:08:52,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2195/3282 [2:19:23<1:08:09,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2196/3282 [2:19:26<1:08:53,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2197/3282 [2:19:30<1:09:54,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2198/3282 [2:19:35<1:11:18,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2199/3282 [2:19:39<1:12:02,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2200/3282 [2:19:42<1:10:55,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2201/3282 [2:19:46<1:09:13,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2202/3282 [2:19:50<1:11:56,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2203/3282 [2:19:54<1:11:13,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2204/3282 [2:19:58<1:10:42,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2205/3282 [2:20:02<1:09:38,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2206/3282 [2:20:06<1:11:20,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2207/3282 [2:20:10<1:10:39,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2208/3282 [2:20:14<1:09:51,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2209/3282 [2:20:18<1:10:00,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2210/3282 [2:20:22<1:11:33,  4.01s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2211/3282 [2:20:25<1:08:38,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2212/3282 [2:20:29<1:09:11,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2213/3282 [2:20:34<1:10:16,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2214/3282 [2:20:37<1:09:37,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  67%|██████▋   | 2215/3282 [2:20:41<1:07:34,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2216/3282 [2:20:45<1:07:53,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2217/3282 [2:20:49<1:07:58,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2218/3282 [2:20:52<1:07:05,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2219/3282 [2:20:56<1:07:53,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2220/3282 [2:21:00<1:07:24,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2221/3282 [2:21:04<1:08:28,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2222/3282 [2:21:08<1:09:40,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2223/3282 [2:21:12<1:07:18,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2224/3282 [2:21:15<1:06:53,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2225/3282 [2:21:20<1:09:23,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2226/3282 [2:21:23<1:05:28,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2227/3282 [2:21:26<1:04:09,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2228/3282 [2:21:30<1:02:51,  3.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2229/3282 [2:21:33<1:03:00,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2230/3282 [2:21:37<1:04:00,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2231/3282 [2:21:41<1:04:08,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2232/3282 [2:21:45<1:05:28,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2233/3282 [2:21:48<1:02:51,  3.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2234/3282 [2:21:52<1:03:42,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2235/3282 [2:21:55<1:03:54,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2236/3282 [2:21:59<1:05:34,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2237/3282 [2:22:03<1:02:06,  3.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2238/3282 [2:22:06<1:03:36,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2239/3282 [2:22:10<1:03:30,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2240/3282 [2:22:14<1:03:09,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2241/3282 [2:22:17<1:03:22,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2242/3282 [2:22:21<1:04:22,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2243/3282 [2:22:25<1:05:21,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2244/3282 [2:22:29<1:04:31,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2245/3282 [2:22:33<1:05:37,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2246/3282 [2:22:37<1:05:32,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2247/3282 [2:22:40<1:01:14,  3.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  68%|██████▊   | 2248/3282 [2:22:43<1:02:54,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▊   | 2249/3282 [2:22:47<1:05:07,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▊   | 2250/3282 [2:22:52<1:06:43,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▊   | 2251/3282 [2:22:55<1:05:36,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▊   | 2252/3282 [2:22:59<1:05:11,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▊   | 2253/3282 [2:23:03<1:05:19,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▊   | 2254/3282 [2:23:07<1:04:35,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▊   | 2255/3282 [2:23:10<1:05:05,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▊   | 2256/3282 [2:23:15<1:07:49,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2257/3282 [2:23:19<1:06:35,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2258/3282 [2:23:23<1:07:35,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2259/3282 [2:23:26<1:06:36,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2260/3282 [2:23:30<1:07:00,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2261/3282 [2:23:34<1:02:56,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2262/3282 [2:23:37<1:03:11,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2263/3282 [2:23:41<1:04:09,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2264/3282 [2:23:45<1:05:36,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2265/3282 [2:23:49<1:06:39,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2266/3282 [2:23:54<1:08:34,  4.05s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2267/3282 [2:23:57<1:06:03,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2268/3282 [2:24:01<1:03:48,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2269/3282 [2:24:05<1:06:19,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2270/3282 [2:24:09<1:06:33,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2271/3282 [2:24:13<1:04:36,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2272/3282 [2:24:16<1:04:30,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2273/3282 [2:24:21<1:05:47,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2274/3282 [2:24:24<1:03:12,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2275/3282 [2:24:28<1:04:26,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2276/3282 [2:24:32<1:05:24,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2277/3282 [2:24:35<1:03:15,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2278/3282 [2:24:40<1:04:26,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2279/3282 [2:24:43<1:03:29,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  69%|██████▉   | 2280/3282 [2:24:47<1:03:18,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2281/3282 [2:24:51<1:05:05,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2282/3282 [2:24:55<1:04:53,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2283/3282 [2:24:58<1:01:22,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2284/3282 [2:25:02<1:00:47,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2285/3282 [2:25:06<1:02:56,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2286/3282 [2:25:10<1:04:43,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2287/3282 [2:25:14<1:05:10,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2288/3282 [2:25:18<1:06:55,  4.04s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2289/3282 [2:25:23<1:07:46,  4.09s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2290/3282 [2:25:27<1:08:07,  4.12s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2291/3282 [2:25:31<1:07:34,  4.09s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2292/3282 [2:25:34<1:02:15,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2293/3282 [2:25:38<1:02:53,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2294/3282 [2:25:41<1:02:04,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2295/3282 [2:25:45<1:03:16,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2296/3282 [2:25:50<1:04:38,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|██████▉   | 2297/3282 [2:25:53<1:03:47,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2298/3282 [2:25:57<1:04:11,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2299/3282 [2:26:01<1:04:51,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2300/3282 [2:26:05<1:04:28,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2301/3282 [2:26:09<1:02:39,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2302/3282 [2:26:13<1:03:02,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2303/3282 [2:26:17<1:03:32,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2304/3282 [2:26:21<1:03:17,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2305/3282 [2:26:24<1:00:34,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2306/3282 [2:26:28<1:01:08,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2307/3282 [2:26:32<1:03:00,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2308/3282 [2:26:36<1:01:58,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2309/3282 [2:26:40<1:02:34,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2310/3282 [2:26:44<1:03:59,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2311/3282 [2:26:47<1:02:49,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2312/3282 [2:26:50<58:34,  3.62s/question]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  70%|███████   | 2313/3282 [2:26:54<1:00:04,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2314/3282 [2:26:58<1:01:26,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2315/3282 [2:27:03<1:02:47,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2316/3282 [2:27:06<1:02:36,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2317/3282 [2:27:10<1:01:36,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2318/3282 [2:27:14<1:00:26,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2319/3282 [2:27:17<58:39,  3.65s/question]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2320/3282 [2:27:21<1:01:32,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2321/3282 [2:27:25<1:00:11,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2322/3282 [2:27:29<1:00:28,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2323/3282 [2:27:33<1:02:29,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2324/3282 [2:27:37<1:01:26,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2325/3282 [2:27:40<1:01:14,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2326/3282 [2:27:44<1:01:47,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2327/3282 [2:27:48<1:00:56,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2328/3282 [2:27:52<1:01:46,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2329/3282 [2:27:56<1:01:11,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2330/3282 [2:28:00<1:00:40,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2331/3282 [2:28:04<1:00:28,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2332/3282 [2:28:08<1:01:36,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2333/3282 [2:28:11<59:44,  3.78s/question]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2334/3282 [2:28:15<59:13,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2335/3282 [2:28:19<1:00:53,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2336/3282 [2:28:23<1:00:23,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2337/3282 [2:28:26<58:52,  3.74s/question]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████   | 2338/3282 [2:28:30<59:40,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████▏  | 2339/3282 [2:28:33<57:25,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████▏  | 2340/3282 [2:28:38<59:26,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████▏  | 2341/3282 [2:28:41<56:48,  3.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████▏  | 2342/3282 [2:28:45<57:23,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████▏  | 2343/3282 [2:28:48<56:10,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████▏  | 2344/3282 [2:28:52<58:16,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████▏  | 2345/3282 [2:28:56<59:55,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  71%|███████▏  | 2346/3282 [2:29:00<59:39,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2347/3282 [2:29:04<59:11,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2348/3282 [2:29:07<59:13,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2349/3282 [2:29:11<56:07,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2350/3282 [2:29:14<55:55,  3.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2351/3282 [2:29:18<58:15,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2352/3282 [2:29:22<56:52,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2353/3282 [2:29:26<57:57,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2354/3282 [2:29:30<58:29,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2355/3282 [2:29:33<58:02,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2356/3282 [2:29:37<59:38,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2357/3282 [2:29:42<1:00:52,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2358/3282 [2:29:46<1:01:12,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2359/3282 [2:29:49<57:38,  3.75s/question]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2360/3282 [2:29:52<57:30,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2361/3282 [2:29:57<1:00:10,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2362/3282 [2:30:01<1:00:06,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2363/3282 [2:30:05<59:50,  3.91s/question]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2364/3282 [2:30:08<59:14,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2365/3282 [2:30:12<59:05,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2366/3282 [2:30:16<59:24,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2367/3282 [2:30:20<59:54,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2368/3282 [2:30:24<1:00:19,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2369/3282 [2:30:28<1:01:07,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2370/3282 [2:30:32<1:00:08,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2371/3282 [2:30:36<1:00:27,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2372/3282 [2:30:40<58:48,  3.88s/question]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2373/3282 [2:30:44<1:00:11,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2374/3282 [2:30:48<1:00:56,  4.03s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2375/3282 [2:30:52<59:24,  3.93s/question]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2376/3282 [2:30:56<59:28,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2377/3282 [2:31:00<1:00:32,  4.01s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2378/3282 [2:31:04<57:55,  3.85s/question]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  72%|███████▏  | 2379/3282 [2:31:08<59:07,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2380/3282 [2:31:11<58:05,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2381/3282 [2:31:15<56:39,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2382/3282 [2:31:19<56:46,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2383/3282 [2:31:22<56:06,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2384/3282 [2:31:26<56:31,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2385/3282 [2:31:30<56:54,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2386/3282 [2:31:34<57:11,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2387/3282 [2:31:38<57:08,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2388/3282 [2:31:41<55:44,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2389/3282 [2:31:45<55:40,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2390/3282 [2:31:49<55:36,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2391/3282 [2:31:52<54:38,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2392/3282 [2:31:56<56:20,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2393/3282 [2:32:00<56:58,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2394/3282 [2:32:05<58:14,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2395/3282 [2:32:08<57:04,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2396/3282 [2:32:12<55:17,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2397/3282 [2:32:15<54:20,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2398/3282 [2:32:19<56:30,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2399/3282 [2:32:23<56:40,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2400/3282 [2:32:27<56:45,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2401/3282 [2:32:31<55:37,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2402/3282 [2:32:35<55:53,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2403/3282 [2:32:39<55:42,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2404/3282 [2:32:43<57:31,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2405/3282 [2:32:47<56:44,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2406/3282 [2:32:51<57:44,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2407/3282 [2:32:55<57:31,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2408/3282 [2:32:58<55:01,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2409/3282 [2:33:02<55:27,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2410/3282 [2:33:06<54:49,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2411/3282 [2:33:09<53:11,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  73%|███████▎  | 2412/3282 [2:33:13<55:28,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▎  | 2413/3282 [2:33:17<55:38,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▎  | 2414/3282 [2:33:20<53:14,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▎  | 2415/3282 [2:33:24<53:01,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▎  | 2416/3282 [2:33:28<53:26,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▎  | 2417/3282 [2:33:32<55:03,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▎  | 2418/3282 [2:33:35<54:10,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▎  | 2419/3282 [2:33:39<52:52,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▎  | 2420/3282 [2:33:43<52:33,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2421/3282 [2:33:47<54:40,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2422/3282 [2:33:50<53:03,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2423/3282 [2:33:53<49:35,  3.46s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2424/3282 [2:33:57<51:25,  3.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2425/3282 [2:34:01<51:42,  3.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2426/3282 [2:34:05<54:09,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2427/3282 [2:34:09<55:15,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2428/3282 [2:34:13<56:06,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2429/3282 [2:34:17<55:00,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2430/3282 [2:34:21<56:15,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2431/3282 [2:34:25<57:56,  4.08s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2432/3282 [2:34:29<55:46,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2433/3282 [2:34:32<52:54,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2434/3282 [2:34:36<53:37,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2435/3282 [2:34:40<52:15,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2436/3282 [2:34:43<52:25,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2437/3282 [2:34:47<53:14,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2438/3282 [2:34:51<54:42,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2439/3282 [2:34:55<54:21,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2440/3282 [2:34:59<54:17,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2441/3282 [2:35:03<52:38,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2442/3282 [2:35:06<51:30,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2443/3282 [2:35:10<51:43,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2444/3282 [2:35:14<53:19,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  74%|███████▍  | 2445/3282 [2:35:18<53:49,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2446/3282 [2:35:22<54:44,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2447/3282 [2:35:26<54:55,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2448/3282 [2:35:30<53:53,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2449/3282 [2:35:34<53:50,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2450/3282 [2:35:38<54:52,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2451/3282 [2:35:41<53:00,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2452/3282 [2:35:45<54:10,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2453/3282 [2:35:49<54:59,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2454/3282 [2:35:53<51:44,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2455/3282 [2:35:57<53:48,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2456/3282 [2:36:00<50:31,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2457/3282 [2:36:04<52:09,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2458/3282 [2:36:08<54:05,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2459/3282 [2:36:12<53:43,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2460/3282 [2:36:16<54:24,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▍  | 2461/3282 [2:36:20<54:20,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2462/3282 [2:36:24<54:41,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2463/3282 [2:36:28<54:00,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2464/3282 [2:36:32<53:46,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2465/3282 [2:36:36<53:43,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2466/3282 [2:36:40<53:08,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2467/3282 [2:36:44<51:51,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2468/3282 [2:36:47<50:09,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2469/3282 [2:36:51<51:13,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2470/3282 [2:36:55<52:56,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2471/3282 [2:36:58<47:39,  3.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2472/3282 [2:37:01<48:09,  3.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2473/3282 [2:37:05<47:51,  3.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2474/3282 [2:37:09<49:34,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2475/3282 [2:37:12<48:32,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2476/3282 [2:37:16<50:01,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  75%|███████▌  | 2477/3282 [2:37:21<51:39,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2478/3282 [2:37:25<52:18,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2479/3282 [2:37:28<51:50,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2480/3282 [2:37:32<49:58,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2481/3282 [2:37:35<49:07,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2482/3282 [2:37:39<49:31,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2483/3282 [2:37:43<49:31,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2484/3282 [2:37:47<49:35,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2485/3282 [2:37:51<50:30,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2486/3282 [2:37:55<52:30,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2487/3282 [2:37:59<53:22,  4.03s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2488/3282 [2:38:03<52:27,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2489/3282 [2:38:07<52:18,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2490/3282 [2:38:11<51:35,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2491/3282 [2:38:15<51:39,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2492/3282 [2:38:19<52:19,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2493/3282 [2:38:22<49:44,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2494/3282 [2:38:26<50:14,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2495/3282 [2:38:30<51:13,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2496/3282 [2:38:34<51:58,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2497/3282 [2:38:38<51:58,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2498/3282 [2:38:42<52:08,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2499/3282 [2:38:46<50:21,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2500/3282 [2:38:49<49:30,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2501/3282 [2:38:53<50:27,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▌  | 2502/3282 [2:38:57<49:22,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▋  | 2503/3282 [2:39:01<50:09,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▋  | 2504/3282 [2:39:05<49:24,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▋  | 2505/3282 [2:39:08<45:32,  3.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▋  | 2506/3282 [2:39:11<45:06,  3.49s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▋  | 2507/3282 [2:39:15<47:37,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▋  | 2508/3282 [2:39:19<46:28,  3.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▋  | 2509/3282 [2:39:22<46:38,  3.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  76%|███████▋  | 2510/3282 [2:39:26<46:25,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2511/3282 [2:39:30<48:09,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2512/3282 [2:39:34<49:38,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2513/3282 [2:39:38<50:44,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2514/3282 [2:39:42<49:16,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2515/3282 [2:39:46<49:38,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2516/3282 [2:39:50<49:20,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2517/3282 [2:39:54<51:17,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2518/3282 [2:39:58<51:47,  4.07s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2519/3282 [2:40:03<53:26,  4.20s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2520/3282 [2:40:07<52:39,  4.15s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2521/3282 [2:40:10<51:17,  4.04s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2522/3282 [2:40:15<51:26,  4.06s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2523/3282 [2:40:18<49:25,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2524/3282 [2:40:22<49:58,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2525/3282 [2:40:26<47:58,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2526/3282 [2:40:30<48:23,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2527/3282 [2:40:33<48:37,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2528/3282 [2:40:38<49:15,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2529/3282 [2:40:42<50:15,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2530/3282 [2:40:46<50:52,  4.06s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2531/3282 [2:40:50<50:16,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2532/3282 [2:40:54<50:23,  4.03s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2533/3282 [2:40:58<49:37,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2534/3282 [2:41:01<48:37,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2535/3282 [2:41:06<49:26,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2536/3282 [2:41:10<49:43,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2537/3282 [2:41:14<50:31,  4.07s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2538/3282 [2:41:18<49:22,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2539/3282 [2:41:22<49:14,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2540/3282 [2:41:25<48:24,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2541/3282 [2:41:29<47:31,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2542/3282 [2:41:33<47:39,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  77%|███████▋  | 2543/3282 [2:41:37<47:33,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2544/3282 [2:41:41<47:45,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2545/3282 [2:41:45<48:10,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2546/3282 [2:41:49<49:13,  4.01s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2547/3282 [2:41:53<49:45,  4.06s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2548/3282 [2:41:56<46:32,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2549/3282 [2:42:00<47:15,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2550/3282 [2:42:05<47:59,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2551/3282 [2:42:09<48:32,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2552/3282 [2:42:13<48:20,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2553/3282 [2:42:17<48:30,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2554/3282 [2:42:20<46:08,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2555/3282 [2:42:24<46:55,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2556/3282 [2:42:28<46:14,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2557/3282 [2:42:32<47:44,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2558/3282 [2:42:36<48:00,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2559/3282 [2:42:40<47:37,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2560/3282 [2:42:44<47:26,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2561/3282 [2:42:48<47:12,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2562/3282 [2:42:51<46:34,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2563/3282 [2:42:55<43:33,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2564/3282 [2:42:59<44:43,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2565/3282 [2:43:03<45:33,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2566/3282 [2:43:07<46:41,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2567/3282 [2:43:10<44:57,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2568/3282 [2:43:14<44:42,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2569/3282 [2:43:17<44:16,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2570/3282 [2:43:21<44:33,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2571/3282 [2:43:25<43:47,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2572/3282 [2:43:29<45:09,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2573/3282 [2:43:33<44:44,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2574/3282 [2:43:37<45:59,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2575/3282 [2:43:41<47:22,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  78%|███████▊  | 2576/3282 [2:43:45<46:19,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▊  | 2577/3282 [2:43:48<44:23,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▊  | 2578/3282 [2:43:52<44:07,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▊  | 2579/3282 [2:43:56<43:52,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▊  | 2580/3282 [2:44:00<45:21,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▊  | 2581/3282 [2:44:04<47:05,  4.03s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▊  | 2582/3282 [2:44:08<47:10,  4.04s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▊  | 2583/3282 [2:44:12<46:27,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▊  | 2584/3282 [2:44:16<45:10,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2585/3282 [2:44:20<45:03,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2586/3282 [2:44:23<43:46,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2587/3282 [2:44:27<43:48,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2588/3282 [2:44:31<43:01,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2589/3282 [2:44:35<44:17,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2590/3282 [2:44:39<44:12,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2591/3282 [2:44:43<45:03,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2592/3282 [2:44:47<44:59,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2593/3282 [2:44:50<44:32,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2594/3282 [2:44:54<43:49,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2595/3282 [2:44:58<44:08,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2596/3282 [2:45:02<44:12,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2597/3282 [2:45:05<42:48,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2598/3282 [2:45:09<43:19,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2599/3282 [2:45:13<43:11,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2600/3282 [2:45:17<42:59,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2601/3282 [2:45:21<43:27,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2602/3282 [2:45:25<43:42,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2603/3282 [2:45:29<43:39,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2604/3282 [2:45:32<43:40,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2605/3282 [2:45:36<43:33,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2606/3282 [2:45:40<43:58,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2607/3282 [2:45:44<42:57,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2608/3282 [2:45:48<44:13,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  79%|███████▉  | 2609/3282 [2:45:51<41:52,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2610/3282 [2:45:55<41:50,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2611/3282 [2:45:59<43:39,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2612/3282 [2:46:03<42:50,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2613/3282 [2:46:07<42:03,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2614/3282 [2:46:10<41:16,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2615/3282 [2:46:14<40:19,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2616/3282 [2:46:17<40:27,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2617/3282 [2:46:21<40:46,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2618/3282 [2:46:25<42:24,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2619/3282 [2:46:29<43:20,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2620/3282 [2:46:34<43:40,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2621/3282 [2:46:37<43:14,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2622/3282 [2:46:41<42:54,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2623/3282 [2:46:45<40:58,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2624/3282 [2:46:48<40:29,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|███████▉  | 2625/3282 [2:46:52<41:36,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2626/3282 [2:46:56<42:01,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2627/3282 [2:47:00<42:34,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2628/3282 [2:47:04<42:50,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2629/3282 [2:47:08<43:03,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2630/3282 [2:47:12<44:00,  4.05s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2631/3282 [2:47:17<43:58,  4.05s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2632/3282 [2:47:20<42:27,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2633/3282 [2:47:24<41:41,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2634/3282 [2:47:28<42:53,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2635/3282 [2:47:32<43:02,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2636/3282 [2:47:36<42:27,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2637/3282 [2:47:40<41:24,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2638/3282 [2:47:43<40:54,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2639/3282 [2:47:47<40:03,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2640/3282 [2:47:51<40:50,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2641/3282 [2:47:55<41:43,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  80%|████████  | 2642/3282 [2:47:59<42:44,  4.01s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2643/3282 [2:48:03<42:46,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2644/3282 [2:48:07<42:00,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2645/3282 [2:48:11<42:44,  4.03s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2646/3282 [2:48:16<43:28,  4.10s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2647/3282 [2:48:19<41:54,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2648/3282 [2:48:23<42:18,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2649/3282 [2:48:28<43:19,  4.11s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2650/3282 [2:48:32<43:27,  4.13s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2651/3282 [2:48:36<42:45,  4.07s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2652/3282 [2:48:40<42:16,  4.03s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2653/3282 [2:48:43<40:54,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2654/3282 [2:48:47<40:58,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2655/3282 [2:48:51<40:28,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2656/3282 [2:48:54<39:13,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2657/3282 [2:48:59<40:15,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2658/3282 [2:49:02<39:50,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2659/3282 [2:49:06<40:44,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2660/3282 [2:49:10<40:46,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2661/3282 [2:49:14<40:30,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2662/3282 [2:49:18<39:25,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2663/3282 [2:49:22<38:49,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2664/3282 [2:49:26<40:17,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2665/3282 [2:49:30<40:42,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████  | 2666/3282 [2:49:34<40:45,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████▏ | 2667/3282 [2:49:38<40:04,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████▏ | 2668/3282 [2:49:42<41:16,  4.03s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████▏ | 2669/3282 [2:49:46<40:20,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████▏ | 2670/3282 [2:49:49<39:40,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████▏ | 2671/3282 [2:49:54<40:12,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████▏ | 2672/3282 [2:49:57<39:48,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████▏ | 2673/3282 [2:50:01<39:06,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  81%|████████▏ | 2674/3282 [2:50:05<37:47,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2675/3282 [2:50:09<38:32,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2676/3282 [2:50:13<39:04,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2677/3282 [2:50:17<40:06,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2678/3282 [2:50:21<39:47,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2679/3282 [2:50:25<39:31,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2680/3282 [2:50:28<38:26,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2681/3282 [2:50:32<37:52,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2682/3282 [2:50:35<36:16,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2683/3282 [2:50:39<37:39,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2684/3282 [2:50:43<38:29,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2685/3282 [2:50:47<39:29,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2686/3282 [2:50:51<39:30,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2687/3282 [2:50:56<40:26,  4.08s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2688/3282 [2:50:59<37:38,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2689/3282 [2:51:03<38:50,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2690/3282 [2:51:07<38:39,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2691/3282 [2:51:11<38:24,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2692/3282 [2:51:15<37:33,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2693/3282 [2:51:18<37:29,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2694/3282 [2:51:22<37:42,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2695/3282 [2:51:26<38:03,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2696/3282 [2:51:30<38:20,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2697/3282 [2:51:34<37:34,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2698/3282 [2:51:38<38:04,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2699/3282 [2:51:42<37:59,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2700/3282 [2:51:46<38:16,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2701/3282 [2:51:50<39:11,  4.05s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2702/3282 [2:51:54<38:04,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2703/3282 [2:51:57<36:12,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2704/3282 [2:52:01<35:39,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2705/3282 [2:52:05<36:57,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2706/3282 [2:52:09<37:52,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  82%|████████▏ | 2707/3282 [2:52:13<38:01,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2708/3282 [2:52:18<39:07,  4.09s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2709/3282 [2:52:21<38:30,  4.03s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2710/3282 [2:52:25<37:52,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2711/3282 [2:52:29<36:55,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2712/3282 [2:52:33<36:51,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2713/3282 [2:52:36<34:53,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2714/3282 [2:52:40<35:40,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2715/3282 [2:52:44<36:24,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2716/3282 [2:52:48<35:35,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2717/3282 [2:52:51<35:28,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2718/3282 [2:52:55<35:23,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2719/3282 [2:52:59<35:21,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2720/3282 [2:53:02<34:19,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2721/3282 [2:53:07<35:51,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2722/3282 [2:53:11<36:56,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2723/3282 [2:53:15<37:28,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2724/3282 [2:53:19<37:01,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2725/3282 [2:53:23<36:52,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2726/3282 [2:53:27<36:29,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2727/3282 [2:53:31<36:54,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2728/3282 [2:53:35<36:49,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2729/3282 [2:53:39<36:42,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2730/3282 [2:53:43<36:21,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2731/3282 [2:53:46<35:58,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2732/3282 [2:53:51<36:21,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2733/3282 [2:53:55<36:13,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2734/3282 [2:53:58<34:37,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2735/3282 [2:54:01<32:50,  3.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2736/3282 [2:54:05<33:37,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2737/3282 [2:54:09<34:16,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2738/3282 [2:54:13<34:54,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2739/3282 [2:54:17<35:23,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  83%|████████▎ | 2740/3282 [2:54:21<34:55,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▎ | 2741/3282 [2:54:25<35:03,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▎ | 2742/3282 [2:54:28<34:38,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▎ | 2743/3282 [2:54:32<33:52,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▎ | 2744/3282 [2:54:36<34:04,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▎ | 2745/3282 [2:54:40<34:40,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▎ | 2746/3282 [2:54:44<35:19,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▎ | 2747/3282 [2:54:48<35:21,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▎ | 2748/3282 [2:54:51<33:30,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2749/3282 [2:54:55<32:58,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2750/3282 [2:54:59<33:39,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2751/3282 [2:55:03<34:20,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2752/3282 [2:55:07<34:08,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2753/3282 [2:55:11<34:49,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2754/3282 [2:55:15<34:53,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2755/3282 [2:55:19<35:00,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2756/3282 [2:55:23<35:04,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2757/3282 [2:55:25<30:22,  3.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2758/3282 [2:55:29<31:28,  3.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2759/3282 [2:55:33<31:48,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2760/3282 [2:55:37<31:42,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2761/3282 [2:55:41<32:19,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2762/3282 [2:55:44<32:44,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2763/3282 [2:55:48<32:22,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2764/3282 [2:55:52<31:44,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2765/3282 [2:55:55<31:40,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2766/3282 [2:55:59<32:27,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2767/3282 [2:56:03<32:02,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2768/3282 [2:56:06<31:27,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2769/3282 [2:56:10<31:57,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2770/3282 [2:56:14<32:11,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2771/3282 [2:56:18<32:10,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2772/3282 [2:56:22<32:37,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  84%|████████▍ | 2773/3282 [2:56:26<32:31,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2774/3282 [2:56:30<32:27,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2775/3282 [2:56:34<32:44,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2776/3282 [2:56:37<32:05,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2777/3282 [2:56:41<31:33,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2778/3282 [2:56:44<30:05,  3.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2779/3282 [2:56:48<31:21,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2780/3282 [2:56:52<31:06,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2781/3282 [2:56:56<31:44,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2782/3282 [2:57:00<31:52,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2783/3282 [2:57:04<32:36,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2784/3282 [2:57:07<31:21,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2785/3282 [2:57:12<32:17,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2786/3282 [2:57:16<32:36,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2787/3282 [2:57:20<32:50,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2788/3282 [2:57:23<32:09,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▍ | 2789/3282 [2:57:27<31:47,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2790/3282 [2:57:31<31:23,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2791/3282 [2:57:35<31:18,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2792/3282 [2:57:39<31:26,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2793/3282 [2:57:43<31:29,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2794/3282 [2:57:46<30:31,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2795/3282 [2:57:49<29:10,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2796/3282 [2:57:53<30:46,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2797/3282 [2:57:57<31:03,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2798/3282 [2:58:01<30:47,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2799/3282 [2:58:05<30:30,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2800/3282 [2:58:09<30:21,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2801/3282 [2:58:12<29:36,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2802/3282 [2:58:16<30:26,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2803/3282 [2:58:20<30:02,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2804/3282 [2:58:24<30:00,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2805/3282 [2:58:27<28:53,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  85%|████████▌ | 2806/3282 [2:58:31<29:37,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2807/3282 [2:58:35<30:07,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2808/3282 [2:58:39<30:21,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2809/3282 [2:58:43<30:58,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2810/3282 [2:58:47<30:09,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2811/3282 [2:58:50<29:44,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2812/3282 [2:58:54<29:55,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2813/3282 [2:58:58<29:50,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2814/3282 [2:59:02<29:45,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2815/3282 [2:59:05<28:51,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2816/3282 [2:59:09<28:38,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2817/3282 [2:59:13<29:07,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2818/3282 [2:59:17<29:16,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2819/3282 [2:59:20<28:49,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2820/3282 [2:59:24<28:20,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2821/3282 [2:59:28<29:08,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2822/3282 [2:59:32<29:19,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2823/3282 [2:59:36<29:10,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2824/3282 [2:59:39<27:56,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2825/3282 [2:59:43<28:36,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2826/3282 [2:59:47<29:14,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2827/3282 [2:59:51<28:59,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2828/3282 [2:59:55<29:22,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2829/3282 [2:59:59<29:08,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▌ | 2830/3282 [3:00:02<28:13,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▋ | 2831/3282 [3:00:06<29:11,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▋ | 2832/3282 [3:00:10<28:46,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▋ | 2833/3282 [3:00:14<28:58,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▋ | 2834/3282 [3:00:18<28:35,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▋ | 2835/3282 [3:00:21<28:21,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▋ | 2836/3282 [3:00:25<27:42,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▋ | 2837/3282 [3:00:29<28:16,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  86%|████████▋ | 2838/3282 [3:00:33<28:41,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2839/3282 [3:00:37<28:24,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2840/3282 [3:00:41<28:29,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2841/3282 [3:00:45<28:52,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2842/3282 [3:00:48<27:59,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2843/3282 [3:00:52<28:27,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2844/3282 [3:00:56<28:57,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2845/3282 [3:01:00<27:58,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2846/3282 [3:01:04<27:31,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2847/3282 [3:01:07<26:54,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2848/3282 [3:01:11<27:10,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2849/3282 [3:01:14<26:02,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2850/3282 [3:01:18<25:25,  3.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2851/3282 [3:01:21<25:49,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2852/3282 [3:01:25<26:37,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2853/3282 [3:01:30<27:31,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2854/3282 [3:01:33<27:19,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2855/3282 [3:01:37<27:02,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2856/3282 [3:01:41<27:39,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2857/3282 [3:01:45<28:05,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2858/3282 [3:01:49<27:49,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2859/3282 [3:01:53<27:32,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2860/3282 [3:01:57<27:50,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2861/3282 [3:02:01<27:19,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2862/3282 [3:02:05<27:14,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2863/3282 [3:02:09<27:05,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2864/3282 [3:02:13<27:23,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2865/3282 [3:02:16<27:00,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2866/3282 [3:02:20<26:23,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2867/3282 [3:02:23<25:10,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2868/3282 [3:02:27<25:31,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2869/3282 [3:02:31<25:04,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2870/3282 [3:02:34<25:01,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  87%|████████▋ | 2871/3282 [3:02:38<25:34,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2872/3282 [3:02:42<25:30,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2873/3282 [3:02:46<25:36,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2874/3282 [3:02:49<25:17,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2875/3282 [3:02:53<25:08,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2876/3282 [3:02:57<24:56,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2877/3282 [3:03:01<25:43,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2878/3282 [3:03:04<24:07,  3.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2879/3282 [3:03:07<23:58,  3.57s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2880/3282 [3:03:11<24:47,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2881/3282 [3:03:16<25:30,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2882/3282 [3:03:19<25:16,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2883/3282 [3:03:23<24:34,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2884/3282 [3:03:26<24:16,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2885/3282 [3:03:30<24:42,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2886/3282 [3:03:34<24:23,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2887/3282 [3:03:38<24:39,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2888/3282 [3:03:42<25:05,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2889/3282 [3:03:45<24:20,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2890/3282 [3:03:49<24:38,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2891/3282 [3:03:53<24:26,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2892/3282 [3:03:57<24:37,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2893/3282 [3:04:01<24:47,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2894/3282 [3:04:04<24:47,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2895/3282 [3:04:08<25:00,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2896/3282 [3:04:12<25:14,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2897/3282 [3:04:16<25:08,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2898/3282 [3:04:20<24:26,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2899/3282 [3:04:24<24:14,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2900/3282 [3:04:27<23:59,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2901/3282 [3:04:31<23:46,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2902/3282 [3:04:35<24:06,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2903/3282 [3:04:39<23:40,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  88%|████████▊ | 2904/3282 [3:04:43<24:13,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▊ | 2905/3282 [3:04:46<23:55,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▊ | 2906/3282 [3:04:50<24:15,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▊ | 2907/3282 [3:04:54<23:27,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▊ | 2908/3282 [3:04:58<23:10,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▊ | 2909/3282 [3:05:01<23:24,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▊ | 2910/3282 [3:05:05<23:54,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▊ | 2911/3282 [3:05:10<24:09,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▊ | 2912/3282 [3:05:14<24:16,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2913/3282 [3:05:17<23:55,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2914/3282 [3:05:20<22:33,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2915/3282 [3:05:24<22:14,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2916/3282 [3:05:28<22:00,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2917/3282 [3:05:32<22:53,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2918/3282 [3:05:35<22:40,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2919/3282 [3:05:38<21:27,  3.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2920/3282 [3:05:42<21:22,  3.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2921/3282 [3:05:46<22:23,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2922/3282 [3:05:49<21:06,  3.52s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2923/3282 [3:05:53<22:09,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2924/3282 [3:05:57<22:01,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2925/3282 [3:06:01<22:29,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2926/3282 [3:06:05<22:27,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2927/3282 [3:06:08<21:40,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2928/3282 [3:06:11<20:49,  3.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2929/3282 [3:06:15<21:15,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2930/3282 [3:06:19<21:53,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2931/3282 [3:06:23<22:30,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2932/3282 [3:06:27<22:15,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2933/3282 [3:06:31<21:44,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2934/3282 [3:06:34<21:50,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2935/3282 [3:06:38<21:50,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2936/3282 [3:06:42<21:48,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  89%|████████▉ | 2937/3282 [3:06:45<21:08,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2938/3282 [3:06:49<21:25,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2939/3282 [3:06:53<21:27,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2940/3282 [3:06:57<21:33,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2941/3282 [3:07:00<19:46,  3.48s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2942/3282 [3:07:03<19:51,  3.50s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2943/3282 [3:07:07<20:33,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2944/3282 [3:07:11<21:27,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2945/3282 [3:07:16<21:58,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2946/3282 [3:07:20<21:50,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2947/3282 [3:07:23<21:23,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2948/3282 [3:07:27<21:26,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2949/3282 [3:07:31<21:18,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2950/3282 [3:07:33<18:28,  3.34s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2951/3282 [3:07:37<19:32,  3.54s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2952/3282 [3:07:41<19:49,  3.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|████████▉ | 2953/3282 [3:07:45<20:45,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2954/3282 [3:07:49<20:53,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2955/3282 [3:07:53<20:50,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2956/3282 [3:07:56<20:09,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2957/3282 [3:08:00<20:30,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2958/3282 [3:08:04<19:53,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2959/3282 [3:08:07<19:39,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2960/3282 [3:08:11<19:24,  3.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2961/3282 [3:08:15<19:56,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2962/3282 [3:08:19<20:16,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2963/3282 [3:08:23<20:30,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2964/3282 [3:08:26<19:54,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2965/3282 [3:08:30<19:43,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2966/3282 [3:08:33<19:24,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2967/3282 [3:08:37<19:14,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2968/3282 [3:08:41<19:44,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2969/3282 [3:08:45<20:09,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  90%|█████████ | 2970/3282 [3:08:49<20:23,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2971/3282 [3:08:53<19:56,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2972/3282 [3:08:57<20:04,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2973/3282 [3:09:01<20:37,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2974/3282 [3:09:05<19:50,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2975/3282 [3:09:09<19:54,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2976/3282 [3:09:12<19:39,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2977/3282 [3:09:16<19:16,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2978/3282 [3:09:20<19:08,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2979/3282 [3:09:24<19:42,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2980/3282 [3:09:28<20:03,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2981/3282 [3:09:32<19:54,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2982/3282 [3:09:36<19:34,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2983/3282 [3:09:40<19:31,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2984/3282 [3:09:44<19:14,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2985/3282 [3:09:47<18:52,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2986/3282 [3:09:52<19:36,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2987/3282 [3:09:56<19:43,  4.01s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2988/3282 [3:09:59<19:04,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2989/3282 [3:10:04<19:36,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2990/3282 [3:10:07<18:50,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2991/3282 [3:10:11<19:09,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2992/3282 [3:10:15<19:23,  4.01s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2993/3282 [3:10:19<19:08,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████ | 2994/3282 [3:10:23<17:58,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████▏| 2995/3282 [3:10:26<18:03,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████▏| 2996/3282 [3:10:31<18:29,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████▏| 2997/3282 [3:10:34<17:53,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████▏| 2998/3282 [3:10:37<17:22,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████▏| 2999/3282 [3:10:41<17:12,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████▏| 3000/3282 [3:10:45<18:03,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████▏| 3001/3282 [3:10:49<17:19,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████▏| 3002/3282 [3:10:52<17:17,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  91%|█████████▏| 3003/3282 [3:10:56<16:55,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3004/3282 [3:11:00<16:59,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3005/3282 [3:11:04<17:19,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3006/3282 [3:11:07<16:57,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3007/3282 [3:11:11<17:01,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3008/3282 [3:11:15<16:56,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3009/3282 [3:11:19<17:08,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3010/3282 [3:11:22<16:54,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3011/3282 [3:11:26<16:32,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3012/3282 [3:11:30<17:09,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3013/3282 [3:11:34<17:23,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3014/3282 [3:11:38<17:31,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3015/3282 [3:11:42<17:52,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3016/3282 [3:11:46<17:03,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3017/3282 [3:11:49<16:21,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3018/3282 [3:11:53<16:52,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3019/3282 [3:11:57<17:04,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3020/3282 [3:12:01<16:59,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3021/3282 [3:12:05<17:16,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3022/3282 [3:12:09<16:42,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3023/3282 [3:12:12<16:09,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3024/3282 [3:12:16<16:27,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3025/3282 [3:12:20<16:36,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3026/3282 [3:12:24<16:45,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3027/3282 [3:12:28<16:18,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3028/3282 [3:12:32<16:59,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3029/3282 [3:12:36<16:51,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3030/3282 [3:12:40<16:58,  4.04s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3031/3282 [3:12:45<17:01,  4.07s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3032/3282 [3:12:49<17:02,  4.09s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3033/3282 [3:12:52<16:30,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3034/3282 [3:12:56<16:09,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  92%|█████████▏| 3035/3282 [3:13:00<16:11,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3036/3282 [3:13:04<15:30,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3037/3282 [3:13:08<15:37,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3038/3282 [3:13:11<15:03,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3039/3282 [3:13:15<14:56,  3.69s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3040/3282 [3:13:18<14:28,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3041/3282 [3:13:22<14:58,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3042/3282 [3:13:25<14:11,  3.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3043/3282 [3:13:28<13:49,  3.47s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3044/3282 [3:13:32<14:25,  3.64s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3045/3282 [3:13:37<14:54,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3046/3282 [3:13:40<14:07,  3.59s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3047/3282 [3:13:44<14:37,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3048/3282 [3:13:48<14:54,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3049/3282 [3:13:52<14:51,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3050/3282 [3:13:56<15:12,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3051/3282 [3:14:00<15:18,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3052/3282 [3:14:04<15:06,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3053/3282 [3:14:08<15:10,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3054/3282 [3:14:12<15:05,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3055/3282 [3:14:16<15:00,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3056/3282 [3:14:19<14:24,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3057/3282 [3:14:23<14:34,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3058/3282 [3:14:27<14:37,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3059/3282 [3:14:31<14:40,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3060/3282 [3:14:35<14:34,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3061/3282 [3:14:39<14:32,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3062/3282 [3:14:43<14:34,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3063/3282 [3:14:47<14:41,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3064/3282 [3:14:51<14:27,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3065/3282 [3:14:55<13:43,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3066/3282 [3:14:58<13:37,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3067/3282 [3:15:02<13:37,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  93%|█████████▎| 3068/3282 [3:15:05<12:40,  3.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▎| 3069/3282 [3:15:09<12:35,  3.55s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▎| 3070/3282 [3:15:13<12:59,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▎| 3071/3282 [3:15:16<12:41,  3.61s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▎| 3072/3282 [3:15:20<13:05,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▎| 3073/3282 [3:15:24<13:27,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▎| 3074/3282 [3:15:28<13:40,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▎| 3075/3282 [3:15:32<13:41,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▎| 3076/3282 [3:15:36<13:22,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3077/3282 [3:15:40<13:23,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3078/3282 [3:15:44<13:28,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3079/3282 [3:15:48<13:14,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3080/3282 [3:15:52<13:19,  3.96s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3081/3282 [3:15:56<13:26,  4.01s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3082/3282 [3:16:00<13:14,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3083/3282 [3:16:04<12:40,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3084/3282 [3:16:07<12:33,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3085/3282 [3:16:11<12:37,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3086/3282 [3:16:15<12:51,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3087/3282 [3:16:19<12:33,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3088/3282 [3:16:23<12:15,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3089/3282 [3:16:27<12:39,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3090/3282 [3:16:31<12:20,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3091/3282 [3:16:35<12:23,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3092/3282 [3:16:39<12:16,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3093/3282 [3:16:42<11:58,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3094/3282 [3:16:46<12:10,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3095/3282 [3:16:50<11:38,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3096/3282 [3:16:54<11:50,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3097/3282 [3:16:57<11:44,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3098/3282 [3:17:01<11:21,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3099/3282 [3:17:05<11:24,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3100/3282 [3:17:09<11:28,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  94%|█████████▍| 3101/3282 [3:17:13<11:46,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3102/3282 [3:17:17<11:39,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3103/3282 [3:17:21<11:50,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3104/3282 [3:17:24<11:32,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3105/3282 [3:17:28<11:13,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3106/3282 [3:17:32<11:00,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3107/3282 [3:17:35<10:55,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3108/3282 [3:17:39<10:51,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3109/3282 [3:17:43<11:02,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3110/3282 [3:17:47<11:06,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3111/3282 [3:17:51<10:49,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3112/3282 [3:17:54<10:32,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3113/3282 [3:17:58<10:30,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3114/3282 [3:18:02<10:23,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3115/3282 [3:18:06<10:42,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3116/3282 [3:18:10<10:25,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▍| 3117/3282 [3:18:13<10:23,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3118/3282 [3:18:17<10:22,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3119/3282 [3:18:21<10:22,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3120/3282 [3:18:25<10:17,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3121/3282 [3:18:29<10:27,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3122/3282 [3:18:33<10:25,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3123/3282 [3:18:37<10:12,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3124/3282 [3:18:40<10:04,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3125/3282 [3:18:44<10:01,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3126/3282 [3:18:48<09:44,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3127/3282 [3:18:52<10:08,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3128/3282 [3:18:56<09:46,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3129/3282 [3:18:59<09:27,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3130/3282 [3:19:03<09:14,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3131/3282 [3:19:06<09:14,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3132/3282 [3:19:10<09:09,  3.66s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3133/3282 [3:19:14<09:23,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  95%|█████████▌| 3134/3282 [3:19:17<08:42,  3.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3135/3282 [3:19:21<09:01,  3.68s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3136/3282 [3:19:25<09:12,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3137/3282 [3:19:29<09:21,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3138/3282 [3:19:33<09:07,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3139/3282 [3:19:36<08:58,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3140/3282 [3:19:40<09:01,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3141/3282 [3:19:44<08:50,  3.76s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3142/3282 [3:19:48<08:53,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3143/3282 [3:19:52<08:49,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3144/3282 [3:19:56<09:01,  3.92s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3145/3282 [3:19:59<08:37,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3146/3282 [3:20:03<08:46,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3147/3282 [3:20:08<08:50,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3148/3282 [3:20:11<08:33,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3149/3282 [3:20:15<08:31,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3150/3282 [3:20:19<08:35,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3151/3282 [3:20:22<08:11,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3152/3282 [3:20:27<08:25,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3153/3282 [3:20:31<08:22,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3154/3282 [3:20:34<08:20,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3155/3282 [3:20:38<08:11,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3156/3282 [3:20:42<08:03,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3157/3282 [3:20:46<08:04,  3.88s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▌| 3158/3282 [3:20:50<07:55,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▋| 3159/3282 [3:20:54<07:53,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▋| 3160/3282 [3:20:58<07:59,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▋| 3161/3282 [3:21:01<07:47,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▋| 3162/3282 [3:21:06<07:58,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▋| 3163/3282 [3:21:10<07:49,  3.94s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▋| 3164/3282 [3:21:13<07:41,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▋| 3165/3282 [3:21:17<07:35,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▋| 3166/3282 [3:21:21<07:36,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  96%|█████████▋| 3167/3282 [3:21:25<07:31,  3.93s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3168/3282 [3:21:29<07:20,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3169/3282 [3:21:33<07:22,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3170/3282 [3:21:36<06:58,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3171/3282 [3:21:40<06:55,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3172/3282 [3:21:44<07:01,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3173/3282 [3:21:48<06:56,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3174/3282 [3:21:52<06:48,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3175/3282 [3:21:55<06:48,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3176/3282 [3:21:59<06:41,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3177/3282 [3:22:03<06:30,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3178/3282 [3:22:07<06:35,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3179/3282 [3:22:11<06:38,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3180/3282 [3:22:14<06:26,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3181/3282 [3:22:18<06:23,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3182/3282 [3:22:22<06:23,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3183/3282 [3:22:26<06:19,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3184/3282 [3:22:30<06:14,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3185/3282 [3:22:34<06:14,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3186/3282 [3:22:38<06:13,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3187/3282 [3:22:41<06:00,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3188/3282 [3:22:45<06:05,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3189/3282 [3:22:49<05:56,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3190/3282 [3:22:53<05:54,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3191/3282 [3:22:57<05:47,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3192/3282 [3:23:00<05:27,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3193/3282 [3:23:04<05:36,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3194/3282 [3:23:08<05:39,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3195/3282 [3:23:12<05:35,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3196/3282 [3:23:16<05:41,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3197/3282 [3:23:20<05:35,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3198/3282 [3:23:24<05:22,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  97%|█████████▋| 3199/3282 [3:23:27<05:09,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3200/3282 [3:23:30<04:53,  3.58s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3201/3282 [3:23:34<05:00,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3202/3282 [3:23:38<04:55,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3203/3282 [3:23:42<04:58,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3204/3282 [3:23:46<04:54,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3205/3282 [3:23:49<04:47,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3206/3282 [3:23:53<04:46,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3207/3282 [3:23:57<04:47,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3208/3282 [3:24:01<04:47,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3209/3282 [3:24:05<04:41,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3210/3282 [3:24:08<04:28,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3211/3282 [3:24:12<04:23,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3212/3282 [3:24:16<04:25,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3213/3282 [3:24:20<04:25,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3214/3282 [3:24:24<04:21,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3215/3282 [3:24:28<04:16,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3216/3282 [3:24:31<04:06,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3217/3282 [3:24:35<04:03,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3218/3282 [3:24:39<03:57,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3219/3282 [3:24:43<03:59,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3220/3282 [3:24:47<04:05,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3221/3282 [3:24:51<04:00,  3.95s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3222/3282 [3:24:55<03:59,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3223/3282 [3:24:58<03:44,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3224/3282 [3:25:02<03:43,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3225/3282 [3:25:06<03:33,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3226/3282 [3:25:10<03:35,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3227/3282 [3:25:14<03:34,  3.89s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3228/3282 [3:25:17<03:18,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3229/3282 [3:25:21<03:17,  3.72s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3230/3282 [3:25:25<03:16,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3231/3282 [3:25:29<03:14,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  98%|█████████▊| 3232/3282 [3:25:33<03:11,  3.83s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▊| 3233/3282 [3:25:36<03:06,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▊| 3234/3282 [3:25:40<03:05,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▊| 3235/3282 [3:25:44<02:57,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▊| 3236/3282 [3:25:48<02:55,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▊| 3237/3282 [3:25:52<02:55,  3.90s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▊| 3238/3282 [3:25:56<02:57,  4.03s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▊| 3239/3282 [3:26:00<02:51,  4.00s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▊| 3240/3282 [3:26:04<02:47,  3.99s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3241/3282 [3:26:08<02:43,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3242/3282 [3:26:12<02:39,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3243/3282 [3:26:16<02:34,  3.97s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3244/3282 [3:26:20<02:31,  3.98s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3245/3282 [3:26:24<02:30,  4.07s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3246/3282 [3:26:28<02:18,  3.86s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3247/3282 [3:26:31<02:12,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3248/3282 [3:26:35<02:11,  3.87s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3249/3282 [3:26:39<02:03,  3.75s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3250/3282 [3:26:43<02:02,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3251/3282 [3:26:47<02:01,  3.91s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3252/3282 [3:26:50<01:53,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3253/3282 [3:26:54<01:48,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3254/3282 [3:26:58<01:45,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3255/3282 [3:27:01<01:40,  3.70s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3256/3282 [3:27:05<01:35,  3.67s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3257/3282 [3:27:09<01:30,  3.63s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3258/3282 [3:27:13<01:29,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3259/3282 [3:27:17<01:27,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3260/3282 [3:27:20<01:23,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3261/3282 [3:27:24<01:19,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3262/3282 [3:27:28<01:16,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3263/3282 [3:27:32<01:12,  3.82s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3264/3282 [3:27:35<01:07,  3.77s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions:  99%|█████████▉| 3265/3282 [3:27:39<01:04,  3.81s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3266/3282 [3:27:43<01:00,  3.80s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3267/3282 [3:27:47<00:56,  3.74s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3268/3282 [3:27:51<00:53,  3.84s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3269/3282 [3:27:54<00:48,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3270/3282 [3:27:58<00:44,  3.71s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3271/3282 [3:28:02<00:41,  3.78s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3272/3282 [3:28:05<00:36,  3.65s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3273/3282 [3:28:09<00:32,  3.60s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3274/3282 [3:28:12<00:28,  3.53s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3275/3282 [3:28:16<00:25,  3.62s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3276/3282 [3:28:20<00:22,  3.73s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3277/3282 [3:28:24<00:18,  3.79s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3278/3282 [3:28:28<00:15,  3.85s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3279/3282 [3:28:32<00:12,  4.02s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3280/3282 [3:28:36<00:08,  4.04s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|█████████▉| 3281/3282 [3:28:40<00:04,  4.07s/question]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nGenerating predictions: 100%|██████████| 3282/3282 [3:28:44<00:00,  3.82s/question]\n","output_type":"stream"}]},{"cell_type":"code","source":"# print(predictions)\nimport csv\n\n# Open the CSV file in write mode\nwith open(\"output.csv\", \"w\", newline=\"\") as f:\n    writer = csv.writer(f)\n    \n    # Optional: Write a header if needed\n    writer.writerow([\"Prediction\"])\n\n    # Write each item from the predictions list\n    for item in predictions:\n        writer.writerow([item])\n","metadata":{"execution":{"iopub.status.busy":"2024-11-17T21:20:26.014201Z","iopub.execute_input":"2024-11-17T21:20:26.014871Z","iopub.status.idle":"2024-11-17T21:20:26.063772Z","shell.execute_reply.started":"2024-11-17T21:20:26.014832Z","shell.execute_reply":"2024-11-17T21:20:26.062869Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import csv\n\n# Open the CSV file in write mode\nwith open(\"true_output.csv\", \"w\", newline=\"\") as f:\n    writer = csv.writer(f)\n    \n    # Optional: Write a header if needed\n    writer.writerow([\"Prediction\"])\n\n    # Write each item from the predictions list\n    for item in test_dataset['Answer']:\n        writer.writerow([item])","metadata":{"execution":{"iopub.status.busy":"2024-11-17T21:20:28.781664Z","iopub.execute_input":"2024-11-17T21:20:28.782393Z","iopub.status.idle":"2024-11-17T21:20:28.987482Z","shell.execute_reply.started":"2024-11-17T21:20:28.782351Z","shell.execute_reply":"2024-11-17T21:20:28.986434Z"},"trusted":true},"execution_count":16,"outputs":[]}]}